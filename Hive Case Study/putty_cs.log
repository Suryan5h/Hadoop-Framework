=~=~=~=~=~=~=~=~=~=~=~= PuTTY log 2022.07.17 09:55:22 =~=~=~=~=~=~=~=~=~=~=~=
login as: hadoop
Authenticating with public key "try_pig"

       __|  __|_  )
       _|  (     /   Amazon Linux 2 AMI
      ___|\___|___|

https://aws.amazon.com/amazon-linux-2/
5 package(s) needed for security, out of 17 available
Run "sudo yum update" to apply all updates.
                                                                    
EEEEEEEEEEEEEEEEEEEE MMMMMMMM           MMMMMMMM RRRRRRRRRRRRRRR    
E::::::::::::::::::E M:::::::M         M:::::::M R::::::::::::::R   
EE:::::EEEEEEEEE:::E M::::::::M       M::::::::M R:::::RRRRRR:::::R 
  E::::E       EEEEE M:::::::::M     M:::::::::M RR::::R      R::::R
  E::::E             M::::::M:::M   M:::M::::::M   R:::R      R::::R
  E:::::EEEEEEEEEE   M:::::M M:::M M:::M M:::::M   R:::RRRRRR:::::R 
  E::::::::::::::E   M:::::M  M:::M:::M  M:::::M   R:::::::::::RR   
  E:::::EEEEEEEEEE   M:::::M   M:::::M   M:::::M   R:::RRRRRR::::R  
  E::::E             M:::::M    M:::M    M:::::M   R:::R      R::::R
  E::::E       EEEEE M:::::M     MMM     M:::::M   R:::R      R::::R
EE:::::EEEEEEEE::::E M:::::M             M:::::M   R:::R      R::::R
E::::::::::::::::::E M:::::M             M:::::M RR::::R      R::::R
EEEEEEEEEEEEEEEEEEEE MMMMMMM             MMMMMMM RRRRRRR      RRRRRR
                                                                    
[hadoop@ip-172-31-42-254 ~]$ [hadoop@ip-172-31-42-254 ~]$ mkdir hive_cs
[hadoop@ip-172-31-42-254 ~]$ ls
hive_cs
[hadoop@ip-172-31-42-254 ~]$ cd hive_cs/
[hadoop@ip-172-31-42-254 hive_cs]$ wget https://e-commerce-events-ml.s3.amazonaws.com/2019-Oct.csv
--2022-07-17 04:26:34--  https://e-commerce-events-ml.s3.amazonaws.com/2019-Oct.csv
Resolving e-commerce-events-ml.s3.amazonaws.com (e-commerce-events-ml.s3.amazonaws.com)... 52.217.130.201
Connecting to e-commerce-events-ml.s3.amazonaws.com (e-commerce-events-ml.s3.amazonaws.com)|52.217.130.201|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 482542278 (460M) [text/csv]
Saving to: 2019-Oct.csv

 0% [                                                                            ] 0           --.-K/s               2% [=>                                                                          ] 14,404,028  68.7MB/s              5% [===>                                                                        ] 28,686,780  68.4MB/s              8% [=====>                                                                      ] 40,424,108  64.2MB/s             11% [=======>                                                                    ] 53,728,828  54.5MB/s             14% [=========>                                                                  ] 68,682,868  57.5MB/s             16% [===========>                                                                ] 81,951,244  58.3MB/s             19% [=============>                                                              ] 92,834,932  57.5MB/s             22% [===============>                                                            ] 107,109,492 58.7MB/s             25% [==================>                                                         ] 121,384,052 59.7MB/s             28% [====================>                                                       ] 135,658,612 60.5MB/s             31% [======================>                                                     ] 149,942,388 61.1MB/s             34% [========================>                                                   ] 164,215,924 61.7MB/s             36% [===========================>                                                ] 177,977,460 61.8MB/s             40% [=============================>                                              ] 193,131,636 62.5MB/s             42% [===============================>                                            ] 207,406,196 62.9MB/s  eta 4s     45% [=================================>                                          ] 221,679,732 62.9MB/s  eta 4s     48% [====================================>                                       ] 235,946,100 62.7MB/s  eta 4s     51% [======================================>                                     ] 249,585,780 63.4MB/s  eta 4s     54% [========================================>                                   ] 264,495,220 63.6MB/s  eta 4s     57% [==========================================>                                 ] 278,769,780 66.6MB/s  eta 3s     60% [=============================================>                              ] 293,035,124 67.0MB/s  eta 3s     63% [===============================================>                            ] 306,796,660 66.8MB/s  eta 3s     66% [=================================================>                          ] 321,175,668 67.9MB/s  eta 3s     69% [===================================================>                        ] 335,494,260 67.9MB/s  eta 3s     72% [======================================================>                     ] 349,680,756 67.9MB/s  eta 2s     75% [========================================================>                   ] 363,903,092 67.8MB/s  eta 2s     78% [==========================================================>                 ] 378,326,132 67.9MB/s  eta 2s     81% [============================================================>               ] 392,592,500 67.9MB/s  eta 2s     84% [==============================================================>             ] 405,865,588 67.5MB/s  eta 2s     87% [=================================================================>          ] 420,044,916 67.5MB/s  eta 1s     90% [===================================================================>        ] 434,815,092 67.7MB/s  eta 1s     93% [=====================================================================>      ] 448,967,796 67.5MB/s  eta 1s     96% [========================================================================>   ] 463,503,476 67.6MB/s  eta 1s     99% [==========================================================================> ] 477,778,036 67.6MB/s  eta 1s     100%[===========================================================================>] 482,542,278 67.6MB/s   in 7.0s   

2022-07-17 04:26:41 (65.5 MB/s) - 2019-Oct.csv saved [482542278/482542278]

[hadoop@ip-172-31-42-254 hive_cs]$ wget https://e-commerce-events-ml.s3.amazonaws.com/2019-Oct.csv.csv.csv.csvN.csvo.csvv.csv
--2022-07-17 04:26:51--  https://e-commerce-events-ml.s3.amazonaws.com/2019-Nov.csv
Resolving e-commerce-events-ml.s3.amazonaws.com (e-commerce-events-ml.s3.amazonaws.com)... 52.216.232.179
Connecting to e-commerce-events-ml.s3.amazonaws.com (e-commerce-events-ml.s3.amazonaws.com)|52.216.232.179|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 545839412 (521M) [text/csv]
Saving to: 2019-Nov.csv

 0% [                                                                            ] 0           --.-K/s               2% [>                                                                           ] 12,054,164  57.5MB/s              4% [==>                                                                         ] 24,849,044  59.1MB/s              7% [====>                                                                       ] 40,429,204  64.2MB/s             10% [======>                                                                     ] 54,912,660  65.4MB/s             12% [========>                                                                   ] 69,195,412  65.9MB/s             14% [==========>                                                                 ] 81,294,996  64.6MB/s             17% [============>                                                               ] 96,908,948  65.8MB/s             20% [==============>                                                             ] 111,645,332 66.3MB/s             22% [================>                                                           ] 124,300,948 65.5MB/s             25% [==================>                                                         ] 140,229,268 66.5MB/s             28% [====================>                                                       ] 153,432,724 66.2MB/s             30% [======================>                                                     ] 167,534,228 66.3MB/s             33% [========================>                                                   ] 181,530,260 66.3MB/s             35% [==========================>                                                 ] 195,752,596 66.4MB/s             38% [============================>                                               ] 209,495,756 66.4MB/s  eta 5s     41% [==============================>                                             ] 224,030,412 67.7MB/s  eta 5s     43% [================================>                                           ] 238,027,468 67.5MB/s  eta 5s     46% [==================================>                                         ] 252,501,708 67.3MB/s  eta 5s     48% [====================================>                                       ] 266,871,500 67.1MB/s  eta 5s     51% [======================================>                                     ] 281,007,820 67.2MB/s  eta 4s     54% [========================================>                                   ] 295,282,380 67.5MB/s  eta 4s     56% [==========================================>                                 ] 309,373,828 67.2MB/s  eta 4s     59% [============================================>                               ] 323,948,420 67.3MB/s  eta 4s     61% [==============================================>                             ] 338,222,980 67.5MB/s  eta 4s     64% [================================================>                           ] 352,506,756 67.4MB/s  eta 3s     67% [==================================================>                         ] 366,772,100 67.8MB/s  eta 3s     69% [====================================================>                       ] 381,054,852 67.7MB/s  eta 3s     72% [======================================================>                     ] 395,321,220 67.8MB/s  eta 3s     75% [========================================================>                   ] 409,595,780 67.9MB/s  eta 3s     77% [==========================================================>                 ] 423,878,532 67.7MB/s  eta 2s     80% [============================================================>               ] 438,144,900 68.1MB/s  eta 2s     82% [=============================================================>              ] 451,836,804 67.9MB/s  eta 2s     85% [===============================================================>            ] 466,694,020 67.9MB/s  eta 2s     88% [=================================================================>          ] 480,951,172 68.2MB/s  eta 2s     90% [===================================================================>        ] 495,190,916 68.2MB/s  eta 1s     93% [=====================================================================>      ] 509,492,100 68.0MB/s  eta 1s     95% [=======================================================================>    ] 523,765,636 68.0MB/s  eta 1s     98% [=========================================================================>  ] 538,032,004 68.0MB/s  eta 1s     100%[===========================================================================>] 545,839,412 68.0MB/s   in 7.7s   

2022-07-17 04:26:58 (67.4 MB/s) - 2019-Nov.csv saved [545839412/545839412]

[hadoop@ip-172-31-42-254 hive_cs]$ ls
2019-Nov.csv  2019-Oct.csv
[hadoop@ip-172-31-42-254 hive_cs]$ hdfdfs =-cat 2019-Oct.csv | wc -l
-bash: dfs: command not found
0
[hadoop@ip-172-31-42-254 hive_cs]$ dfs -cat 2019-Oct.csv | wc -lhdfs 
cat: `2019-Oct.csv': No such file or directory
0
[hadoop@ip-172-31-42-254 hive_cs]$ ls
2019-Nov.csv  2019-Oct.csv
[hadoop@ip-172-31-42-254 hive_cs]$ hadoop fs -ls
[hadoop@ip-172-31-42-254 hive_cs]$ hadoop/hive_cs fs -ls
-bash: hadoop/hive_cs: No such file or directory
[hadoop@ip-172-31-42-254 hive_cs]$ hadoop fs -cat 20asdwget https://e-commerce-events-ml.s3.amazonaws.com/2019-Oct.csv 2019-Oct.csv | wc -l
cat: `2019-Oct.csv': No such file or directory
0
[hadoop@ip-172-31-42-254 hive_cs]$ cat 2019-Oct.csv | head
event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
2019-10-01 00:00:00 UTC,cart,5773203,1487580005134238553,,runail,2.62,463240011,26dd6e6e-4dac-4778-8d2c-92e149dab885
2019-10-01 00:00:03 UTC,cart,5773353,1487580005134238553,,runail,2.62,463240011,26dd6e6e-4dac-4778-8d2c-92e149dab885
2019-10-01 00:00:07 UTC,cart,5881589,2151191071051219817,,lovely,13.48,429681830,49e8d843-adf3-428b-a2c3-fe8bc6a307c9
2019-10-01 00:00:07 UTC,cart,5723490,1487580005134238553,,runail,2.62,463240011,26dd6e6e-4dac-4778-8d2c-92e149dab885
2019-10-01 00:00:15 UTC,cart,5881449,1487580013522845895,,lovely,0.56,429681830,49e8d843-adf3-428b-a2c3-fe8bc6a307c9
2019-10-01 00:00:16 UTC,cart,5857269,1487580005134238553,,runail,2.62,430174032,73dea1e7-664e-43f4-8b30-d32b9d5af04f
2019-10-01 00:00:19 UTC,cart,5739055,1487580008246412266,,kapous,4.75,377667011,81326ac6-daa4-4f0a-b488-fd0956a78733
2019-10-01 00:00:24 UTC,cart,5825598,1487580009445982239,,,0.56,467916806,2f5b5546-b8cb-9ee7-7ecd-84276f8ef486
2019-10-01 00:00:25 UTC,cart,5698989,1487580006317032337,,,1.27,385985999,d30965e8-1101-44ab-b45d-cc1bb9fae694
[hadoop@ip-172-31-42-254 hive_cs]$ cat 2019-Oct.csv | headNov
event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
2019-11-01 00:00:02 UTC,view,5802432,1487580009286598681,,,0.32,562076640,09fafd6c-6c99-46b1-834f-33527f4de241
2019-11-01 00:00:09 UTC,cart,5844397,1487580006317032337,,,2.38,553329724,2067216c-31b5-455d-a1cc-af0575a34ffb
2019-11-01 00:00:10 UTC,view,5837166,1783999064103190764,,pnb,22.22,556138645,57ed222e-a54a-4907-9944-5a875c2d7f4f
2019-11-01 00:00:11 UTC,cart,5876812,1487580010100293687,,jessnail,3.16,564506666,186c1951-8052-4b37-adce-dd9644b1d5f7
2019-11-01 00:00:24 UTC,remove_from_cart,5826182,1487580007483048900,,,3.33,553329724,2067216c-31b5-455d-a1cc-af0575a34ffb
2019-11-01 00:00:24 UTC,remove_from_cart,5826182,1487580007483048900,,,3.33,553329724,2067216c-31b5-455d-a1cc-af0575a34ffb
2019-11-01 00:00:25 UTC,view,5856189,1487580009026551821,,runail,15.71,562076640,09fafd6c-6c99-46b1-834f-33527f4de241
2019-11-01 00:00:32 UTC,view,5837835,1933472286753424063,,,3.49,514649199,432a4e95-375c-4b40-bd36-0fc039e77580
2019-11-01 00:00:34 UTC,remove_from_cart,5870838,1487580007675986893,,milv,0.79,429913900,2f0bff3c-252f-4fe6-afcd-5d8a6a92839a
[hadoop@ip-172-31-42-254 hive_cs]$ beeline -u jdbc:hive2://localhost:10000/default  -n hadoop
Connecting to jdbc:hive2://localhost:10000/default
Connected to: Apache Hive (version 2.3.9-amzn-2)
Driver: Hive JDBC (version 2.3.9-amzn-2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
Beeline version 2.3.9-amzn-2 by Apache Hive
0: jdbc:hive2://localhost:10000/default> show data bases;
INFO  : Compiling command(queryId=hive_20220717043609_6dc13e7d-dd4c-4eb0-8e28-cbec5d46e2ca): show databases
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:database_name, type:string, comment:from deserializer)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717043609_6dc13e7d-dd4c-4eb0-8e28-cbec5d46e2ca : STAGE DEPENDENCIES:
  Stage-0 is a root stage [DDL]
  Stage-1 depends on stages: Stage-0 [FETCH]

STAGE PLANS:
  Stage: Stage-0
      Show Databases Operator:
        Show Databases
          result file: file:/mnt/tmp/hive/c64b26ee-afee-44f3-bde1-17b8435a8c63/hive_2022-07-17_04-36-09_264_1581978858224025095-1/-local-10000

  Stage: Stage-1
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717043609_6dc13e7d-dd4c-4eb0-8e28-cbec5d46e2ca); Time taken: 1.726 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717043609_6dc13e7d-dd4c-4eb0-8e28-cbec5d46e2ca): show databases
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20220717043609_6dc13e7d-dd4c-4eb0-8e28-cbec5d46e2ca); Time taken: 0.06 seconds
INFO  : OK
+----------------+
| database_name  |
+----------------+
| default        |
+----------------+
1 row selected (2.804 seconds)
0: jdbc:hive2://localhost:10000/default> create database if not  if not exists clickstream;
INFO  : Compiling command(queryId=hive_20220717043648_f15e6f3f-d080-4bd3-9011-68710c7abecd): create database if not exists clickstream
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : EXPLAIN output for queryid hive_20220717043648_f15e6f3f-d080-4bd3-9011-68710c7abecd : STAGE DEPENDENCIES:
  Stage-0 is a root stage [DDL]

STAGE PLANS:
  Stage: Stage-0


INFO  : Completed compiling command(queryId=hive_20220717043648_f15e6f3f-d080-4bd3-9011-68710c7abecd); Time taken: 0.044 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717043648_f15e6f3f-d080-4bd3-9011-68710c7abecd): create database if not exists clickstream
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20220717043648_f15e6f3f-d080-4bd3-9011-68710c7abecd); Time taken: 0.689 seconds
INFO  : OK
No rows affected (0.766 seconds)
0: jdbc:hive2://localhost:10000/default> show databases;
INFO  : Compiling command(queryId=hive_20220717043656_d24b8abf-77c2-4f0b-8e1b-ef085650f612): show databases
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:database_name, type:string, comment:from deserializer)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717043656_d24b8abf-77c2-4f0b-8e1b-ef085650f612 : STAGE DEPENDENCIES:
  Stage-0 is a root stage [DDL]
  Stage-1 depends on stages: Stage-0 [FETCH]

STAGE PLANS:
  Stage: Stage-0
      Show Databases Operator:
        Show Databases
          result file: file:/mnt/tmp/hive/c64b26ee-afee-44f3-bde1-17b8435a8c63/hive_2022-07-17_04-36-56_859_5731896599564250842-1/-local-10000

  Stage: Stage-1
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717043656_d24b8abf-77c2-4f0b-8e1b-ef085650f612); Time taken: 0.023 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717043656_d24b8abf-77c2-4f0b-8e1b-ef085650f612): show databases
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20220717043656_d24b8abf-77c2-4f0b-8e1b-ef085650f612); Time taken: 0.009 seconds
INFO  : OK
+----------------+
| database_name  |
+----------------+
| clickstream    |
| default        |
+----------------+
2 rows selected (0.071 seconds)
0: jdbc:hive2://localhost:10000/default> use clickstream;
INFO  : Compiling command(queryId=hive_20220717043702_e7422a6e-25b0-4dc0-b22e-28a7203e4ca9): use clickstream
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : EXPLAIN output for queryid hive_20220717043702_e7422a6e-25b0-4dc0-b22e-28a7203e4ca9 : STAGE DEPENDENCIES:
  Stage-0 is a root stage [DDL]

STAGE PLANS:
  Stage: Stage-0


INFO  : Completed compiling command(queryId=hive_20220717043702_e7422a6e-25b0-4dc0-b22e-28a7203e4ca9); Time taken: 0.032 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717043702_e7422a6e-25b0-4dc0-b22e-28a7203e4ca9): use clickstream
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20220717043702_e7422a6e-25b0-4dc0-b22e-28a7203e4ca9); Time taken: 0.018 seconds
INFO  : OK
No rows affected (0.089 seconds)
0: jdbc:hive2://localhost:10000/default> create table clickstream_stats(event_time string,event_type string,product_i d string,category_id string,category_code string,brand string,price string,user_id string,user_session string) row fo rmat delimited fields terminated by ',' lines terminated by '\n' stored as textfile;
INFO  : Compiling command(queryId=hive_20220717054754_22d91731-a1a6-4255-9fc6-c4aab5ebce06): create table clickstream_stats(event_time string,event_type string,product_id string,category_id string,category_code string,brand string,price string,user_id string,user_session string) row format delimited fields terminated by ',' lines terminated by '\n' stored as textfile
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : EXPLAIN output for queryid hive_20220717054754_22d91731-a1a6-4255-9fc6-c4aab5ebce06 : STAGE DEPENDENCIES:
  Stage-0 is a root stage [DDL]

STAGE PLANS:
  Stage: Stage-0
      Create Table Operator:
        Create Table
          columns: event_time string, event_type string, product_id string, category_id string, category_code string, brand string, price string, user_id string, user_session string
          field delimiter: ,
          input format: org.apache.hadoop.mapred.TextInputFormat
          line delimiter: 

          output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
          serde name: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          name: clickstream.clickstream_stats


INFO  : Completed compiling command(queryId=hive_20220717054754_22d91731-a1a6-4255-9fc6-c4aab5ebce06); Time taken: 0.101 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717054754_22d91731-a1a6-4255-9fc6-c4aab5ebce06): create table clickstream_stats(event_time string,event_type string,product_id string,category_id string,category_code string,brand string,price string,user_id string,user_session string) row format delimited fields terminated by ',' lines terminated by '\n' stored as textfile
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20220717054754_22d91731-a1a6-4255-9fc6-c4aab5ebce06); Time taken: 0.713 seconds
INFO  : OK
No rows affected (0.832 seconds)
0: jdbc:hive2://localhost:10000/default> load data local inpath '/home/hadoop/hive_cs/2019-Oct.csv' into table clicks tream_stats;
INFO  : Compiling command(queryId=hive_20220717054836_44fdddb1-e075-454a-b138-c16399dc3231): load data local inpath '/home/hadoop/hive_cs/2019-Oct.csv' into table clickstream_stats
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : EXPLAIN output for queryid hive_20220717054836_44fdddb1-e075-454a-b138-c16399dc3231 : STAGE DEPENDENCIES:
  Stage-0 is a root stage [MOVE]
  Stage-1 depends on stages: Stage-0 [STATS]

STAGE PLANS:
  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          source: file:/home/hadoop/hive_cs/2019-Oct.csv
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
                bucket_count -1
                column.name.delimiter ,
                columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                columns.comments 
                columns.types string:string:string:string:string:string:string:string:string
                field.delim ,
                file.inputformat org.apache.hadoop.mapred.TextInputFormat
                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                line.delim 

                location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_stats
                name clickstream.clickstream_stats
                numFiles 0
                numRows 0
                rawDataSize 0
                serialization.ddl struct clickstream_stats { string event_time, string event_type, string product_id, string category_id, string category_code, string brand, string price, string user_id, string user_session}
                serialization.format ,
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                totalSize 0
                transient_lastDdlTime 1658036875
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: clickstream.clickstream_stats

  Stage: Stage-1
    Stats-Aggr Operator


INFO  : Completed compiling command(queryId=hive_20220717054836_44fdddb1-e075-454a-b138-c16399dc3231); Time taken: 0.171 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717054836_44fdddb1-e075-454a-b138-c16399dc3231): load data local inpath '/home/hadoop/hive_cs/2019-Oct.csv' into table clickstream_stats
INFO  : Starting task [Stage-0:MOVE] in serial mode
INFO  : Loading data to table clickstream.clickstream_stats from file:/home/hadoop/hive_cs/2019-Oct.csv
INFO  : Starting task [Stage-1:STATS] in serial mode
INFO  : Completed executing command(queryId=hive_20220717054836_44fdddb1-e075-454a-b138-c16399dc3231); Time taken: 8.371 seconds
INFO  : OK
No rows affected (8.571 seconds)
0: jdbc:hive2://localhost:10000/default> load data local inpath '/home/hadoop/hive_cs/2019-Nov.csv' into table clicks tream_stats;
INFO  : Compiling command(queryId=hive_20220717054945_31082c63-62a6-4c13-b085-ef802600dd3b): load data local inpath '/home/hadoop/hive_cs/2019-Nov.csv' into table clickstream_stats
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : EXPLAIN output for queryid hive_20220717054945_31082c63-62a6-4c13-b085-ef802600dd3b : STAGE DEPENDENCIES:
  Stage-0 is a root stage [MOVE]
  Stage-1 depends on stages: Stage-0 [STATS]

STAGE PLANS:
  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          source: file:/home/hadoop/hive_cs/2019-Nov.csv
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count -1
                column.name.delimiter ,
                columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                columns.comments 
                columns.types string:string:string:string:string:string:string:string:string
                field.delim ,
                file.inputformat org.apache.hadoop.mapred.TextInputFormat
                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                line.delim 

                location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_stats
                name clickstream.clickstream_stats
                numFiles 1
                numRows 0
                rawDataSize 0
                serialization.ddl struct clickstream_stats { string event_time, string event_type, string product_id, string category_id, string category_code, string brand, string price, string user_id, string user_session}
                serialization.format ,
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                totalSize 482542278
                transient_lastDdlTime 1658036925
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: clickstream.clickstream_stats

  Stage: Stage-1
    Stats-Aggr Operator


INFO  : Completed compiling command(queryId=hive_20220717054945_31082c63-62a6-4c13-b085-ef802600dd3b); Time taken: 0.104 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717054945_31082c63-62a6-4c13-b085-ef802600dd3b): load data local inpath '/home/hadoop/hive_cs/2019-Nov.csv' into table clickstream_stats
INFO  : Starting task [Stage-0:MOVE] in serial mode
INFO  : Loading data to table clickstream.clickstream_stats from file:/home/hadoop/hive_cs/2019-Nov.csv
INFO  : Starting task [Stage-1:STATS] in serial mode
INFO  : Completed executing command(queryId=hive_20220717054945_31082c63-62a6-4c13-b085-ef802600dd3b); Time taken: 9.135 seconds
INFO  : OK
No rows affected (9.254 seconds)
0: jdbc:hive2://localhost:10000/default> selecrt * from lcclickstream_Stastats orderorder by event_time lasc limit 10;
INFO  : Compiling command(queryId=hive_20220717055036_2884feaf-f28b-4571-847a-aa1f2fae9329): select * from clickstream_stats order by event_time asc limit 10
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:clickstream_stats.event_time, type:string, comment:null), FieldSchema(name:clickstream_stats.event_type, type:string, comment:null), FieldSchema(name:clickstream_stats.product_id, type:string, comment:null), FieldSchema(name:clickstream_stats.category_id, type:string, comment:null), FieldSchema(name:clickstream_stats.category_code, type:string, comment:null), FieldSchema(name:clickstream_stats.brand, type:string, comment:null), FieldSchema(name:clickstream_stats.price, type:string, comment:null), FieldSchema(name:clickstream_stats.user_id, type:string, comment:null), FieldSchema(name:clickstream_stats.user_session, type:string, comment:null)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717055036_2884feaf-f28b-4571-847a-aa1f2fae9329 : STAGE DEPENDENCIES:
  Stage-1 is a root stage [MAPRED]
  Stage-0 depends on stages: Stage-1 [FETCH]

STAGE PLANS:
  Stage: Stage-1
    Tez
      DagId: hive_20220717055036_2884feaf-f28b-4571-847a-aa1f2fae9329:1
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
      DagName: 
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: clickstream_stats
                  Statistics: Num rows: 1142646 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Select Operator
                    expressions: event_time (type: string), event_type (type: string), product_id (type: string), category_id (type: string), category_code (type: string), brand (type: string), price (type: string), user_id (type: string), user_session (type: string)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
                    Statistics: Num rows: 1142646 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: string)
                      null sort order: a
                      sort order: +
                      Statistics: Num rows: 1142646 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                      tag: -1
                      TopN: 10
                      TopN Hash Memory Usage: 0.1
                      value expressions: _col1 (type: string), _col2 (type: string), _col3 (type: string), _col4 (type: string), _col5 (type: string), _col6 (type: string), _col7 (type: string), _col8 (type: string)
                      auto parallelism: false
            Path -> Alias:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_stats [clickstream_stats]
            Path -> Partition:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_stats 
                Partition
                  base file name: clickstream_stats
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    column.name.delimiter ,
                    columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                    columns.comments 
                    columns.types string:string:string:string:string:string:string:string:string
                    field.delim ,
                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    line.delim 

                    location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_stats
                    name clickstream.clickstream_stats
                    numFiles 2
                    numRows 0
                    rawDataSize 0
                    serialization.ddl struct clickstream_stats { string event_time, string event_type, string product_id, string category_id, string category_code, string brand, string price, string user_id, string user_session}
                    serialization.format ,
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 1028381690
                    transient_lastDdlTime 1658036994
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      column.name.delimiter ,
                      columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                      columns.comments 
                      columns.types string:string:string:string:string:string:string:string:string
                      field.delim ,
                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      line.delim 

                      location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_stats
                      name clickstream.clickstream_stats
                      numFiles 2
                      numRows 0
                      rawDataSize 0
                      serialization.ddl struct clickstream_stats { string event_time, string event_type, string product_id, string category_id, string category_code, string brand, string price, string user_id, string user_session}
                      serialization.format ,
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      totalSize 1028381690
                      transient_lastDdlTime 1658036994
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: clickstream.clickstream_stats
                  name: clickstream.clickstream_stats
            Truncated Path -> Alias:
              /clickstream.db/clickstream_stats [clickstream_stats]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: string), VALUE._col0 (type: string), VALUE._col1 (type: string), VALUE._col2 (type: string), VALUE._col3 (type: string), VALUE._col4 (type: string), VALUE._col5 (type: string), VALUE._col6 (type: string), VALUE._col7 (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
                Statistics: Num rows: 1142646 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                Limit
                  Number of rows: 10
                  Statistics: Num rows: 10 Data size: 9000 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    GlobalTableId: 0
                    directory: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/c64b26ee-afee-44f3-bde1-17b8435a8c63/hive_2022-07-17_05-50-36_773_6815130166727818295-1/-mr-10001/.hive-staging_hive_2022-07-17_05-50-36_773_6815130166727818295-1/-ext-10002
                    NumFilesPerFileSink: 1
                    Statistics: Num rows: 10 Data size: 9000 Basic stats: COMPLETE Column stats: NONE
                    Stats Publishing Key Prefix: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/c64b26ee-afee-44f3-bde1-17b8435a8c63/hive_2022-07-17_05-50-36_773_6815130166727818295-1/-mr-10001/.hive-staging_hive_2022-07-17_05-50-36_773_6815130166727818295-1/-ext-10002/
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        properties:
                          columns _col0,_col1,_col2,_col3,_col4,_col5,_col6,_col7,_col8
                          columns.types string:string:string:string:string:string:string:string:string
                          escape.delim \
                          hive.serialization.extend.additional.nesting.levels true
                          serialization.escape.crlf true
                          serialization.format 1
                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    TotalFiles: 1
                    GatherStats: false
                    MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: 10
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717055036_2884feaf-f28b-4571-847a-aa1f2fae9329); Time taken: 3.771 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717055036_2884feaf-f28b-4571-847a-aa1f2fae9329): select * from clickstream_stats order by event_time asc limit 10
INFO  : Query ID = hive_20220717055036_2884feaf-f28b-4571-847a-aa1f2fae9329
INFO  : Total jobs = 1
INFO  : Launching Job 1 out of 1
INFO  : Starting task [Stage-1:MAPRED] in serial mode
INFO  : Tez session hasn't been created yet. Opening session
INFO  : Dag name: select * from clickstream_stats order b...10(Stage-1)
INFO  : Status: Running (Executing on YARN cluster with App id application_1658032091232_0001)

INFO  : Map 1: 0/8Reducer 2: 0/1
INFO  : Map 1: 0/8Reducer 2: 0/1
INFO  : Map 1: 0/8Reducer 2: 0/1
INFO  : Map 1: 0(+1)/8Reducer 2: 0/1
INFO  : Map 1: 0(+2)/8Reducer 2: 0/1
INFO  : Map 1: 0(+3)/8Reducer 2: 0/1
INFO  : Map 1: 0(+3)/8Reducer 2: 0/1
INFO  : Map 1: 0(+3)/8Reducer 2: 0/1
INFO  : Map 1: 0(+3)/8Reducer 2: 0/1
INFO  : Map 1: 0(+3)/8Reducer 2: 0/1
INFO  : Map 1: 0(+3)/8Reducer 2: 0/1
INFO  : Map 1: 0(+2)/8Reducer 2: 0/1
INFO  : Map 1: 1(+3)/8Reducer 2: 0/1
INFO  : Map 1: 2(+3)/8Reducer 2: 0/1
INFO  : Map 1: 3(+3)/8Reducer 2: 0/1
INFO  : Map 1: 3(+3)/8Reducer 2: 0/1
INFO  : Map 1: 4(+2)/8Reducer 2: 0/1
INFO  : Map 1: 5(+2)/8Reducer 2: 0/1
INFO  : Map 1: 5(+3)/8Reducer 2: 0/1
INFO  : Map 1: 6(+2)/8Reducer 2: 0(+1)/1
INFO  : Map 1: 7(+1)/8Reducer 2: 0(+1)/1
INFO  : Map 1: 8/8Reducer 2: 0(+1)/1
INFO  : Map 1: 8/8Reducer 2: 1/1
INFO  : Completed executing command(queryId=hive_20220717055036_2884feaf-f28b-4571-847a-aa1f2fae9329); Time taken: 52.284 seconds
INFO  : OK
+-------------------------------+-------------------------------+-------------------------------+--------------------------------+----------------------------------+--------------------------+--------------------------+----------------------------+---------------------------------------+
| clickstream_stats.event_time  | clickstream_stats.event_type  | clickstream_stats.product_id  | clickstream_stats.category_id  | clickstream_stats.category_code  | clickstream_stats.brand  | clickstream_stats.price  | clickstream_stats.user_id  |    clickstream_stats.user_session     |
+-------------------------------+-------------------------------+-------------------------------+--------------------------------+----------------------------------+--------------------------+--------------------------+----------------------------+---------------------------------------+
| 2019-10-01 00:00:00 UTC       | cart                          | 5773203                       | 1487580005134238553            |                                  | runail                   | 2.62                     | 463240011                  | 26dd6e6e-4dac-4778-8d2c-92e149dab885  |
| 2019-10-01 00:00:03 UTC       | cart                          | 5773353                       | 1487580005134238553            |                                  | runail                   | 2.62                     | 463240011                  | 26dd6e6e-4dac-4778-8d2c-92e149dab885  |
| 2019-10-01 00:00:07 UTC       | cart                          | 5723490                       | 1487580005134238553            |                                  | runail                   | 2.62                     | 463240011                  | 26dd6e6e-4dac-4778-8d2c-92e149dab885  |
| 2019-10-01 00:00:07 UTC       | cart                          | 5881589                       | 2151191071051219817            |                                  | lovely                   | 13.48                    | 429681830                  | 49e8d843-adf3-428b-a2c3-fe8bc6a307c9  |
| 2019-10-01 00:00:15 UTC       | cart                          | 5881449                       | 1487580013522845895            |                                  | lovely                   | 0.56                     | 429681830                  | 49e8d843-adf3-428b-a2c3-fe8bc6a307c9  |
| 2019-10-01 00:00:16 UTC       | cart                          | 5857269                       | 1487580005134238553            |                                  | runail                   | 2.62                     | 430174032                  | 73dea1e7-664e-43f4-8b30-d32b9d5af04f  |
| 2019-10-01 00:00:19 UTC       | cart                          | 5739055                       | 1487580008246412266            |                                  | kapous                   | 4.75                     | 377667011                  | 81326ac6-daa4-4f0a-b488-fd0956a78733  |
| 2019-10-01 00:00:24 UTC       | cart                          | 5825598                       | 1487580009445982239            |                                  |                          | 0.56                     | 467916806                  | 2f5b5546-b8cb-9ee7-7ecd-84276f8ef486  |
| 2019-10-01 00:00:25 UTC       | cart                          | 5698989                       | 1487580006317032337            |                                  |                          | 1.27                     | 385985999                  | d30965e8-1101-44ab-b45d-cc1bb9fae694  |
| 2019-10-01 00:00:26 UTC       | view                          | 5875317                       | 2029082628195353599            |                                  |                          | 1.59                     | 474232307                  | 445f2b74-5e4c-427e-b7fa-6e0a28b156fe  |
+-------------------------------+-------------------------------+-------------------------------+--------------------------------+----------------------------------+--------------------------+--------------------------+----------------------------+---------------------------------------+
10 rows selected (56.211 seconds)
0: jdbc:hive2://localhost:10000/default> select * from clickstream_stats order by event_time asc limit 10; limit 10; limit 10; limit 10;d limit 10;e limit 10;s limit 10;c limit 10;
INFO  : Compiling command(queryId=hive_20220717055204_53171230-4ad8-41e9-b184-7159f0b7bab2): select * from clickstream_stats order by event_time desc limit 10
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:clickstream_stats.event_time, type:string, comment:null), FieldSchema(name:clickstream_stats.event_type, type:string, comment:null), FieldSchema(name:clickstream_stats.product_id, type:string, comment:null), FieldSchema(name:clickstream_stats.category_id, type:string, comment:null), FieldSchema(name:clickstream_stats.category_code, type:string, comment:null), FieldSchema(name:clickstream_stats.brand, type:string, comment:null), FieldSchema(name:clickstream_stats.price, type:string, comment:null), FieldSchema(name:clickstream_stats.user_id, type:string, comment:null), FieldSchema(name:clickstream_stats.user_session, type:string, comment:null)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717055204_53171230-4ad8-41e9-b184-7159f0b7bab2 : STAGE DEPENDENCIES:
  Stage-1 is a root stage [MAPRED]
  Stage-0 depends on stages: Stage-1 [FETCH]

STAGE PLANS:
  Stage: Stage-1
    Tez
      DagId: hive_20220717055204_53171230-4ad8-41e9-b184-7159f0b7bab2:2
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
      DagName: 
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: clickstream_stats
                  Statistics: Num rows: 1142646 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Select Operator
                    expressions: event_time (type: string), event_type (type: string), product_id (type: string), category_id (type: string), category_code (type: string), brand (type: string), price (type: string), user_id (type: string), user_session (type: string)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
                    Statistics: Num rows: 1142646 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: string)
                      null sort order: z
                      sort order: -
                      Statistics: Num rows: 1142646 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                      tag: -1
                      TopN: 10
                      TopN Hash Memory Usage: 0.1
                      value expressions: _col1 (type: string), _col2 (type: string), _col3 (type: string), _col4 (type: string), _col5 (type: string), _col6 (type: string), _col7 (type: string), _col8 (type: string)
                      auto parallelism: false
            Path -> Alias:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_stats [clickstream_stats]
            Path -> Partition:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_stats 
                Partition
                  base file name: clickstream_stats
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    column.name.delimiter ,
                    columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                    columns.comments 
                    columns.types string:string:string:string:string:string:string:string:string
                    field.delim ,
                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    line.delim 

                    location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_stats
                    name clickstream.clickstream_stats
                    numFiles 2
                    numRows 0
                    rawDataSize 0
                    serialization.ddl struct clickstream_stats { string event_time, string event_type, string product_id, string category_id, string category_code, string brand, string price, string user_id, string user_session}
                    serialization.format ,
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 1028381690
                    transient_lastDdlTime 1658036994
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      column.name.delimiter ,
                      columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                      columns.comments 
                      columns.types string:string:string:string:string:string:string:string:string
                      field.delim ,
                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      line.delim 

                      location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_stats
                      name clickstream.clickstream_stats
                      numFiles 2
                      numRows 0
                      rawDataSize 0
                      serialization.ddl struct clickstream_stats { string event_time, string event_type, string product_id, string category_id, string category_code, string brand, string price, string user_id, string user_session}
                      serialization.format ,
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      totalSize 1028381690
                      transient_lastDdlTime 1658036994
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: clickstream.clickstream_stats
                  name: clickstream.clickstream_stats
            Truncated Path -> Alias:
              /clickstream.db/clickstream_stats [clickstream_stats]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: string), VALUE._col0 (type: string), VALUE._col1 (type: string), VALUE._col2 (type: string), VALUE._col3 (type: string), VALUE._col4 (type: string), VALUE._col5 (type: string), VALUE._col6 (type: string), VALUE._col7 (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
                Statistics: Num rows: 1142646 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                Limit
                  Number of rows: 10
                  Statistics: Num rows: 10 Data size: 9000 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    GlobalTableId: 0
                    directory: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/c64b26ee-afee-44f3-bde1-17b8435a8c63/hive_2022-07-17_05-52-04_039_5171292266360537366-1/-mr-10001/.hive-staging_hive_2022-07-17_05-52-04_039_5171292266360537366-1/-ext-10002
                    NumFilesPerFileSink: 1
                    Statistics: Num rows: 10 Data size: 9000 Basic stats: COMPLETE Column stats: NONE
                    Stats Publishing Key Prefix: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/c64b26ee-afee-44f3-bde1-17b8435a8c63/hive_2022-07-17_05-52-04_039_5171292266360537366-1/-mr-10001/.hive-staging_hive_2022-07-17_05-52-04_039_5171292266360537366-1/-ext-10002/
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        properties:
                          columns _col0,_col1,_col2,_col3,_col4,_col5,_col6,_col7,_col8
                          columns.types string:string:string:string:string:string:string:string:string
                          escape.delim \
                          hive.serialization.extend.additional.nesting.levels true
                          serialization.escape.crlf true
                          serialization.format 1
                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    TotalFiles: 1
                    GatherStats: false
                    MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: 10
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717055204_53171230-4ad8-41e9-b184-7159f0b7bab2); Time taken: 0.404 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717055204_53171230-4ad8-41e9-b184-7159f0b7bab2): select * from clickstream_stats order by event_time desc limit 10
INFO  : Query ID = hive_20220717055204_53171230-4ad8-41e9-b184-7159f0b7bab2
INFO  : Total jobs = 1
INFO  : Launching Job 1 out of 1
INFO  : Starting task [Stage-1:MAPRED] in serial mode
INFO  : Session is already open
INFO  : Dag name: select * from clickstream_stats order b...10(Stage-1)
INFO  : Status: Running (Executing on YARN cluster with App id application_1658032091232_0001)

INFO  : Map 1: 0/8Reducer 2: 0/1
INFO  : Map 1: 0/8Reducer 2: 0/1
INFO  : Map 1: 0/8Reducer 2: 0/1
INFO  : Map 1: 0(+1)/8Reducer 2: 0/1
INFO  : Map 1: 0(+2)/8Reducer 2: 0/1
INFO  : Map 1: 0(+3)/8Reducer 2: 0/1
INFO  : Map 1: 0(+3)/8Reducer 2: 0/1
INFO  : Map 1: 0(+3)/8Reducer 2: 0/1
INFO  : Map 1: 0(+3)/8Reducer 2: 0/1
INFO  : Map 1: 0(+3)/8Reducer 2: 0/1
INFO  : Map 1: 0(+3)/8Reducer 2: 0/1
INFO  : Map 1: 0(+3)/8Reducer 2: 0/1
INFO  : Map 1: 1(+3)/8Reducer 2: 0/1
INFO  : Map 1: 2(+3)/8Reducer 2: 0/1
INFO  : Map 1: 3(+3)/8Reducer 2: 0/1
INFO  : Map 1: 3(+3)/8Reducer 2: 0/1
INFO  : Map 1: 3(+3)/8Reducer 2: 0/1
INFO  : Map 1: 4(+2)/8Reducer 2: 0/1
INFO  : Map 1: 5(+2)/8Reducer 2: 0/1
INFO  : Map 1: 6(+2)/8Reducer 2: 0(+1)/1
INFO  : Map 1: 6(+2)/8Reducer 2: 0(+1)/1
INFO  : Map 1: 7(+1)/8Reducer 2: 0(+1)/1
INFO  : Map 1: 8/8Reducer 2: 0(+1)/1
INFO  : Map 1: 8/8Reducer 2: 1/1
INFO  : Completed executing command(queryId=hive_20220717055204_53171230-4ad8-41e9-b184-7159f0b7bab2); Time taken: 43.801 seconds
INFO  : OK
+-------------------------------+-------------------------------+-------------------------------+--------------------------------+----------------------------------+--------------------------+--------------------------+----------------------------+---------------------------------------+
| clickstream_stats.event_time  | clickstream_stats.event_type  | clickstream_stats.product_id  | clickstream_stats.category_id  | clickstream_stats.category_code  | clickstream_stats.brand  | clickstream_stats.price  | clickstream_stats.user_id  |    clickstream_stats.user_session     |
+-------------------------------+-------------------------------+-------------------------------+--------------------------------+----------------------------------+--------------------------+--------------------------+----------------------------+---------------------------------------+
| event_time                    | event_type                    | product_id                    | category_id                    | category_code                    | brand                    | price                    | user_id                    | user_session                          |
| event_time                    | event_type                    | product_id                    | category_id                    | category_code                    | brand                    | price                    | user_id                    | user_session                          |
| 2019-11-30 23:59:58 UTC       | view                          | 5880201                       | 2029731308699124089            |                                  | rasyan                   | 3.76                     | 579969854                  | e9fa2c3e-8c9e-448c-880a-21ca57c18b3b  |
| 2019-11-30 23:59:57 UTC       | view                          | 5779406                       | 2151191071051219817            |                                  |                          | 2.86                     | 540006764                  | d4b5aa49-d731-40f1-92f1-277416d6e063  |
| 2019-11-30 23:59:47 UTC       | view                          | 5867785                       | 1487580007835370453            |                                  | kims                     | 31.10                    | 572579084                  | d42865b7-7e04-4038-9be0-a59165625f06  |
| 2019-11-30 23:59:47 UTC       | view                          | 5733064                       | 1487580004832248652            |                                  | beautix                  | 9.37                     | 422196217                  | ab5e6dd5-8700-4ecc-a300-9f1eca5d1a95  |
| 2019-11-30 23:59:46 UTC       | view                          | 5830317                       | 1487580009496313889            |                                  |                          | 4.76                     | 457678989                  | ee50b160-a4db-4722-8751-6812c5b38295  |
| 2019-11-30 23:59:37 UTC       | view                          | 5699730                       | 1487580004882580302            |                                  |                          | 2.70                     | 422196217                  | dd6d8240-0896-4965-9344-110648581a51  |
| 2019-11-30 23:59:32 UTC       | view                          | 5795387                       | 1487580005713052531            |                                  | ingarden                 | 7.14                     | 576802932                  | 2dc9ed07-93bb-47db-abe7-e9d88ed7ae94  |
| 2019-11-30 23:59:27 UTC       | remove_from_cart              | 5801131                       | 1487580005486560104            |                                  | irisk                    | 3.65                     | 566513990                  | b5053009-b3c4-4581-b05f-6199d1a2037e  |
+-------------------------------+-------------------------------+-------------------------------+--------------------------------+----------------------------------+--------------------------+--------------------------+----------------------------+---------------------------------------+
10 rows selected (44.261 seconds)
0: jdbc:hive2://localhost:10000/default> select * from clickstream_stats order by event_time desc limit 10;0;20;
INFO  : Compiling command(queryId=hive_20220717055431_0c83ab20-685b-4a03-a9c1-680653f0564c): select * from clickstream_stats order by event_time desc limit 20
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:clickstream_stats.event_time, type:string, comment:null), FieldSchema(name:clickstream_stats.event_type, type:string, comment:null), FieldSchema(name:clickstream_stats.product_id, type:string, comment:null), FieldSchema(name:clickstream_stats.category_id, type:string, comment:null), FieldSchema(name:clickstream_stats.category_code, type:string, comment:null), FieldSchema(name:clickstream_stats.brand, type:string, comment:null), FieldSchema(name:clickstream_stats.price, type:string, comment:null), FieldSchema(name:clickstream_stats.user_id, type:string, comment:null), FieldSchema(name:clickstream_stats.user_session, type:string, comment:null)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717055431_0c83ab20-685b-4a03-a9c1-680653f0564c : STAGE DEPENDENCIES:
  Stage-1 is a root stage [MAPRED]
  Stage-0 depends on stages: Stage-1 [FETCH]

STAGE PLANS:
  Stage: Stage-1
    Tez
      DagId: hive_20220717055431_0c83ab20-685b-4a03-a9c1-680653f0564c:3
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
      DagName: 
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: clickstream_stats
                  Statistics: Num rows: 1142646 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Select Operator
                    expressions: event_time (type: string), event_type (type: string), product_id (type: string), category_id (type: string), category_code (type: string), brand (type: string), price (type: string), user_id (type: string), user_session (type: string)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
                    Statistics: Num rows: 1142646 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: string)
                      null sort order: z
                      sort order: -
                      Statistics: Num rows: 1142646 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                      tag: -1
                      TopN: 20
                      TopN Hash Memory Usage: 0.1
                      value expressions: _col1 (type: string), _col2 (type: string), _col3 (type: string), _col4 (type: string), _col5 (type: string), _col6 (type: string), _col7 (type: string), _col8 (type: string)
                      auto parallelism: false
            Path -> Alias:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_stats [clickstream_stats]
            Path -> Partition:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_stats 
                Partition
                  base file name: clickstream_stats
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    column.name.delimiter ,
                    columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                    columns.comments 
                    columns.types string:string:string:string:string:string:string:string:string
                    field.delim ,
                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    line.delim 

                    location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_stats
                    name clickstream.clickstream_stats
                    numFiles 2
                    numRows 0
                    rawDataSize 0
                    serialization.ddl struct clickstream_stats { string event_time, string event_type, string product_id, string category_id, string category_code, string brand, string price, string user_id, string user_session}
                    serialization.format ,
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 1028381690
                    transient_lastDdlTime 1658036994
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      column.name.delimiter ,
                      columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                      columns.comments 
                      columns.types string:string:string:string:string:string:string:string:string
                      field.delim ,
                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      line.delim 

                      location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_stats
                      name clickstream.clickstream_stats
                      numFiles 2
                      numRows 0
                      rawDataSize 0
                      serialization.ddl struct clickstream_stats { string event_time, string event_type, string product_id, string category_id, string category_code, string brand, string price, string user_id, string user_session}
                      serialization.format ,
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      totalSize 1028381690
                      transient_lastDdlTime 1658036994
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: clickstream.clickstream_stats
                  name: clickstream.clickstream_stats
            Truncated Path -> Alias:
              /clickstream.db/clickstream_stats [clickstream_stats]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: string), VALUE._col0 (type: string), VALUE._col1 (type: string), VALUE._col2 (type: string), VALUE._col3 (type: string), VALUE._col4 (type: string), VALUE._col5 (type: string), VALUE._col6 (type: string), VALUE._col7 (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
                Statistics: Num rows: 1142646 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                Limit
                  Number of rows: 20
                  Statistics: Num rows: 20 Data size: 18000 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    GlobalTableId: 0
                    directory: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/c64b26ee-afee-44f3-bde1-17b8435a8c63/hive_2022-07-17_05-54-31_298_753016501682716217-1/-mr-10001/.hive-staging_hive_2022-07-17_05-54-31_298_753016501682716217-1/-ext-10002
                    NumFilesPerFileSink: 1
                    Statistics: Num rows: 20 Data size: 18000 Basic stats: COMPLETE Column stats: NONE
                    Stats Publishing Key Prefix: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/c64b26ee-afee-44f3-bde1-17b8435a8c63/hive_2022-07-17_05-54-31_298_753016501682716217-1/-mr-10001/.hive-staging_hive_2022-07-17_05-54-31_298_753016501682716217-1/-ext-10002/
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        properties:
                          columns _col0,_col1,_col2,_col3,_col4,_col5,_col6,_col7,_col8
                          columns.types string:string:string:string:string:string:string:string:string
                          escape.delim \
                          hive.serialization.extend.additional.nesting.levels true
                          serialization.escape.crlf true
                          serialization.format 1
                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    TotalFiles: 1
                    GatherStats: false
                    MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: 20
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717055431_0c83ab20-685b-4a03-a9c1-680653f0564c); Time taken: 0.236 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717055431_0c83ab20-685b-4a03-a9c1-680653f0564c): select * from clickstream_stats order by event_time desc limit 20
INFO  : Query ID = hive_20220717055431_0c83ab20-685b-4a03-a9c1-680653f0564c
INFO  : Total jobs = 1
INFO  : Launching Job 1 out of 1
INFO  : Starting task [Stage-1:MAPRED] in serial mode
INFO  : Session is already open
INFO  : Dag name: select * from clickstream_stats order b...20(Stage-1)
INFO  : Status: Running (Executing on YARN cluster with App id application_1658032091232_0001)

INFO  : Map 1: 0/8Reducer 2: 0/1
INFO  : Map 1: 0/8Reducer 2: 0/1
INFO  : Map 1: 0(+1)/8Reducer 2: 0/1
INFO  : Map 1: 0(+2)/8Reducer 2: 0/1
INFO  : Map 1: 0(+3)/8Reducer 2: 0/1
INFO  : Map 1: 0(+3)/8Reducer 2: 0/1
INFO  : Map 1: 0(+3)/8Reducer 2: 0/1
INFO  : Map 1: 0(+3)/8Reducer 2: 0/1
INFO  : Map 1: 0(+3)/8Reducer 2: 0/1
INFO  : Map 1: 0(+3)/8Reducer 2: 0/1
INFO  : Map 1: 0(+3)/8Reducer 2: 0/1
INFO  : Map 1: 1(+3)/8Reducer 2: 0/1
INFO  : Map 1: 2(+3)/8Reducer 2: 0/1
INFO  : Map 1: 3(+3)/8Reducer 2: 0/1
INFO  : Map 1: 3(+3)/8Reducer 2: 0/1
INFO  : Map 1: 3(+3)/8Reducer 2: 0/1
INFO  : Map 1: 3(+3)/8Reducer 2: 0/1
INFO  : Map 1: 4(+2)/8Reducer 2: 0/1
INFO  : Map 1: 6(+0)/8Reducer 2: 0/1
INFO  : Map 1: 6(+1)/8Reducer 2: 0/1
INFO  : Map 1: 6(+2)/8Reducer 2: 0(+1)/1
INFO  : Map 1: 6(+2)/8Reducer 2: 0(+1)/1
INFO  : Map 1: 7(+1)/8Reducer 2: 0(+1)/1
INFO  : Map 1: 8/8Reducer 2: 0(+1)/1
INFO  : Map 1: 8/8Reducer 2: 1/1
INFO  : Completed executing command(queryId=hive_20220717055431_0c83ab20-685b-4a03-a9c1-680653f0564c); Time taken: 46.035 seconds
INFO  : OK
+-------------------------------+-------------------------------+-------------------------------+--------------------------------+----------------------------------+--------------------------+--------------------------+----------------------------+---------------------------------------+
| clickstream_stats.event_time  | clickstream_stats.event_type  | clickstream_stats.product_id  | clickstream_stats.category_id  | clickstream_stats.category_code  | clickstream_stats.brand  | clickstream_stats.price  | clickstream_stats.user_id  |    clickstream_stats.user_session     |
+-------------------------------+-------------------------------+-------------------------------+--------------------------------+----------------------------------+--------------------------+--------------------------+----------------------------+---------------------------------------+
| event_time                    | event_type                    | product_id                    | category_id                    | category_code                    | brand                    | price                    | user_id                    | user_session                          |
| event_time                    | event_type                    | product_id                    | category_id                    | category_code                    | brand                    | price                    | user_id                    | user_session                          |
| 2019-11-30 23:59:58 UTC       | view                          | 5880201                       | 2029731308699124089            |                                  | rasyan                   | 3.76                     | 579969854                  | e9fa2c3e-8c9e-448c-880a-21ca57c18b3b  |
| 2019-11-30 23:59:57 UTC       | view                          | 5779406                       | 2151191071051219817            |                                  |                          | 2.86                     | 540006764                  | d4b5aa49-d731-40f1-92f1-277416d6e063  |
| 2019-11-30 23:59:47 UTC       | view                          | 5867785                       | 1487580007835370453            |                                  | kims                     | 31.10                    | 572579084                  | d42865b7-7e04-4038-9be0-a59165625f06  |
| 2019-11-30 23:59:47 UTC       | view                          | 5733064                       | 1487580004832248652            |                                  | beautix                  | 9.37                     | 422196217                  | ab5e6dd5-8700-4ecc-a300-9f1eca5d1a95  |
| 2019-11-30 23:59:46 UTC       | view                          | 5830317                       | 1487580009496313889            |                                  |                          | 4.76                     | 457678989                  | ee50b160-a4db-4722-8751-6812c5b38295  |
| 2019-11-30 23:59:37 UTC       | view                          | 5699730                       | 1487580004882580302            |                                  |                          | 2.70                     | 422196217                  | dd6d8240-0896-4965-9344-110648581a51  |
| 2019-11-30 23:59:32 UTC       | view                          | 5795387                       | 1487580005713052531            |                                  | ingarden                 | 7.14                     | 576802932                  | 2dc9ed07-93bb-47db-abe7-e9d88ed7ae94  |
| 2019-11-30 23:59:27 UTC       | remove_from_cart              | 5801131                       | 1487580005486560104            |                                  | irisk                    | 3.65                     | 566513990                  | b5053009-b3c4-4581-b05f-6199d1a2037e  |
| 2019-11-30 23:59:27 UTC       | remove_from_cart              | 5801131                       | 1487580005486560104            |                                  | irisk                    | 3.65                     | 566513990                  | b5053009-b3c4-4581-b05f-6199d1a2037e  |
| 2019-11-30 23:59:25 UTC       | remove_from_cart              | 5810080                       | 1487580005268456287            |                                  | irisk                    | 6.51                     | 566513990                  | b5053009-b3c4-4581-b05f-6199d1a2037e  |
| 2019-11-30 23:59:25 UTC       | remove_from_cart              | 5810080                       | 1487580005268456287            |                                  | irisk                    | 6.51                     | 566513990                  | b5053009-b3c4-4581-b05f-6199d1a2037e  |
| 2019-11-30 23:59:25 UTC       | view                          | 5772301                       | 1602943681873052386            |                                  | grattol                  | 4.76                     | 576005683                  | 28172809-7e4a-45ce-bab0-5efa90117cd5  |
| 2019-11-30 23:59:24 UTC       | view                          | 5694628                       | 1487580007835370453            |                                  | yoko                     | 3.65                     | 576802932                  | f5b0e79b-0470-4256-ba47-4166ea4f05f5  |
| 2019-11-30 23:59:24 UTC       | remove_from_cart              | 5608703                       | 1487580005553668971            |                                  |                          | 9.52                     | 566513990                  | b5053009-b3c4-4581-b05f-6199d1a2037e  |
| 2019-11-30 23:59:24 UTC       | remove_from_cart              | 5608703                       | 1487580005553668971            |                                  |                          | 9.52                     | 566513990                  | b5053009-b3c4-4581-b05f-6199d1a2037e  |
| 2019-11-30 23:59:22 UTC       | cart                          | 5839649                       | 1487580005671109489            |                                  | masura                   | 2.37                     | 475720349                  | d2ec1d29-88d9-40b5-98e2-ffdac2a832cd  |
| 2019-11-30 23:59:22 UTC       | view                          | 5650610                       | 1487580007835370453            |                                  | metzger                  | 4.84                     | 576802932                  | 64c39ba7-5018-4009-ac30-fa04bdabc434  |
| 2019-11-30 23:59:20 UTC       | view                          | 5692261                       | 1487580007835370453            |                                  | staleks                  | 6.35                     | 576802932                  | 495159b1-ab2a-4daa-901f-5889da3905a3  |
+-------------------------------+-------------------------------+-------------------------------+--------------------------------+----------------------------------+--------------------------+--------------------------+----------------------------+---------------------------------------+
20 rows selected (46.349 seconds)
0: jdbc:hive2://localhost:10000/default> select * from clickstream_stats order by event_time desc limit 20; limit 20; limit 20; limit 20; limit 20;a limit 20;s limit 20;c limit 20;
INFO  : Compiling command(queryId=hive_20220717055817_8263914c-a284-4b0c-ad0d-75500e4ec342): select * from clickstream_stats order by event_time asc limit 20
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:clickstream_stats.event_time, type:string, comment:null), FieldSchema(name:clickstream_stats.event_type, type:string, comment:null), FieldSchema(name:clickstream_stats.product_id, type:string, comment:null), FieldSchema(name:clickstream_stats.category_id, type:string, comment:null), FieldSchema(name:clickstream_stats.category_code, type:string, comment:null), FieldSchema(name:clickstream_stats.brand, type:string, comment:null), FieldSchema(name:clickstream_stats.price, type:string, comment:null), FieldSchema(name:clickstream_stats.user_id, type:string, comment:null), FieldSchema(name:clickstream_stats.user_session, type:string, comment:null)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717055817_8263914c-a284-4b0c-ad0d-75500e4ec342 : STAGE DEPENDENCIES:
  Stage-1 is a root stage [MAPRED]
  Stage-0 depends on stages: Stage-1 [FETCH]

STAGE PLANS:
  Stage: Stage-1
    Tez
      DagId: hive_20220717055817_8263914c-a284-4b0c-ad0d-75500e4ec342:4
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
      DagName: 
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: clickstream_stats
                  Statistics: Num rows: 1142646 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Select Operator
                    expressions: event_time (type: string), event_type (type: string), product_id (type: string), category_id (type: string), category_code (type: string), brand (type: string), price (type: string), user_id (type: string), user_session (type: string)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
                    Statistics: Num rows: 1142646 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: string)
                      null sort order: a
                      sort order: +
                      Statistics: Num rows: 1142646 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                      tag: -1
                      TopN: 20
                      TopN Hash Memory Usage: 0.1
                      value expressions: _col1 (type: string), _col2 (type: string), _col3 (type: string), _col4 (type: string), _col5 (type: string), _col6 (type: string), _col7 (type: string), _col8 (type: string)
                      auto parallelism: false
            Path -> Alias:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_stats [clickstream_stats]
            Path -> Partition:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_stats 
                Partition
                  base file name: clickstream_stats
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    column.name.delimiter ,
                    columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                    columns.comments 
                    columns.types string:string:string:string:string:string:string:string:string
                    field.delim ,
                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    line.delim 

                    location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_stats
                    name clickstream.clickstream_stats
                    numFiles 2
                    numRows 0
                    rawDataSize 0
                    serialization.ddl struct clickstream_stats { string event_time, string event_type, string product_id, string category_id, string category_code, string brand, string price, string user_id, string user_session}
                    serialization.format ,
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 1028381690
                    transient_lastDdlTime 1658036994
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      column.name.delimiter ,
                      columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                      columns.comments 
                      columns.types string:string:string:string:string:string:string:string:string
                      field.delim ,
                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      line.delim 

                      location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_stats
                      name clickstream.clickstream_stats
                      numFiles 2
                      numRows 0
                      rawDataSize 0
                      serialization.ddl struct clickstream_stats { string event_time, string event_type, string product_id, string category_id, string category_code, string brand, string price, string user_id, string user_session}
                      serialization.format ,
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      totalSize 1028381690
                      transient_lastDdlTime 1658036994
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: clickstream.clickstream_stats
                  name: clickstream.clickstream_stats
            Truncated Path -> Alias:
              /clickstream.db/clickstream_stats [clickstream_stats]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: string), VALUE._col0 (type: string), VALUE._col1 (type: string), VALUE._col2 (type: string), VALUE._col3 (type: string), VALUE._col4 (type: string), VALUE._col5 (type: string), VALUE._col6 (type: string), VALUE._col7 (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
                Statistics: Num rows: 1142646 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                Limit
                  Number of rows: 20
                  Statistics: Num rows: 20 Data size: 18000 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    GlobalTableId: 0
                    directory: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/c64b26ee-afee-44f3-bde1-17b8435a8c63/hive_2022-07-17_05-58-17_902_4744982976614571682-1/-mr-10001/.hive-staging_hive_2022-07-17_05-58-17_902_4744982976614571682-1/-ext-10002
                    NumFilesPerFileSink: 1
                    Statistics: Num rows: 20 Data size: 18000 Basic stats: COMPLETE Column stats: NONE
                    Stats Publishing Key Prefix: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/c64b26ee-afee-44f3-bde1-17b8435a8c63/hive_2022-07-17_05-58-17_902_4744982976614571682-1/-mr-10001/.hive-staging_hive_2022-07-17_05-58-17_902_4744982976614571682-1/-ext-10002/
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        properties:
                          columns _col0,_col1,_col2,_col3,_col4,_col5,_col6,_col7,_col8
                          columns.types string:string:string:string:string:string:string:string:string
                          escape.delim \
                          hive.serialization.extend.additional.nesting.levels true
                          serialization.escape.crlf true
                          serialization.format 1
                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    TotalFiles: 1
                    GatherStats: false
                    MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: 20
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717055817_8263914c-a284-4b0c-ad0d-75500e4ec342); Time taken: 0.216 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717055817_8263914c-a284-4b0c-ad0d-75500e4ec342): select * from clickstream_stats order by event_time asc limit 20
INFO  : Query ID = hive_20220717055817_8263914c-a284-4b0c-ad0d-75500e4ec342
INFO  : Total jobs = 1
INFO  : Launching Job 1 out of 1
INFO  : Starting task [Stage-1:MAPRED] in serial mode
INFO  : Session is already open
INFO  : Dag name: select * from clickstream_stats order b...20(Stage-1)
INFO  : Status: Running (Executing on YARN cluster with App id application_1658032091232_0001)

INFO  : Map 1: 0/8Reducer 2: 0/1
INFO  : Map 1: 0/8Reducer 2: 0/1
INFO  : Map 1: 0(+1)/8Reducer 2: 0/1
INFO  : Map 1: 0(+2)/8Reducer 2: 0/1
INFO  : Map 1: 0(+3)/8Reducer 2: 0/1
INFO  : Map 1: 0(+3)/8Reducer 2: 0/1
INFO  : Map 1: 0(+3)/8Reducer 2: 0/1
INFO  : Map 1: 0(+3)/8Reducer 2: 0/1
INFO  : Map 1: 0(+3)/8Reducer 2: 0/1
INFO  : Map 1: 0(+3)/8Reducer 2: 0/1
INFO  : Map 1: 1(+3)/8Reducer 2: 0/1
INFO  : Map 1: 2(+3)/8Reducer 2: 0/1
INFO  : Map 1: 3(+3)/8Reducer 2: 0/1
INFO  : Map 1: 3(+3)/8Reducer 2: 0/1
INFO  : Map 1: 4(+2)/8Reducer 2: 0/1
INFO  : Map 1: 4(+3)/8Reducer 2: 0/1
INFO  : Map 1: 5(+2)/8Reducer 2: 0/1
INFO  : Map 1: 5(+3)/8Reducer 2: 0/1
INFO  : Map 1: 6(+2)/8Reducer 2: 0(+1)/1
INFO  : Map 1: 7(+1)/8Reducer 2: 0(+1)/1
INFO  : Map 1: 8/8Reducer 2: 0(+1)/1
INFO  : Map 1: 8/8Reducer 2: 1/1
INFO  : Completed executing command(queryId=hive_20220717055817_8263914c-a284-4b0c-ad0d-75500e4ec342); Time taken: 37.689 seconds
INFO  : OK
+-------------------------------+-------------------------------+-------------------------------+--------------------------------+----------------------------------+--------------------------+--------------------------+----------------------------+---------------------------------------+
| clickstream_stats.event_time  | clickstream_stats.event_type  | clickstream_stats.product_id  | clickstream_stats.category_id  | clickstream_stats.category_code  | clickstream_stats.brand  | clickstream_stats.price  | clickstream_stats.user_id  |    clickstream_stats.user_session     |
+-------------------------------+-------------------------------+-------------------------------+--------------------------------+----------------------------------+--------------------------+--------------------------+----------------------------+---------------------------------------+
| 2019-10-01 00:00:00 UTC       | cart                          | 5773203                       | 1487580005134238553            |                                  | runail                   | 2.62                     | 463240011                  | 26dd6e6e-4dac-4778-8d2c-92e149dab885  |
| 2019-10-01 00:00:03 UTC       | cart                          | 5773353                       | 1487580005134238553            |                                  | runail                   | 2.62                     | 463240011                  | 26dd6e6e-4dac-4778-8d2c-92e149dab885  |
| 2019-10-01 00:00:07 UTC       | cart                          | 5723490                       | 1487580005134238553            |                                  | runail                   | 2.62                     | 463240011                  | 26dd6e6e-4dac-4778-8d2c-92e149dab885  |
| 2019-10-01 00:00:07 UTC       | cart                          | 5881589                       | 2151191071051219817            |                                  | lovely                   | 13.48                    | 429681830                  | 49e8d843-adf3-428b-a2c3-fe8bc6a307c9  |
| 2019-10-01 00:00:15 UTC       | cart                          | 5881449                       | 1487580013522845895            |                                  | lovely                   | 0.56                     | 429681830                  | 49e8d843-adf3-428b-a2c3-fe8bc6a307c9  |
| 2019-10-01 00:00:16 UTC       | cart                          | 5857269                       | 1487580005134238553            |                                  | runail                   | 2.62                     | 430174032                  | 73dea1e7-664e-43f4-8b30-d32b9d5af04f  |
| 2019-10-01 00:00:19 UTC       | cart                          | 5739055                       | 1487580008246412266            |                                  | kapous                   | 4.75                     | 377667011                  | 81326ac6-daa4-4f0a-b488-fd0956a78733  |
| 2019-10-01 00:00:24 UTC       | cart                          | 5825598                       | 1487580009445982239            |                                  |                          | 0.56                     | 467916806                  | 2f5b5546-b8cb-9ee7-7ecd-84276f8ef486  |
| 2019-10-01 00:00:25 UTC       | cart                          | 5698989                       | 1487580006317032337            |                                  |                          | 1.27                     | 385985999                  | d30965e8-1101-44ab-b45d-cc1bb9fae694  |
| 2019-10-01 00:00:26 UTC       | view                          | 5875317                       | 2029082628195353599            |                                  |                          | 1.59                     | 474232307                  | 445f2b74-5e4c-427e-b7fa-6e0a28b156fe  |
| 2019-10-01 00:00:28 UTC       | remove_from_cart              | 5834172                       | 1487580013522845895            |                                  | runail                   | 0.95                     | 429681830                  | 49e8d843-adf3-428b-a2c3-fe8bc6a307c9  |
| 2019-10-01 00:00:28 UTC       | view                          | 5692917                       | 1487580004857414477            |                                  | lianail                  | 5.54                     | 555446068                  | 4257671a-efc8-4e58-96c2-3ab457916d78  |
| 2019-10-01 00:00:30 UTC       | remove_from_cart              | 5809103                       | 1487580013522845895            |                                  | irisk                    | 0.60                     | 429681830                  | 49e8d843-adf3-428b-a2c3-fe8bc6a307c9  |
| 2019-10-01 00:00:30 UTC       | remove_from_cart              | 5809103                       | 1487580013522845895            |                                  | irisk                    | 0.60                     | 429681830                  | 49e8d843-adf3-428b-a2c3-fe8bc6a307c9  |
| 2019-10-01 00:00:32 UTC       | remove_from_cart              | 5779403                       | 1487580013506068678            |                                  |                          | 12.22                    | 429681830                  | 49e8d843-adf3-428b-a2c3-fe8bc6a307c9  |
| 2019-10-01 00:00:33 UTC       | remove_from_cart              | 5779403                       | 1487580013506068678            |                                  |                          | 12.22                    | 429681830                  | 49e8d843-adf3-428b-a2c3-fe8bc6a307c9  |
| 2019-10-01 00:00:34 UTC       | cart                          | 5670337                       | 1752742615205281895            |                                  |                          | 2.38                     | 546705258                  | 3b5c65c0-bb1c-453b-b340-4ebf973a3136  |
| 2019-10-01 00:00:42 UTC       | cart                          | 5836522                       | 1487580013522845895            |                                  | nagaraku                 | 0.40                     | 429681830                  | 49e8d843-adf3-428b-a2c3-fe8bc6a307c9  |
| 2019-10-01 00:00:43 UTC       | cart                          | 5836522                       | 1487580013522845895            |                                  | nagaraku                 | 0.40                     | 429681830                  | 49e8d843-adf3-428b-a2c3-fe8bc6a307c9  |
| 2019-10-01 00:00:48 UTC       | cart                          | 5859414                       | 1487580005671109489            |                                  | masura                   | 2.37                     | 555442940                  | 618f3d7d-2939-47ea-8f1d-07a4f97d0fe2  |
+-------------------------------+-------------------------------+-------------------------------+--------------------------------+----------------------------------+--------------------------+--------------------------+----------------------------+---------------------------------------+
20 rows selected (37.951 seconds)
0: jdbc:hive2://localhost:10000/default> shwow tables;
INFO  : Compiling command(queryId=hive_20220717062721_c1889da0-f78b-44f2-8536-517c0ef5013d): show tables
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:tab_name, type:string, comment:from deserializer)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717062721_c1889da0-f78b-44f2-8536-517c0ef5013d : STAGE DEPENDENCIES:
  Stage-0 is a root stage [DDL]
  Stage-1 depends on stages: Stage-0 [FETCH]

STAGE PLANS:
  Stage: Stage-0
      Show Table Operator:
        Show Tables
          database name: clickstream
          result file: file:/mnt/tmp/hive/c64b26ee-afee-44f3-bde1-17b8435a8c63/hive_2022-07-17_06-27-21_545_7711364949251917636-1/-local-10000

  Stage: Stage-1
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717062721_c1889da0-f78b-44f2-8536-517c0ef5013d); Time taken: 0.025 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717062721_c1889da0-f78b-44f2-8536-517c0ef5013d): show tables
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20220717062721_c1889da0-f78b-44f2-8536-517c0ef5013d); Time taken: 0.051 seconds
INFO  : OK
+--------------------+
|      tab_name      |
+--------------------+
| clickstream_stats  |
+--------------------+
1 row selected (0.1 seconds)
0: jdbc:hive2://localhost:10000/default> create table if not exists clickstream_tbl(event_time timestamp,event_type s tring, product_id string, category_id string, category_code string, brand string, price decimal(10,3),user_id bigint,  user_session string) row format serde 'org.apache.hadoop.hive.serde2.OpenCSVSerde' 
. . . . . . . . . . . . . . . . . . . .> WITH SERDEPROPERTIES ( "separatorChar" = ",", "quoteChar" = "\"", "escapeCha r" = "\\") stored as textfile 
. . . . . . . . . . . . . . . . . . . .> TBLPROPERTIES ("skip.header.line.count"="1");asd);
Error: Error while compiling statement: FAILED: ParseException line 3:44 extraneous input ')' expecting EOF near '<EOF>' (state=42000,code=40000)
0: jdbc:hive2://localhost:10000/default> create table if not exists clickstream_tbl(event_time timestamp,event_type s tring, product_id string, category_id string, category_code string, brand string, price decimal(10,3),user_id bigint,  user_session string) row format serde 'org.apache.hadoop.hive.serde2.OpenCSVSerde' WITH SERDEPROPERTIES ( "separator Char" = ",", "quoteChar" = "\"", "escapeChar" = "\\") stored as textfile TBLPROPERTIES ("skip.header.line.count"="1") ;
INFO  : Compiling command(queryId=hive_20220717063543_3540aa53-8e2b-4b09-80b4-b7e41fceeb59): create table if not exists clickstream_tbl(event_time timestamp,event_type string, product_id string, category_id string, category_code string, brand string, price decimal(10,3),user_id bigint, user_session string) row format serde 'org.apache.hadoop.hive.serde2.OpenCSVSerde' WITH SERDEPROPERTIES ( "separatorChar" = ",", "quoteChar" = "\"", "escapeChar" = "\\") stored as textfile TBLPROPERTIES ("skip.header.line.count"="1")
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : EXPLAIN output for queryid hive_20220717063543_3540aa53-8e2b-4b09-80b4-b7e41fceeb59 : STAGE DEPENDENCIES:
  Stage-0 is a root stage [DDL]

STAGE PLANS:
  Stage: Stage-0
      Create Table Operator:
        Create Table
          columns: event_time timestamp, event_type string, product_id string, category_id string, category_code string, brand string, price decimal(10,3), user_id bigint, user_session string
          if not exists: true
          input format: org.apache.hadoop.mapred.TextInputFormat
          output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
          serde name: org.apache.hadoop.hive.serde2.OpenCSVSerde
          serde properties:
            escapeChar \
            quoteChar "
            separatorChar ,
          name: clickstream.clickstream_tbl
          table properties:
            skip.header.line.count 1


INFO  : Completed compiling command(queryId=hive_20220717063543_3540aa53-8e2b-4b09-80b4-b7e41fceeb59); Time taken: 0.03 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717063543_3540aa53-8e2b-4b09-80b4-b7e41fceeb59): create table if not exists clickstream_tbl(event_time timestamp,event_type string, product_id string, category_id string, category_code string, brand string, price decimal(10,3),user_id bigint, user_session string) row format serde 'org.apache.hadoop.hive.serde2.OpenCSVSerde' WITH SERDEPROPERTIES ( "separatorChar" = ",", "quoteChar" = "\"", "escapeChar" = "\\") stored as textfile TBLPROPERTIES ("skip.header.line.count"="1")
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20220717063543_3540aa53-8e2b-4b09-80b4-b7e41fceeb59); Time taken: 0.079 seconds
INFO  : OK
No rows affected (0.123 seconds)
0: jdbc:hive2://localhost:10000/default> load data local inpath '/home/hadoop/hive_cs/2019-Oct.csv' into table clicks tream_tbl;
INFO  : Compiling command(queryId=hive_20220717063613_1dc71144-55b6-4665-908c-e00e5578af03): load data local inpath '/home/hadoop/hive_cs/2019-Oct.csv' into table clickstream_tbl
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : EXPLAIN output for queryid hive_20220717063613_1dc71144-55b6-4665-908c-e00e5578af03 : STAGE DEPENDENCIES:
  Stage-0 is a root stage [MOVE]
  Stage-1 depends on stages: Stage-0 [STATS]

STAGE PLANS:
  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          source: file:/home/hadoop/hive_cs/2019-Oct.csv
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
                bucket_count -1
                column.name.delimiter ,
                columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                columns.comments 
                columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                escapeChar \
                file.inputformat org.apache.hadoop.mapred.TextInputFormat
                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                name clickstream.clickstream_tbl
                numFiles 0
                numRows 0
                quoteChar "
                rawDataSize 0
                separatorChar ,
                serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                skip.header.line.count 1
                totalSize 0
                transient_lastDdlTime 1658039743
              serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
              name: clickstream.clickstream_tbl

  Stage: Stage-1
    Stats-Aggr Operator


INFO  : Completed compiling command(queryId=hive_20220717063613_1dc71144-55b6-4665-908c-e00e5578af03); Time taken: 0.039 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717063613_1dc71144-55b6-4665-908c-e00e5578af03): load data local inpath '/home/hadoop/hive_cs/2019-Oct.csv' into table clickstream_tbl
INFO  : Starting task [Stage-0:MOVE] in serial mode
INFO  : Loading data to table clickstream.clickstream_tbl from file:/home/hadoop/hive_cs/2019-Oct.csv
INFO  : Starting task [Stage-1:STATS] in serial mode
INFO  : Completed executing command(queryId=hive_20220717063613_1dc71144-55b6-4665-908c-e00e5578af03); Time taken: 8.624 seconds
INFO  : OK
No rows affected (8.677 seconds)
0: jdbc:hive2://localhost:10000/default> load data local inpath '/home/hadoop/hive_cs/2019-Nov.csv' into table clicks tream_tbl;
INFO  : Compiling command(queryId=hive_20220717063639_964690ec-3572-4695-bfdc-c80dac1ccce5): load data local inpath '/home/hadoop/hive_cs/2019-Nov.csv' into table clickstream_tbl
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : EXPLAIN output for queryid hive_20220717063639_964690ec-3572-4695-bfdc-c80dac1ccce5 : STAGE DEPENDENCIES:
  Stage-0 is a root stage [MOVE]
  Stage-1 depends on stages: Stage-0 [STATS]

STAGE PLANS:
  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          source: file:/home/hadoop/hive_cs/2019-Nov.csv
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count -1
                column.name.delimiter ,
                columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                columns.comments 
                columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                escapeChar \
                file.inputformat org.apache.hadoop.mapred.TextInputFormat
                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                name clickstream.clickstream_tbl
                numFiles 1
                numRows 0
                quoteChar "
                rawDataSize 0
                separatorChar ,
                serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                skip.header.line.count 1
                totalSize 482542278
                transient_lastDdlTime 1658039782
              serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
              name: clickstream.clickstream_tbl

  Stage: Stage-1
    Stats-Aggr Operator


INFO  : Completed compiling command(queryId=hive_20220717063639_964690ec-3572-4695-bfdc-c80dac1ccce5); Time taken: 0.145 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717063639_964690ec-3572-4695-bfdc-c80dac1ccce5): load data local inpath '/home/hadoop/hive_cs/2019-Nov.csv' into table clickstream_tbl
INFO  : Starting task [Stage-0:MOVE] in serial mode
INFO  : Loading data to table clickstream.clickstream_tbl from file:/home/hadoop/hive_cs/2019-Nov.csv
INFO  : Starting task [Stage-1:STATS] in serial mode
INFO  : Completed executing command(queryId=hive_20220717063639_964690ec-3572-4695-bfdc-c80dac1ccce5); Time taken: 9.134 seconds
INFO  : OK
No rows affected (9.333 seconds)
0: jdbc:hive2://localhost:10000/default> load data local inpath '/home/hadoop/hive_cs/2019-Nov.csv' into table clickstream_tbl;Oct.csv' into table clickstream_tbl;create table if not exists clickstream_tbl(event_time timestamp,event_type string, product_id string, category_id string, category_code string, brand string, price decimal(10,3),user_id bigint, user_session string) row format serde 'org.apache.hadoop.hive.serde2.OpenCSVSerde' WITH SERDEPROPERTIES ( "separatorChar" = ",", "quoteChar" = "\"", "escapeChar" = "\\") stored as textfile TBLPROPERTIES ("skip.header.line.count"="1");TBLPROPERTIES ("skip.header.line.count"="1"));WITH SERDEPROPERTIES ( "separatorChar" = ",", "quoteChar" = "\"", "escapeChar" = "\\") stored as textfile create table if not exists clickstream_tbl(event_time timestamp,event_type string, product_id string, category_id string, category_code string, brand string, price decimal(10,3),user_id bigint, user_session string) row format serde 'org.apache.hadoop.hive.serde2.OpenCSVSerde' show tables;create table if not exists clickstream_tbl(event_time timestamp,event_type string, product_id string, category_id string, category_code string, brand string, price decimal(10,3),user_id bigint, user_session string) row format serde 'org.apache.hadoop.hive.serde2.OpenCSVSerde' show tables;elect * from clickstream_stats order by event_time asc limit 20; order by event_time asc limit 20; order by event_time asc limit 20; order by event_time asc limit 20; order by event_time asc limit 20; order by event_time asc limit 20;t order by event_time asc limit 20;b order by event_time asc limit 20;l order by event_time asc limit 20;
INFO  : Compiling command(queryId=hive_20220717063705_5df8f218-3395-4d8d-b08f-4a6d246d8a3f): select * from clickstream_tbl order by event_time asc limit 20
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:clickstream_tbl.event_time, type:string, comment:null), FieldSchema(name:clickstream_tbl.event_type, type:string, comment:null), FieldSchema(name:clickstream_tbl.product_id, type:string, comment:null), FieldSchema(name:clickstream_tbl.category_id, type:string, comment:null), FieldSchema(name:clickstream_tbl.category_code, type:string, comment:null), FieldSchema(name:clickstream_tbl.brand, type:string, comment:null), FieldSchema(name:clickstream_tbl.price, type:string, comment:null), FieldSchema(name:clickstream_tbl.user_id, type:string, comment:null), FieldSchema(name:clickstream_tbl.user_session, type:string, comment:null)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717063705_5df8f218-3395-4d8d-b08f-4a6d246d8a3f : STAGE DEPENDENCIES:
  Stage-1 is a root stage [MAPRED]
  Stage-0 depends on stages: Stage-1 [FETCH]

STAGE PLANS:
  Stage: Stage-1
    Tez
      DagId: hive_20220717063705_5df8f218-3395-4d8d-b08f-4a6d246d8a3f:5
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
      DagName: 
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: clickstream_tbl
                  Statistics: Num rows: 1142646 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Select Operator
                    expressions: event_time (type: string), event_type (type: string), product_id (type: string), category_id (type: string), category_code (type: string), brand (type: string), price (type: string), user_id (type: string), user_session (type: string)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
                    Statistics: Num rows: 1142646 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: string)
                      null sort order: a
                      sort order: +
                      Statistics: Num rows: 1142646 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                      tag: -1
                      TopN: 20
                      TopN Hash Memory Usage: 0.1
                      value expressions: _col1 (type: string), _col2 (type: string), _col3 (type: string), _col4 (type: string), _col5 (type: string), _col6 (type: string), _col7 (type: string), _col8 (type: string)
                      auto parallelism: false
            Path -> Alias:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl [clickstream_tbl]
            Path -> Partition:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl 
                Partition
                  base file name: clickstream_tbl
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    column.name.delimiter ,
                    columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                    columns.comments 
                    columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                    escapeChar \
                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                    name clickstream.clickstream_tbl
                    numFiles 2
                    numRows 0
                    quoteChar "
                    rawDataSize 0
                    separatorChar ,
                    serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                    skip.header.line.count 1
                    totalSize 1028381690
                    transient_lastDdlTime 1658039808
                  serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      column.name.delimiter ,
                      columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                      columns.comments 
                      columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                      escapeChar \
                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                      name clickstream.clickstream_tbl
                      numFiles 2
                      numRows 0
                      quoteChar "
                      rawDataSize 0
                      separatorChar ,
                      serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                      skip.header.line.count 1
                      totalSize 1028381690
                      transient_lastDdlTime 1658039808
                    serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                    name: clickstream.clickstream_tbl
                  name: clickstream.clickstream_tbl
            Truncated Path -> Alias:
              /clickstream.db/clickstream_tbl [clickstream_tbl]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: string), VALUE._col0 (type: string), VALUE._col1 (type: string), VALUE._col2 (type: string), VALUE._col3 (type: string), VALUE._col4 (type: string), VALUE._col5 (type: string), VALUE._col6 (type: string), VALUE._col7 (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
                Statistics: Num rows: 1142646 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                Limit
                  Number of rows: 20
                  Statistics: Num rows: 20 Data size: 18000 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    GlobalTableId: 0
                    directory: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/c64b26ee-afee-44f3-bde1-17b8435a8c63/hive_2022-07-17_06-37-05_674_3275992589685756299-1/-mr-10001/.hive-staging_hive_2022-07-17_06-37-05_674_3275992589685756299-1/-ext-10002
                    NumFilesPerFileSink: 1
                    Statistics: Num rows: 20 Data size: 18000 Basic stats: COMPLETE Column stats: NONE
                    Stats Publishing Key Prefix: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/c64b26ee-afee-44f3-bde1-17b8435a8c63/hive_2022-07-17_06-37-05_674_3275992589685756299-1/-mr-10001/.hive-staging_hive_2022-07-17_06-37-05_674_3275992589685756299-1/-ext-10002/
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        properties:
                          columns _col0,_col1,_col2,_col3,_col4,_col5,_col6,_col7,_col8
                          columns.types string:string:string:string:string:string:string:string:string
                          escape.delim \
                          hive.serialization.extend.additional.nesting.levels true
                          serialization.escape.crlf true
                          serialization.format 1
                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    TotalFiles: 1
                    GatherStats: false
                    MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: 20
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717063705_5df8f218-3395-4d8d-b08f-4a6d246d8a3f); Time taken: 0.447 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717063705_5df8f218-3395-4d8d-b08f-4a6d246d8a3f): select * from clickstream_tbl order by event_time asc limit 20
INFO  : Query ID = hive_20220717063705_5df8f218-3395-4d8d-b08f-4a6d246d8a3f
INFO  : Total jobs = 1
INFO  : Launching Job 1 out of 1
INFO  : Starting task [Stage-1:MAPRED] in serial mode
INFO  : Session is already open
INFO  : Dag name: select * from clickstream_tbl order by ...20(Stage-1)
INFO  : Tez session was closed. Reopening...
INFO  : Session re-established.
INFO  : Status: Running (Executing on YARN cluster with App id application_1658032091232_0002)

INFO  : Map 1: 0/2Reducer 2: 0/1
INFO  : Map 1: 0/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 1(+1)/2Reducer 2: 0/1
INFO  : Map 1: 1(+1)/2Reducer 2: 0(+1)/1
INFO  : Map 1: 1(+1)/2Reducer 2: 0(+1)/1
INFO  : Map 1: 2/2Reducer 2: 0(+1)/1
INFO  : Map 1: 2/2Reducer 2: 1/1
INFO  : Completed executing command(queryId=hive_20220717063705_5df8f218-3395-4d8d-b08f-4a6d246d8a3f); Time taken: 71.384 seconds
INFO  : OK
+-----------------------------+-----------------------------+-----------------------------+------------------------------+--------------------------------+------------------------+------------------------+--------------------------+---------------------------------------+
| clickstream_tbl.event_time  | clickstream_tbl.event_type  | clickstream_tbl.product_id  | clickstream_tbl.category_id  | clickstream_tbl.category_code  | clickstream_tbl.brand  | clickstream_tbl.price  | clickstream_tbl.user_id  |     clickstream_tbl.user_session      |
+-----------------------------+-----------------------------+-----------------------------+------------------------------+--------------------------------+------------------------+------------------------+--------------------------+---------------------------------------+
| 2019-10-01 00:00:00 UTC     | cart                        | 5773203                     | 1487580005134238553          |                                | runail                 | 2.62                   | 463240011                | 26dd6e6e-4dac-4778-8d2c-92e149dab885  |
| 2019-10-01 00:00:03 UTC     | cart                        | 5773353                     | 1487580005134238553          |                                | runail                 | 2.62                   | 463240011                | 26dd6e6e-4dac-4778-8d2c-92e149dab885  |
| 2019-10-01 00:00:07 UTC     | cart                        | 5723490                     | 1487580005134238553          |                                | runail                 | 2.62                   | 463240011                | 26dd6e6e-4dac-4778-8d2c-92e149dab885  |
| 2019-10-01 00:00:07 UTC     | cart                        | 5881589                     | 2151191071051219817          |                                | lovely                 | 13.48                  | 429681830                | 49e8d843-adf3-428b-a2c3-fe8bc6a307c9  |
| 2019-10-01 00:00:15 UTC     | cart                        | 5881449                     | 1487580013522845895          |                                | lovely                 | 0.56                   | 429681830                | 49e8d843-adf3-428b-a2c3-fe8bc6a307c9  |
| 2019-10-01 00:00:16 UTC     | cart                        | 5857269                     | 1487580005134238553          |                                | runail                 | 2.62                   | 430174032                | 73dea1e7-664e-43f4-8b30-d32b9d5af04f  |
| 2019-10-01 00:00:19 UTC     | cart                        | 5739055                     | 1487580008246412266          |                                | kapous                 | 4.75                   | 377667011                | 81326ac6-daa4-4f0a-b488-fd0956a78733  |
| 2019-10-01 00:00:24 UTC     | cart                        | 5825598                     | 1487580009445982239          |                                |                        | 0.56                   | 467916806                | 2f5b5546-b8cb-9ee7-7ecd-84276f8ef486  |
| 2019-10-01 00:00:25 UTC     | cart                        | 5698989                     | 1487580006317032337          |                                |                        | 1.27                   | 385985999                | d30965e8-1101-44ab-b45d-cc1bb9fae694  |
| 2019-10-01 00:00:26 UTC     | view                        | 5875317                     | 2029082628195353599          |                                |                        | 1.59                   | 474232307                | 445f2b74-5e4c-427e-b7fa-6e0a28b156fe  |
| 2019-10-01 00:00:28 UTC     | view                        | 5692917                     | 1487580004857414477          |                                | lianail                | 5.54                   | 555446068                | 4257671a-efc8-4e58-96c2-3ab457916d78  |
| 2019-10-01 00:00:28 UTC     | remove_from_cart            | 5834172                     | 1487580013522845895          |                                | runail                 | 0.95                   | 429681830                | 49e8d843-adf3-428b-a2c3-fe8bc6a307c9  |
| 2019-10-01 00:00:30 UTC     | remove_from_cart            | 5809103                     | 1487580013522845895          |                                | irisk                  | 0.60                   | 429681830                | 49e8d843-adf3-428b-a2c3-fe8bc6a307c9  |
| 2019-10-01 00:00:30 UTC     | remove_from_cart            | 5809103                     | 1487580013522845895          |                                | irisk                  | 0.60                   | 429681830                | 49e8d843-adf3-428b-a2c3-fe8bc6a307c9  |
| 2019-10-01 00:00:32 UTC     | remove_from_cart            | 5779403                     | 1487580013506068678          |                                |                        | 12.22                  | 429681830                | 49e8d843-adf3-428b-a2c3-fe8bc6a307c9  |
| 2019-10-01 00:00:33 UTC     | remove_from_cart            | 5779403                     | 1487580013506068678          |                                |                        | 12.22                  | 429681830                | 49e8d843-adf3-428b-a2c3-fe8bc6a307c9  |
| 2019-10-01 00:00:34 UTC     | cart                        | 5670337                     | 1752742615205281895          |                                |                        | 2.38                   | 546705258                | 3b5c65c0-bb1c-453b-b340-4ebf973a3136  |
| 2019-10-01 00:00:42 UTC     | cart                        | 5836522                     | 1487580013522845895          |                                | nagaraku               | 0.40                   | 429681830                | 49e8d843-adf3-428b-a2c3-fe8bc6a307c9  |
| 2019-10-01 00:00:43 UTC     | cart                        | 5836522                     | 1487580013522845895          |                                | nagaraku               | 0.40                   | 429681830                | 49e8d843-adf3-428b-a2c3-fe8bc6a307c9  |
| 2019-10-01 00:00:48 UTC     | cart                        | 5859414                     | 1487580005671109489          |                                | masura                 | 2.37                   | 555442940                | 618f3d7d-2939-47ea-8f1d-07a4f97d0fe2  |
+-----------------------------+-----------------------------+-----------------------------+------------------------------+--------------------------------+------------------------+------------------------+--------------------------+---------------------------------------+
20 rows selected (71.886 seconds)
0: jdbc:hive2://localhost:10000/default> select * from clickstream_tbl order by event_time asc limit 20; limit 20; limit 20; limit 20;d limit 20;e limit 20;s limit 20;c limit 20;
INFO  : Compiling command(queryId=hive_20220717063915_38eb60b4-5640-4d97-b0d6-62271c79d04a): select * from clickstream_tbl order by event_time desc limit 20
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:clickstream_tbl.event_time, type:string, comment:null), FieldSchema(name:clickstream_tbl.event_type, type:string, comment:null), FieldSchema(name:clickstream_tbl.product_id, type:string, comment:null), FieldSchema(name:clickstream_tbl.category_id, type:string, comment:null), FieldSchema(name:clickstream_tbl.category_code, type:string, comment:null), FieldSchema(name:clickstream_tbl.brand, type:string, comment:null), FieldSchema(name:clickstream_tbl.price, type:string, comment:null), FieldSchema(name:clickstream_tbl.user_id, type:string, comment:null), FieldSchema(name:clickstream_tbl.user_session, type:string, comment:null)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717063915_38eb60b4-5640-4d97-b0d6-62271c79d04a : STAGE DEPENDENCIES:
  Stage-1 is a root stage [MAPRED]
  Stage-0 depends on stages: Stage-1 [FETCH]

STAGE PLANS:
  Stage: Stage-1
    Tez
      DagId: hive_20220717063915_38eb60b4-5640-4d97-b0d6-62271c79d04a:6
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
      DagName: 
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: clickstream_tbl
                  Statistics: Num rows: 1142646 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Select Operator
                    expressions: event_time (type: string), event_type (type: string), product_id (type: string), category_id (type: string), category_code (type: string), brand (type: string), price (type: string), user_id (type: string), user_session (type: string)
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
                    Statistics: Num rows: 1142646 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: string)
                      null sort order: z
                      sort order: -
                      Statistics: Num rows: 1142646 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                      tag: -1
                      TopN: 20
                      TopN Hash Memory Usage: 0.1
                      value expressions: _col1 (type: string), _col2 (type: string), _col3 (type: string), _col4 (type: string), _col5 (type: string), _col6 (type: string), _col7 (type: string), _col8 (type: string)
                      auto parallelism: false
            Path -> Alias:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl [clickstream_tbl]
            Path -> Partition:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl 
                Partition
                  base file name: clickstream_tbl
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    column.name.delimiter ,
                    columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                    columns.comments 
                    columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                    escapeChar \
                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                    name clickstream.clickstream_tbl
                    numFiles 2
                    numRows 0
                    quoteChar "
                    rawDataSize 0
                    separatorChar ,
                    serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                    skip.header.line.count 1
                    totalSize 1028381690
                    transient_lastDdlTime 1658039808
                  serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      column.name.delimiter ,
                      columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                      columns.comments 
                      columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                      escapeChar \
                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                      name clickstream.clickstream_tbl
                      numFiles 2
                      numRows 0
                      quoteChar "
                      rawDataSize 0
                      separatorChar ,
                      serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                      skip.header.line.count 1
                      totalSize 1028381690
                      transient_lastDdlTime 1658039808
                    serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                    name: clickstream.clickstream_tbl
                  name: clickstream.clickstream_tbl
            Truncated Path -> Alias:
              /clickstream.db/clickstream_tbl [clickstream_tbl]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: string), VALUE._col0 (type: string), VALUE._col1 (type: string), VALUE._col2 (type: string), VALUE._col3 (type: string), VALUE._col4 (type: string), VALUE._col5 (type: string), VALUE._col6 (type: string), VALUE._col7 (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
                Statistics: Num rows: 1142646 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                Limit
                  Number of rows: 20
                  Statistics: Num rows: 20 Data size: 18000 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    GlobalTableId: 0
                    directory: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/c64b26ee-afee-44f3-bde1-17b8435a8c63/hive_2022-07-17_06-39-15_711_943652210305534259-1/-mr-10001/.hive-staging_hive_2022-07-17_06-39-15_711_943652210305534259-1/-ext-10002
                    NumFilesPerFileSink: 1
                    Statistics: Num rows: 20 Data size: 18000 Basic stats: COMPLETE Column stats: NONE
                    Stats Publishing Key Prefix: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/c64b26ee-afee-44f3-bde1-17b8435a8c63/hive_2022-07-17_06-39-15_711_943652210305534259-1/-mr-10001/.hive-staging_hive_2022-07-17_06-39-15_711_943652210305534259-1/-ext-10002/
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        properties:
                          columns _col0,_col1,_col2,_col3,_col4,_col5,_col6,_col7,_col8
                          columns.types string:string:string:string:string:string:string:string:string
                          escape.delim \
                          hive.serialization.extend.additional.nesting.levels true
                          serialization.escape.crlf true
                          serialization.format 1
                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    TotalFiles: 1
                    GatherStats: false
                    MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: 20
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717063915_38eb60b4-5640-4d97-b0d6-62271c79d04a); Time taken: 0.176 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717063915_38eb60b4-5640-4d97-b0d6-62271c79d04a): select * from clickstream_tbl order by event_time desc limit 20
INFO  : Query ID = hive_20220717063915_38eb60b4-5640-4d97-b0d6-62271c79d04a
INFO  : Total jobs = 1
INFO  : Launching Job 1 out of 1
INFO  : Starting task [Stage-1:MAPRED] in serial mode
INFO  : Session is already open
INFO  : Dag name: select * from clickstream_tbl order by ...20(Stage-1)
INFO  : Status: Running (Executing on YARN cluster with App id application_1658032091232_0002)

INFO  : Map 1: 0/2Reducer 2: 0/1
INFO  : Map 1: 0/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 1(+1)/2Reducer 2: 0(+1)/1
INFO  : Map 1: 1(+1)/2Reducer 2: 0(+1)/1
INFO  : Map 1: 2/2Reducer 2: 0(+1)/1
INFO  : Map 1: 2/2Reducer 2: 1/1
INFO  : Completed executing command(queryId=hive_20220717063915_38eb60b4-5640-4d97-b0d6-62271c79d04a); Time taken: 76.203 seconds
INFO  : OK
+-----------------------------+-----------------------------+-----------------------------+------------------------------+--------------------------------+------------------------+------------------------+--------------------------+---------------------------------------+
| clickstream_tbl.event_time  | clickstream_tbl.event_type  | clickstream_tbl.product_id  | clickstream_tbl.category_id  | clickstream_tbl.category_code  | clickstream_tbl.brand  | clickstream_tbl.price  | clickstream_tbl.user_id  |     clickstream_tbl.user_session      |
+-----------------------------+-----------------------------+-----------------------------+------------------------------+--------------------------------+------------------------+------------------------+--------------------------+---------------------------------------+
| 2019-11-30 23:59:58 UTC     | view                        | 5880201                     | 2029731308699124089          |                                | rasyan                 | 3.76                   | 579969854                | e9fa2c3e-8c9e-448c-880a-21ca57c18b3b  |
| 2019-11-30 23:59:57 UTC     | view                        | 5779406                     | 2151191071051219817          |                                |                        | 2.86                   | 540006764                | d4b5aa49-d731-40f1-92f1-277416d6e063  |
| 2019-11-30 23:59:47 UTC     | view                        | 5867785                     | 1487580007835370453          |                                | kims                   | 31.10                  | 572579084                | d42865b7-7e04-4038-9be0-a59165625f06  |
| 2019-11-30 23:59:47 UTC     | view                        | 5733064                     | 1487580004832248652          |                                | beautix                | 9.37                   | 422196217                | ab5e6dd5-8700-4ecc-a300-9f1eca5d1a95  |
| 2019-11-30 23:59:46 UTC     | view                        | 5830317                     | 1487580009496313889          |                                |                        | 4.76                   | 457678989                | ee50b160-a4db-4722-8751-6812c5b38295  |
| 2019-11-30 23:59:37 UTC     | view                        | 5699730                     | 1487580004882580302          |                                |                        | 2.70                   | 422196217                | dd6d8240-0896-4965-9344-110648581a51  |
| 2019-11-30 23:59:32 UTC     | view                        | 5795387                     | 1487580005713052531          |                                | ingarden               | 7.14                   | 576802932                | 2dc9ed07-93bb-47db-abe7-e9d88ed7ae94  |
| 2019-11-30 23:59:27 UTC     | remove_from_cart            | 5801131                     | 1487580005486560104          |                                | irisk                  | 3.65                   | 566513990                | b5053009-b3c4-4581-b05f-6199d1a2037e  |
| 2019-11-30 23:59:27 UTC     | remove_from_cart            | 5801131                     | 1487580005486560104          |                                | irisk                  | 3.65                   | 566513990                | b5053009-b3c4-4581-b05f-6199d1a2037e  |
| 2019-11-30 23:59:25 UTC     | remove_from_cart            | 5810080                     | 1487580005268456287          |                                | irisk                  | 6.51                   | 566513990                | b5053009-b3c4-4581-b05f-6199d1a2037e  |
| 2019-11-30 23:59:25 UTC     | remove_from_cart            | 5810080                     | 1487580005268456287          |                                | irisk                  | 6.51                   | 566513990                | b5053009-b3c4-4581-b05f-6199d1a2037e  |
| 2019-11-30 23:59:25 UTC     | view                        | 5772301                     | 1602943681873052386          |                                | grattol                | 4.76                   | 576005683                | 28172809-7e4a-45ce-bab0-5efa90117cd5  |
| 2019-11-30 23:59:24 UTC     | view                        | 5694628                     | 1487580007835370453          |                                | yoko                   | 3.65                   | 576802932                | f5b0e79b-0470-4256-ba47-4166ea4f05f5  |
| 2019-11-30 23:59:24 UTC     | remove_from_cart            | 5608703                     | 1487580005553668971          |                                |                        | 9.52                   | 566513990                | b5053009-b3c4-4581-b05f-6199d1a2037e  |
| 2019-11-30 23:59:24 UTC     | remove_from_cart            | 5608703                     | 1487580005553668971          |                                |                        | 9.52                   | 566513990                | b5053009-b3c4-4581-b05f-6199d1a2037e  |
| 2019-11-30 23:59:22 UTC     | cart                        | 5839649                     | 1487580005671109489          |                                | masura                 | 2.37                   | 475720349                | d2ec1d29-88d9-40b5-98e2-ffdac2a832cd  |
| 2019-11-30 23:59:22 UTC     | view                        | 5650610                     | 1487580007835370453          |                                | metzger                | 4.84                   | 576802932                | 64c39ba7-5018-4009-ac30-fa04bdabc434  |
| 2019-11-30 23:59:20 UTC     | view                        | 5692261                     | 1487580007835370453          |                                | staleks                | 6.35                   | 576802932                | 495159b1-ab2a-4daa-901f-5889da3905a3  |
| 2019-11-30 23:59:18 UTC     | view                        | 5801125                     | 1487580005486560104          |                                | irisk                  | 3.65                   | 566513990                | b5053009-b3c4-4581-b05f-6199d1a2037e  |
| 2019-11-30 23:59:18 UTC     | cart                        | 5705002                     | 1487580006551913373          |                                | irisk                  | 3.33                   | 494077766                | c99a50e8-2fac-4c4d-89ec-41c05f114554  |
+-----------------------------+-----------------------------+-----------------------------+------------------------------+--------------------------------+------------------------+------------------------+--------------------------+---------------------------------------+
20 rows selected (76.4 seconds)
0: jdbc:hive2://localhost:10000/default> select distinct(countcountcount(distinct event_timeype from clicksterream_tbl;
INFO  : Compiling command(queryId=hive_20220717065654_6b50cc64-53b3-41d5-916e-252f222abc6f): select distinct event_type from clickstream_tbl
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:event_type, type:string, comment:null)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717065654_6b50cc64-53b3-41d5-916e-252f222abc6f : STAGE DEPENDENCIES:
  Stage-1 is a root stage [MAPRED]
  Stage-0 depends on stages: Stage-1 [FETCH]

STAGE PLANS:
  Stage: Stage-1
    Tez
      DagId: hive_20220717065654_6b50cc64-53b3-41d5-916e-252f222abc6f:7
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
      DagName: 
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: clickstream_tbl
                  Statistics: Num rows: 10283816 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Select Operator
                    expressions: event_type (type: string)
                    outputColumnNames: event_type
                    Statistics: Num rows: 10283816 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      keys: event_type (type: string)
                      mode: hash
                      outputColumnNames: _col0
                      Statistics: Num rows: 10283816 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: string)
                        null sort order: a
                        sort order: +
                        Map-reduce partition columns: _col0 (type: string)
                        Statistics: Num rows: 10283816 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                        tag: -1
                        auto parallelism: true
            Path -> Alias:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl [clickstream_tbl]
            Path -> Partition:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl 
                Partition
                  base file name: clickstream_tbl
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    column.name.delimiter ,
                    columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                    columns.comments 
                    columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                    escapeChar \
                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                    name clickstream.clickstream_tbl
                    numFiles 2
                    numRows 0
                    quoteChar "
                    rawDataSize 0
                    separatorChar ,
                    serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                    skip.header.line.count 1
                    totalSize 1028381690
                    transient_lastDdlTime 1658039808
                  serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      column.name.delimiter ,
                      columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                      columns.comments 
                      columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                      escapeChar \
                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                      name clickstream.clickstream_tbl
                      numFiles 2
                      numRows 0
                      quoteChar "
                      rawDataSize 0
                      separatorChar ,
                      serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                      skip.header.line.count 1
                      totalSize 1028381690
                      transient_lastDdlTime 1658039808
                    serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                    name: clickstream.clickstream_tbl
                  name: clickstream.clickstream_tbl
            Truncated Path -> Alias:
              /clickstream.db/clickstream_tbl [clickstream_tbl]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Group By Operator
                keys: KEY._col0 (type: string)
                mode: mergepartial
                outputColumnNames: _col0
                Statistics: Num rows: 5141908 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
                  directory: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/c64b26ee-afee-44f3-bde1-17b8435a8c63/hive_2022-07-17_06-56-54_548_2380687005490274306-1/-mr-10001/.hive-staging_hive_2022-07-17_06-56-54_548_2380687005490274306-1/-ext-10002
                  NumFilesPerFileSink: 1
                  Statistics: Num rows: 5141908 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                  Stats Publishing Key Prefix: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/c64b26ee-afee-44f3-bde1-17b8435a8c63/hive_2022-07-17_06-56-54_548_2380687005490274306-1/-mr-10001/.hive-staging_hive_2022-07-17_06-56-54_548_2380687005490274306-1/-ext-10002/
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      properties:
                        columns _col0
                        columns.types string
                        escape.delim \
                        hive.serialization.extend.additional.nesting.levels true
                        serialization.escape.crlf true
                        serialization.format 1
                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  TotalFiles: 1
                  GatherStats: false
                  MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717065654_6b50cc64-53b3-41d5-916e-252f222abc6f); Time taken: 0.244 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717065654_6b50cc64-53b3-41d5-916e-252f222abc6f): select distinct event_type from clickstream_tbl
INFO  : Query ID = hive_20220717065654_6b50cc64-53b3-41d5-916e-252f222abc6f
INFO  : Total jobs = 1
INFO  : Launching Job 1 out of 1
INFO  : Starting task [Stage-1:MAPRED] in serial mode
INFO  : Session is already open
INFO  : Dag name: select distinct event_type...clickstream_tbl(Stage-1)
INFO  : Tez session was closed. Reopening...
INFO  : Session re-established.
INFO  : Status: Running (Executing on YARN cluster with App id application_1658032091232_0003)

INFO  : Map 1: 0/2Reducer 2: 0/10
INFO  : Map 1: 0/2Reducer 2: 0/10
INFO  : Map 1: 0(+1)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 1(+1)/2Reducer 2: 0/10
INFO  : Map 1: 1(+1)/2Reducer 2: 0/10
INFO  : Map 1: 2/2Reducer 2: 0/1
INFO  : Map 1: 2/2Reducer 2: 0(+1)/1
INFO  : Map 1: 2/2Reducer 2: 1/1
INFO  : Completed executing command(queryId=hive_20220717065654_6b50cc64-53b3-41d5-916e-252f222abc6f); Time taken: 64.031 seconds
INFO  : OK
+-------------------+
|    event_type     |
+-------------------+
| cart              |
| purchase          |
| remove_from_cart  |
| view              |
+-------------------+
4 rows selected (64.303 seconds)
0: jdbc:hive2://localhost:10000/default> create table set hive.exec.dynamic.partition = trueue;
No rows affected (0.005 seconds)
0: jdbc:hive2://localhost:10000/default> set hive.exec.dynamic.partition.mode = nonstirict;
No rows affected (0.004 seconds)
0: jdbc:hive2://localhost:10000/default> set hive.enforce.bucketing = true;
No rows affected (0.004 seconds)
0: jdbc:hive2://localhost:10000/default> create external table if not exists part_type_bucket_monthnth_tbl(event_time str ing,event_type string,product_id string,category_id string,category_code string,brand string,price string,user_id str ing,user_session string,user_session string,user_session string,user_session string, user_session string,u ser_session string,us er_session stringb,u ser_session stringi, user_session stringg,user_session stringi,user_session stringn,user_session stringt,user_session string,user_id bigi nt,user_session string,user_id bigin t,user_session string,user_id bigint ,user_session string,user_id bigint, user_session string,user_id bigint,u ser_session string,user_id bigint,us er_session stringd,user_id bigint,u ser_session stringe,user_id bigint, user_session stringc,user_id bigint ,user_session stringi,user_id bigin t,user_session stringm,user_id bigi nt,user_session stringa,user_id big int,user_session stringl,user_id bi gint,user_session string(,user_id b igint,user_session string1,user_id  bigint,user_session string0,user_id  bigint,user_session string,,user_i d bigint,user_session string3,user_ id bigint,user_session string),user _id bigint,user_session string)p partitioned by (event_timeype) clustered by (mnth int) into 2 buckets row format SERDE  ' org.apache.hadoop.hive.serde2.OpenCSVSerde' stored as textfile;
Error: Error while compiling statement: FAILED: ParseException line 1:251 cannot recognize input near ')' 'clustered' 'by' in column type (state=42000,code=40000)
0: jdbc:hive2://localhost:10000/default> create external table if not exists part_type_bucket_mnth_tbl(event_time string,event_type string,product_id string,category_id string,category_code string,brand string,price decimal(10,3),user_id bigint,user_session string) partitioned by (event_type) clustered by (mnth int) into 2 buckets row format SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' stored as textfile; ) clustered by (mnth int) into 2 buckets row format SERDE  'org.apache.hadoop.hive.serde2.OpenCSVSerde' stored as textfile;s) clustered by (mnth int) into 2 buckets row format SERDE  'org.apache.hadoop.hive.serde2.OpenCSVSerde' stored as textfile;t) clustered by (mnth int) into 2 buckets row format SERD E 'org.apache.hadoop.hive.serde2.OpenCSVSerde' stored as textfile;r) clustered by (mnth int) into 2 buckets row format SER DE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' stored as textfile;i) clustered by (mnth int) into 2 buckets row format SE RDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' stored as textfile;n) clustered by (mnth int) into 2 buckets row format S ERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' stored as textfile;g) clustered by (mnth int) into 2 buckets row format  SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' stored as textfile;) into 2 buckets row format S ERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' stored as textfile;) into 2 buckets row format SE RDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' stored as textfile;) into 2 buckets row format SER DE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' stored as textfile;) into 2 buckets row format SERD E 'org.apache.hadoop.hive.serde2.OpenCSVSerde' stored as textfile;
Error: Error while compiling statement: FAILED: SemanticException [Error 10002]: Invalid column reference  'mnth' (state=42000,code=10002)
0: jdbc:hive2://localhost:10000/default> create external table if not exists part_type_bucket_mnth_tbl(event_time string,event_type string,product_id string,category_id string,category_code string,brand string,price decimal(10,3),user_id bigint,user_session string) partitioned by (event_type string) clustered by (mnth) into 2 buckets row format SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' stored as textfile; ) into 2 buckets row format SER DE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' stored as textfile;i) into 2 buckets row format SE RDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' stored as textfile;n) into 2 buckets row format S ERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' stored as textfile;t) into 2 buckets row format  SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' stored as textfile;
Error: Error while compiling statement: FAILED: ParseException line 1:279 extraneous input 'int' expecting ) near '<EOF>' (state=42000,code=40000)
0: jdbc:hive2://localhost:10000/default> create table if not exists part_mnth_buck_type_tbl(event_time string,event_t ype string,product_id string,category_id string,category_code string,brand string,price string,user_id string,user_se ssion string) partitioned by (mnth int) clustered by (event_type) into 4 buckets row format SERDE 'org.apache.hadoop. hive.serde2.OpenCSVSerde' stored as textfile;
INFO  : Compiling command(queryId=hive_20220717070839_b9667444-555f-43da-bedb-04248cf0e50c): create table if not exists part_mnth_buck_type_tbl(event_time string,event_type string,product_id string,category_id string,category_code string,brand string,price string,user_id string,user_session string) partitioned by (mnth int) clustered by (event_type) into 4 buckets row format SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' stored as textfile
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : EXPLAIN output for queryid hive_20220717070839_b9667444-555f-43da-bedb-04248cf0e50c : STAGE DEPENDENCIES:
  Stage-0 is a root stage [DDL]

STAGE PLANS:
  Stage: Stage-0
      Create Table Operator:
        Create Table
          bucket columns: event_type
          columns: event_time string, event_type string, product_id string, category_id string, category_code string, brand string, price string, user_id string, user_session string
          if not exists: true
          input format: org.apache.hadoop.mapred.TextInputFormat
          # buckets: 4
          output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
          partition columns: mnth int
          serde name: org.apache.hadoop.hive.serde2.OpenCSVSerde
          name: clickstream.part_mnth_buck_type_tbl


INFO  : Completed compiling command(queryId=hive_20220717070839_b9667444-555f-43da-bedb-04248cf0e50c); Time taken: 0.043 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717070839_b9667444-555f-43da-bedb-04248cf0e50c): create table if not exists part_mnth_buck_type_tbl(event_time string,event_type string,product_id string,category_id string,category_code string,brand string,price string,user_id string,user_session string) partitioned by (mnth int) clustered by (event_type) into 4 buckets row format SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' stored as textfile
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20220717070839_b9667444-555f-43da-bedb-04248cf0e50c); Time taken: 0.11 seconds
INFO  : OK
No rows affected (0.162 seconds)
0: jdbc:hive2://localhost:10000/default> show tablesshow tables;
INFO  : Compiling command(queryId=hive_20220717070857_8dd991d3-ef21-4ed2-83db-56c091248144): show tables
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:tab_name, type:string, comment:from deserializer)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717070857_8dd991d3-ef21-4ed2-83db-56c091248144 : STAGE DEPENDENCIES:
  Stage-0 is a root stage [DDL]
  Stage-1 depends on stages: Stage-0 [FETCH]

STAGE PLANS:
  Stage: Stage-0
      Show Table Operator:
        Show Tables
          database name: clickstream
          result file: file:/mnt/tmp/hive/c64b26ee-afee-44f3-bde1-17b8435a8c63/hive_2022-07-17_07-08-57_600_3313906842016533558-1/-local-10000

  Stage: Stage-1
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717070857_8dd991d3-ef21-4ed2-83db-56c091248144); Time taken: 0.03 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717070857_8dd991d3-ef21-4ed2-83db-56c091248144): show tables
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20220717070857_8dd991d3-ef21-4ed2-83db-56c091248144); Time taken: 0.03 seconds
INFO  : OK
+--------------------------+
|         tab_name         |
+--------------------------+
| clickstream_stats        |
| clickstream_tbl          |
| part_mnth_buck_type_tbl  |
+--------------------------+
3 rows selected (0.096 seconds)
0: jdbc:hive2://localhost:10000/default> drop table partparti
partial     partition   
0: jdbc:hive2://localhost:10000/default> drop table parti_mnth_buck_type_tbl;
INFO  : Compiling command(queryId=hive_20220717070915_444530a1-7c07-4a0a-8e1e-ed7992d5254c): drop table part_mnth_buck_type_tbl
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : EXPLAIN output for queryid hive_20220717070915_444530a1-7c07-4a0a-8e1e-ed7992d5254c : STAGE DEPENDENCIES:
  Stage-0 is a root stage [DDL]

STAGE PLANS:
  Stage: Stage-0
      Drop Table Operator:
        Drop Table
          table: part_mnth_buck_type_tbl


INFO  : Completed compiling command(queryId=hive_20220717070915_444530a1-7c07-4a0a-8e1e-ed7992d5254c); Time taken: 0.035 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717070915_444530a1-7c07-4a0a-8e1e-ed7992d5254c): drop table part_mnth_buck_type_tbl
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20220717070915_444530a1-7c07-4a0a-8e1e-ed7992d5254c); Time taken: 0.193 seconds
INFO  : OK
No rows affected (0.24 seconds)
0: jdbc:hive2://localhost:10000/default> drop table part_mnth_buck_type_tbl;show tables;
INFO  : Compiling command(queryId=hive_20220717070918_47586940-c4b7-4f12-b0f2-7fdef86ade3e): show tables
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:tab_name, type:string, comment:from deserializer)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717070918_47586940-c4b7-4f12-b0f2-7fdef86ade3e : STAGE DEPENDENCIES:
  Stage-0 is a root stage [DDL]
  Stage-1 depends on stages: Stage-0 [FETCH]

STAGE PLANS:
  Stage: Stage-0
      Show Table Operator:
        Show Tables
          database name: clickstream
          result file: file:/mnt/tmp/hive/c64b26ee-afee-44f3-bde1-17b8435a8c63/hive_2022-07-17_07-09-18_544_3822086006560156781-1/-local-10000

  Stage: Stage-1
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717070918_47586940-c4b7-4f12-b0f2-7fdef86ade3e); Time taken: 0.022 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717070918_47586940-c4b7-4f12-b0f2-7fdef86ade3e): show tables
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20220717070918_47586940-c4b7-4f12-b0f2-7fdef86ade3e); Time taken: 0.018 seconds
INFO  : OK
+--------------------+
|      tab_name      |
+--------------------+
| clickstream_stats  |
| clickstream_tbl    |
+--------------------+
2 rows selected (0.054 seconds)
0: jdbc:hive2://localhost:10000/default> create table if not exists part_mnth_buck_type_tbl(event_time string,event_t ype string,product_id string,category_id string,category_code string,brand string,price decimal(10,3),user_id bigint, user_session string) partitioned by (mnth int) clustered by (event_type) into 4 buckets row format SERDE 'org.apache. hadoop.hive.serde2.OpenCSVSerde' stored as textfile;
INFO  : Compiling command(queryId=hive_20220717070948_1dc80be6-8c64-48bf-a369-07f576d028b2): create table if not exists part_mnth_buck_type_tbl(event_time string,event_type string,product_id string,category_id string,category_code string,brand string,price decimal(10,3),user_id bigint,user_session string) partitioned by (mnth int) clustered by (event_type) into 4 buckets row format SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' stored as textfile
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : EXPLAIN output for queryid hive_20220717070948_1dc80be6-8c64-48bf-a369-07f576d028b2 : STAGE DEPENDENCIES:
  Stage-0 is a root stage [DDL]

STAGE PLANS:
  Stage: Stage-0
      Create Table Operator:
        Create Table
          bucket columns: event_type
          columns: event_time string, event_type string, product_id string, category_id string, category_code string, brand string, price decimal(10,3), user_id bigint, user_session string
          if not exists: true
          input format: org.apache.hadoop.mapred.TextInputFormat
          # buckets: 4
          output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
          partition columns: mnth int
          serde name: org.apache.hadoop.hive.serde2.OpenCSVSerde
          name: clickstream.part_mnth_buck_type_tbl


INFO  : Completed compiling command(queryId=hive_20220717070948_1dc80be6-8c64-48bf-a369-07f576d028b2); Time taken: 0.024 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717070948_1dc80be6-8c64-48bf-a369-07f576d028b2): create table if not exists part_mnth_buck_type_tbl(event_time string,event_type string,product_id string,category_id string,category_code string,brand string,price decimal(10,3),user_id bigint,user_session string) partitioned by (mnth int) clustered by (event_type) into 4 buckets row format SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' stored as textfile
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20220717070948_1dc80be6-8c64-48bf-a369-07f576d028b2); Time taken: 0.057 seconds
INFO  : OK
No rows affected (0.091 seconds)
0: jdbc:hive2://localhost:10000/default> insert into table part_mnth_buck_type_tbl partition(mnth) select *,month(eve nt_time) as mnth from clickstream_stats where month(event_time) in (10,11);
INFO  : Compiling command(queryId=hive_20220717071042_72a14924-784d-4666-ae8c-11dd705f015c): insert into table part_mnth_buck_type_tbl partition(mnth) select *,month(event_time) as mnth from clickstream_stats where month(event_time) in (10,11)
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:clickstream_stats.event_time, type:string, comment:null), FieldSchema(name:clickstream_stats.event_type, type:string, comment:null), FieldSchema(name:clickstream_stats.product_id, type:string, comment:null), FieldSchema(name:clickstream_stats.category_id, type:string, comment:null), FieldSchema(name:clickstream_stats.category_code, type:string, comment:null), FieldSchema(name:clickstream_stats.brand, type:string, comment:null), FieldSchema(name:clickstream_stats.price, type:string, comment:null), FieldSchema(name:clickstream_stats.user_id, type:string, comment:null), FieldSchema(name:clickstream_stats.user_session, type:string, comment:null), FieldSchema(name:mnth, type:int, comment:null)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717071042_72a14924-784d-4666-ae8c-11dd705f015c : STAGE DEPENDENCIES:
  Stage-1 is a root stage [MAPRED]
  Stage-2 depends on stages: Stage-1 [DEPENDENCY_COLLECTION]
  Stage-0 depends on stages: Stage-2 [MOVE]
  Stage-3 depends on stages: Stage-0 [STATS]

STAGE PLANS:
  Stage: Stage-1
    Tez
      DagId: hive_20220717071042_72a14924-784d-4666-ae8c-11dd705f015c:8
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
      DagName: 
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: clickstream_stats
                  Statistics: Num rows: 1142646 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: (month(event_time)) IN (10, 11) (type: boolean)
                    Statistics: Num rows: 571323 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: event_time (type: string), event_type (type: string), product_id (type: string), category_id (type: string), category_code (type: string), brand (type: string), price (type: string), user_id (type: string), user_session (type: string), month(event_time) (type: int)
                      outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9
                      Statistics: Num rows: 571323 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col9 (type: int), '_bucket_number' (type: string)
                        null sort order: aa
                        sort order: ++
                        Map-reduce partition columns: _col9 (type: int)
                        Statistics: Num rows: 571323 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                        tag: -1
                        value expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string), _col3 (type: string), _col4 (type: string), _col5 (type: string), _col6 (type: string), _col7 (type: string), _col8 (type: string)
                        auto parallelism: true
            Path -> Alias:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_stats [clickstream_stats]
            Path -> Partition:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_stats 
                Partition
                  base file name: clickstream_stats
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    column.name.delimiter ,
                    columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                    columns.comments 
                    columns.types string:string:string:string:string:string:string:string:string
                    field.delim ,
                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    line.delim 

                    location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_stats
                    name clickstream.clickstream_stats
                    numFiles 2
                    numRows 0
                    rawDataSize 0
                    serialization.ddl struct clickstream_stats { string event_time, string event_type, string product_id, string category_id, string category_code, string brand, string price, string user_id, string user_session}
                    serialization.format ,
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 1028381690
                    transient_lastDdlTime 1658036994
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      column.name.delimiter ,
                      columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                      columns.comments 
                      columns.types string:string:string:string:string:string:string:string:string
                      field.delim ,
                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      line.delim 

                      location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_stats
                      name clickstream.clickstream_stats
                      numFiles 2
                      numRows 0
                      rawDataSize 0
                      serialization.ddl struct clickstream_stats { string event_time, string event_type, string product_id, string category_id, string category_code, string brand, string price, string user_id, string user_session}
                      serialization.format ,
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      totalSize 1028381690
                      transient_lastDdlTime 1658036994
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: clickstream.clickstream_stats
                  name: clickstream.clickstream_stats
            Truncated Path -> Alias:
              /clickstream.db/clickstream_stats [clickstream_stats]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: string), VALUE._col1 (type: string), VALUE._col2 (type: string), VALUE._col3 (type: string), VALUE._col4 (type: string), VALUE._col5 (type: string), VALUE._col6 (type: string), VALUE._col7 (type: string), VALUE._col8 (type: string), KEY._col9 (type: int), KEY.'_bucket_number' (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, '_bucket_number'
                Statistics: Num rows: 571323 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  GlobalTableId: 1
                  directory: hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl/.hive-staging_hive_2022-07-17_07-10-42_039_3342112967386627911-1/-ext-10000
                  Dp Sort State: PARTITION_BUCKET_SORTED
                  NumFilesPerFileSink: 1
                  Statistics: Num rows: 571323 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                  Stats Publishing Key Prefix: hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl/.hive-staging_hive_2022-07-17_07-10-42_039_3342112967386627911-1/-ext-10000/
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      properties:
                        bucket_count 4
                        bucket_field_name event_type
                        column.name.delimiter ,
                        columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                        columns.comments 
                        columns.types string:string:string:string:string:string:decimal(10,3):bigint:string
                        file.inputformat org.apache.hadoop.mapred.TextInputFormat
                        file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                        location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl
                        name clickstream.part_mnth_buck_type_tbl
                        partition_columns mnth
                        partition_columns.types int
                        serialization.ddl struct part_mnth_buck_type_tbl { string event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                        serialization.format 1
                        serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                        transient_lastDdlTime 1658041789
                      serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                      name: clickstream.part_mnth_buck_type_tbl
                  TotalFiles: 1
                  GatherStats: true
                  MultiFileSpray: false

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          partition:
            mnth 
          replace: false
          source: hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl/.hive-staging_hive_2022-07-17_07-10-42_039_3342112967386627911-1/-ext-10000
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count 4
                bucket_field_name event_type
                column.name.delimiter ,
                columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                columns.comments 
                columns.types string:string:string:string:string:string:decimal(10,3):bigint:string
                file.inputformat org.apache.hadoop.mapred.TextInputFormat
                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl
                name clickstream.part_mnth_buck_type_tbl
                partition_columns mnth
                partition_columns.types int
                serialization.ddl struct part_mnth_buck_type_tbl { string event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                transient_lastDdlTime 1658041789
              serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
              name: clickstream.part_mnth_buck_type_tbl

  Stage: Stage-3
    Stats-Aggr Operator
      Stats Aggregation Key Prefix: hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl/.hive-staging_hive_2022-07-17_07-10-42_039_3342112967386627911-1/-ext-10000/


INFO  : Completed compiling command(queryId=hive_20220717071042_72a14924-784d-4666-ae8c-11dd705f015c); Time taken: 0.745 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717071042_72a14924-784d-4666-ae8c-11dd705f015c): insert into table part_mnth_buck_type_tbl partition(mnth) select *,month(event_time) as mnth from clickstream_stats where month(event_time) in (10,11)
INFO  : Query ID = hive_20220717071042_72a14924-784d-4666-ae8c-11dd705f015c
INFO  : Total jobs = 1
INFO  : Launching Job 1 out of 1
INFO  : Starting task [Stage-1:MAPRED] in serial mode
INFO  : Session is already open
INFO  : Dag name: insert into table part_mnth_buck_t...(10,11)(Stage-1)
INFO  : Tez session was closed. Reopening...
INFO  : Session re-established.
INFO  : Status: Running (Executing on YARN cluster with App id application_1658032091232_0004)

INFO  : Map 1: 0/8Reducer 2: 0/6
INFO  : Map 1: 0/8Reducer 2: 0/6
INFO  : Map 1: 0/8Reducer 2: 0/6
INFO  : Map 1: 0(+1)/8Reducer 2: 0/6
INFO  : Map 1: 0(+2)/8Reducer 2: 0/6
INFO  : Map 1: 0(+3)/8Reducer 2: 0/6
INFO  : Map 1: 0(+3)/8Reducer 2: 0/6
INFO  : Map 1: 0(+3)/8Reducer 2: 0/6
INFO  : Map 1: 0(+3)/8Reducer 2: 0/6
INFO  : Map 1: 0(+3)/8Reducer 2: 0/6
INFO  : Map 1: 0(+3)/8Reducer 2: 0/6
INFO  : Map 1: 0(+3)/8Reducer 2: 0/6
INFO  : Map 1: 0(+3)/8Reducer 2: 0/6
INFO  : Map 1: 0(+3)/8Reducer 2: 0/6
INFO  : Map 1: 0(+3)/8Reducer 2: 0/6
INFO  : Map 1: 0(+3)/8Reducer 2: 0/6
INFO  : Map 1: 0(+3)/8Reducer 2: 0/6
INFO  : Map 1: 1(+2)/8Reducer 2: 0/6
INFO  : Map 1: 1(+3)/8Reducer 2: 0/6
INFO  : Map 1: 2(+3)/8Reducer 2: 0/6
INFO  : Map 1: 3(+3)/8Reducer 2: 0/6
INFO  : Map 1: 3(+3)/8Reducer 2: 0/6
INFO  : Map 1: 3(+3)/8Reducer 2: 0/6
INFO  : Map 1: 3(+3)/8Reducer 2: 0/6
INFO  : Map 1: 3(+3)/8Reducer 2: 0/6
INFO  : Map 1: 3(+3)/8Reducer 2: 0/6
INFO  : Map 1: 3(+3)/8Reducer 2: 0/6
INFO  : Map 1: 3(+3)/8Reducer 2: 0/6
INFO  : Map 1: 4(+2)/8Reducer 2: 0/6
INFO  : Map 1: 5(+1)/8Reducer 2: 0/6
INFO  : Map 1: 6(+1)/8Reducer 2: 0/6
INFO  : Map 1: 6(+2)/8Reducer 2: 0/6
INFO  : Map 1: 6(+2)/8Reducer 2: 0(+1)/6
INFO  : Map 1: 6(+2)/8Reducer 2: 0(+1)/6
INFO  : Map 1: 6(+2)/8Reducer 2: 0(+1)/6
INFO  : Map 1: 6(+2)/8Reducer 2: 0(+1)/6
INFO  : Map 1: 7(+1)/8Reducer 2: 0(+2)/6
INFO  : Map 1: 8/8Reducer 2: 0(+3)/6
INFO  : Map 1: 8/8Reducer 2: 0(+3)/6
INFO  : Map 1: 8/8Reducer 2: 0(+3)/6
INFO  : Map 1: 8/8Reducer 2: 0(+3)/6
INFO  : Map 1: 8/8Reducer 2: 0(+3)/6
INFO  : Map 1: 8/8Reducer 2: 0(+3)/6
INFO  : Map 1: 8/8Reducer 2: 0(+3)/6
INFO  : Map 1: 8/8Reducer 2: 0(+3)/6
INFO  : Map 1: 8/8Reducer 2: 0(+3)/6
INFO  : Map 1: 8/8Reducer 2: 0(+3)/6
INFO  : Map 1: 8/8Reducer 2: 0(+3)/6
INFO  : Map 1: 8/8Reducer 2: 0(+3)/6
INFO  : Map 1: 8/8Reducer 2: 1(+3)/6
INFO  : Map 1: 8/8Reducer 2: 1(+3)/6
INFO  : Map 1: 8/8Reducer 2: 1(+3)/6
INFO  : Map 1: 8/8Reducer 2: 1(+3)/6
INFO  : Map 1: 8/8Reducer 2: 1(+3)/6
INFO  : Map 1: 8/8Reducer 2: 1(+3)/6
INFO  : Map 1: 8/8Reducer 2: 1(+3)/6
INFO  : Map 1: 8/8Reducer 2: 1(+3)/6
INFO  : Map 1: 8/8Reducer 2: 2(+3)/6
INFO  : Map 1: 8/8Reducer 2: 3(+3)/6
INFO  : Map 1: 8/8Reducer 2: 4(+2)/6
INFO  : Map 1: 8/8Reducer 2: 4(+2)/6
INFO  : Map 1: 8/8Reducer 2: 4(+2)/6
INFO  : Map 1: 8/8Reducer 2: 4(+2)/6
INFO  : Map 1: 8/8Reducer 2: 4(+2)/6
INFO  : Map 1: 8/8Reducer 2: 4(+2)/6
INFO  : Map 1: 8/8Reducer 2: 4(+2)/6
INFO  : Map 1: 8/8Reducer 2: 5(+1)/6
INFO  : Map 1: 8/8Reducer 2: 6/6
INFO  : Starting task [Stage-2:DEPENDENCY_COLLECTION] in serial mode
INFO  : Starting task [Stage-0:MOVE] in serial mode
INFO  : Loading data to table clickstream.part_mnth_buck_type_tbl partition (mnth=null) from hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl/.hive-staging_hive_2022-07-17_07-10-42_039_3342112967386627911-1/-ext-10000
INFO  : 

INFO  :  Time taken to load dynamic partitions: 0.249 seconds
INFO  :  Time taken for adding to write entity : 0.005 seconds
INFO  : Starting task [Stage-3:STATS] in serial mode
INFO  : Completed executing command(queryId=hive_20220717071042_72a14924-784d-4666-ae8c-11dd705f015c); Time taken: 168.804 seconds
INFO  : OK
No rows affected (169.572 seconds)
0: jdbc:hive2://localhost:10000/default> select *select * from part_mnth_buck_type_tbl limit 5;
INFO  : Compiling command(queryId=hive_20220717071519_c38fe826-2084-4e15-bc4a-3f9422bc75d4): select * from part_mnth_buck_type_tbl limit 5
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:part_mnth_buck_type_tbl.event_time, type:string, comment:null), FieldSchema(name:part_mnth_buck_type_tbl.event_type, type:string, comment:null), FieldSchema(name:part_mnth_buck_type_tbl.product_id, type:string, comment:null), FieldSchema(name:part_mnth_buck_type_tbl.category_id, type:string, comment:null), FieldSchema(name:part_mnth_buck_type_tbl.category_code, type:string, comment:null), FieldSchema(name:part_mnth_buck_type_tbl.brand, type:string, comment:null), FieldSchema(name:part_mnth_buck_type_tbl.price, type:string, comment:null), FieldSchema(name:part_mnth_buck_type_tbl.user_id, type:string, comment:null), FieldSchema(name:part_mnth_buck_type_tbl.user_session, type:string, comment:null), FieldSchema(name:part_mnth_buck_type_tbl.mnth, type:int, comment:null)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717071519_c38fe826-2084-4e15-bc4a-3f9422bc75d4 : STAGE DEPENDENCIES:
  Stage-0 is a root stage [FETCH]

STAGE PLANS:
  Stage: Stage-0
    Fetch Operator
      limit: 5
      Partition Description:
          Partition
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            partition values:
              mnth 10
            properties:
              COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
              bucket_count 4
              bucket_field_name event_type
              column.name.delimiter ,
              columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
              columns.comments 
              columns.types string:string:string:string:string:string:decimal(10,3):bigint:string
              file.inputformat org.apache.hadoop.mapred.TextInputFormat
              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl/mnth=10
              name clickstream.part_mnth_buck_type_tbl
              numFiles 3
              numRows 4102283
              partition_columns mnth
              partition_columns.types int
              rawDataSize 0
              serialization.ddl struct part_mnth_buck_type_tbl { string event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
              totalSize 556383280
              transient_lastDdlTime 1658042010
            serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count 4
                bucket_field_name event_type
                column.name.delimiter ,
                columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                columns.comments 
                columns.types string:string:string:string:string:string:decimal(10,3):bigint:string
                file.inputformat org.apache.hadoop.mapred.TextInputFormat
                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl
                name clickstream.part_mnth_buck_type_tbl
                partition_columns mnth
                partition_columns.types int
                serialization.ddl struct part_mnth_buck_type_tbl { string event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                transient_lastDdlTime 1658041789
              serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
              name: clickstream.part_mnth_buck_type_tbl
            name: clickstream.part_mnth_buck_type_tbl
          Partition
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            partition values:
              mnth 11
            properties:
              COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
              bucket_count 4
              bucket_field_name event_type
              column.name.delimiter ,
              columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
              columns.comments 
              columns.types string:string:string:string:string:string:decimal(10,3):bigint:string
              file.inputformat org.apache.hadoop.mapred.TextInputFormat
              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl/mnth=11
              name clickstream.part_mnth_buck_type_tbl
              numFiles 3
              numRows 4635837
              partition_columns mnth
              partition_columns.types int
              rawDataSize 0
              serialization.ddl struct part_mnth_buck_type_tbl { string event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
              totalSize 629284386
              transient_lastDdlTime 1658042011
            serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count 4
                bucket_field_name event_type
                column.name.delimiter ,
                columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                columns.comments 
                columns.types string:string:string:string:string:string:decimal(10,3):bigint:string
                file.inputformat org.apache.hadoop.mapred.TextInputFormat
                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl
                name clickstream.part_mnth_buck_type_tbl
                partition_columns mnth
                partition_columns.types int
                serialization.ddl struct part_mnth_buck_type_tbl { string event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                transient_lastDdlTime 1658041789
              serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
              name: clickstream.part_mnth_buck_type_tbl
            name: clickstream.part_mnth_buck_type_tbl
      Processor Tree:
        TableScan
          alias: part_mnth_buck_type_tbl
          GatherStats: false
          Select Operator
            expressions: event_time (type: string), event_type (type: string), product_id (type: string), category_id (type: string), category_code (type: string), brand (type: string), price (type: string), user_id (type: string), user_session (type: string), mnth (type: int)
            outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9
            Limit
              Number of rows: 5
              ListSink


INFO  : Completed compiling command(queryId=hive_20220717071519_c38fe826-2084-4e15-bc4a-3f9422bc75d4); Time taken: 0.38 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717071519_c38fe826-2084-4e15-bc4a-3f9422bc75d4): select * from part_mnth_buck_type_tbl limit 5
INFO  : Completed executing command(queryId=hive_20220717071519_c38fe826-2084-4e15-bc4a-3f9422bc75d4); Time taken: 0.004 seconds
INFO  : OK
+-------------------------------------+-------------------------------------+-------------------------------------+--------------------------------------+----------------------------------------+--------------------------------+--------------------------------+----------------------------------+---------------------------------------+-------------------------------+
| part_mnth_buck_type_tbl.event_time  | part_mnth_buck_type_tbl.event_type  | part_mnth_buck_type_tbl.product_id  | part_mnth_buck_type_tbl.category_id  | part_mnth_buck_type_tbl.category_code  | part_mnth_buck_type_tbl.brand  | part_mnth_buck_type_tbl.price  | part_mnth_buck_type_tbl.user_id  | part_mnth_buck_type_tbl.user_session  | part_mnth_buck_type_tbl.mnth  |
+-------------------------------------+-------------------------------------+-------------------------------------+--------------------------------------+----------------------------------------+--------------------------------+--------------------------------+----------------------------------+---------------------------------------+-------------------------------+
| 2019-10-31 16:36:59 UTC             | cart                                | 5700048                             | 1487580009286598681                  |                                        | runail                         | 0.40                           | 289709344                        | 61c3e638-39a6-438b-9753-3418a6868e2f  | 10                            |
| 2019-10-29 18:48:11 UTC             | cart                                | 5854897                             | 1487580009445982239                  |                                        | irisk                          | 0.32                           | 554153960                        | 47827419-5917-4268-945a-0835cc743ed7  | 10                            |
| 2019-10-31 16:37:01 UTC             | cart                                | 5819238                             | 1487580005713052531                  |                                        | ingarden                       | 4.44                           | 561335709                        | ad150937-1521-4744-99de-dc9ad93cf9d8  | 10                            |
| 2019-10-31 16:37:01 UTC             | cart                                | 5700048                             | 1487580009286598681                  |                                        | runail                         | 0.40                           | 289709344                        | 61c3e638-39a6-438b-9753-3418a6868e2f  | 10                            |
| 2019-10-28 19:44:37 UTC             | cart                                | 5686081                             | 1487580008145748965                  |                                        |                                | 0.57                           | 565164853                        | f0e9b742-d83b-4e59-a4db-d7ecccb2c376  | 10                            |
+-------------------------------------+-------------------------------------+-------------------------------------+--------------------------------------+----------------------------------------+--------------------------------+--------------------------------+----------------------------------+---------------------------------------+-------------------------------+
5 rows selected (0.48 seconds)
0: jdbc:hive2://localhost:10000/default> create table if not exists part_type_tbl(event_time string,event_type string ,product_id string,category_id string,category_code string,brand string,price decimal(10,3),user_id bigint,user_sessi on string) partitioned by (event_type string) row format SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' stored as  textfile;
Error: Error while compiling statement: FAILED: SemanticException [Error 10035]: Column repeated in partitioning columns (state=42000,code=10035)
0: jdbc:hive2://localhost:10000/default> create table if not exists part_type_tbl(event_time string,event_type string ,product_id string,category_id string,category_code string,brand string,price decimal(10,3),user_id bigint,user_sessi on string) partitioned by (event_type) row format SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' stored as textfi le;
Error: Error while compiling statement: FAILED: ParseException line 1:230 cannot recognize input near ')' 'row' 'format' in column type (state=42000,code=40000)
0: jdbc:hive2://localhost:10000/default> select * from  round(sum(price),2) as Oct_Revenue from clickstream_tbl where month(e vent_time) = 10 and event_type = 'purchase';
INFO  : Compiling command(queryId=hive_20220717071745_693b42c7-6534-4564-9be7-028cd856e2de): select round(sum(price),2) as Oct_Revenue from clickstream_tbl where month(event_time) = 10 and event_type = 'purchase'
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:oct_revenue, type:double, comment:null)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717071745_693b42c7-6534-4564-9be7-028cd856e2de : STAGE DEPENDENCIES:
  Stage-1 is a root stage [MAPRED]
  Stage-0 depends on stages: Stage-1 [FETCH]

STAGE PLANS:
  Stage: Stage-1
    Tez
      DagId: hive_20220717071745_693b42c7-6534-4564-9be7-028cd856e2de:9
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
      DagName: 
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: clickstream_tbl
                  Statistics: Num rows: 3427938 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: ((month(event_time) = 10) and (event_type = 'purchase')) (type: boolean)
                    Statistics: Num rows: 856984 Data size: 257095273 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: price (type: string)
                      outputColumnNames: price
                      Statistics: Num rows: 856984 Data size: 257095273 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        aggregations: sum(price)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          null sort order: 
                          sort order: 
                          Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                          tag: -1
                          value expressions: _col0 (type: double)
                          auto parallelism: false
            Path -> Alias:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl [clickstream_tbl]
            Path -> Partition:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl 
                Partition
                  base file name: clickstream_tbl
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    column.name.delimiter ,
                    columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                    columns.comments 
                    columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                    escapeChar \
                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                    name clickstream.clickstream_tbl
                    numFiles 2
                    numRows 0
                    quoteChar "
                    rawDataSize 0
                    separatorChar ,
                    serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                    skip.header.line.count 1
                    totalSize 1028381690
                    transient_lastDdlTime 1658039808
                  serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      column.name.delimiter ,
                      columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                      columns.comments 
                      columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                      escapeChar \
                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                      name clickstream.clickstream_tbl
                      numFiles 2
                      numRows 0
                      quoteChar "
                      rawDataSize 0
                      separatorChar ,
                      serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                      skip.header.line.count 1
                      totalSize 1028381690
                      transient_lastDdlTime 1658039808
                    serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                    name: clickstream.clickstream_tbl
                  name: clickstream.clickstream_tbl
            Truncated Path -> Alias:
              /clickstream.db/clickstream_tbl [clickstream_tbl]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0)
                mode: mergepartial
                outputColumnNames: _col0
                Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: round(_col0, 2) (type: double)
                  outputColumnNames: _col0
                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    GlobalTableId: 0
                    directory: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/c64b26ee-afee-44f3-bde1-17b8435a8c63/hive_2022-07-17_07-17-45_133_9045674440703151185-1/-mr-10001/.hive-staging_hive_2022-07-17_07-17-45_133_9045674440703151185-1/-ext-10002
                    NumFilesPerFileSink: 1
                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                    Stats Publishing Key Prefix: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/c64b26ee-afee-44f3-bde1-17b8435a8c63/hive_2022-07-17_07-17-45_133_9045674440703151185-1/-mr-10001/.hive-staging_hive_2022-07-17_07-17-45_133_9045674440703151185-1/-ext-10002/
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        properties:
                          columns _col0
                          columns.types double
                          escape.delim \
                          hive.serialization.extend.additional.nesting.levels true
                          serialization.escape.crlf true
                          serialization.format 1
                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    TotalFiles: 1
                    GatherStats: false
                    MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717071745_693b42c7-6534-4564-9be7-028cd856e2de); Time taken: 0.258 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717071745_693b42c7-6534-4564-9be7-028cd856e2de): select round(sum(price),2) as Oct_Revenue from clickstream_tbl where month(event_time) = 10 and event_type = 'purchase'
INFO  : Query ID = hive_20220717071745_693b42c7-6534-4564-9be7-028cd856e2de
INFO  : Total jobs = 1
INFO  : Launching Job 1 out of 1
INFO  : Starting task [Stage-1:MAPRED] in serial mode
INFO  : Session is already open
INFO  : Dag name: select round(sum(price),2) as O...'purchase'(Stage-1)
INFO  : Status: Running (Executing on YARN cluster with App id application_1658032091232_0004)

INFO  : Map 1: 0/2Reducer 2: 0/1
INFO  : Map 1: 0/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 1(+1)/2Reducer 2: 0(+1)/1
INFO  : Map 1: 1(+1)/2Reducer 2: 0(+1)/1
INFO  : Map 1: 2/2Reducer 2: 0(+1)/1
INFO  : Map 1: 2/2Reducer 2: 1/1
INFO  : Completed executing command(queryId=hive_20220717071745_693b42c7-6534-4564-9be7-028cd856e2de); Time taken: 65.876 seconds
INFO  : OK
+--------------+
| oct_revenue  |
+--------------+
| 1211538.43   |
+--------------+
1 row selected (66.179 seconds)
0: jdbc:hive2://localhost:10000/default> select round(sum(price),2) as Oct_Revenue from clickstream_tbl where month(event_time) = 10 and event_type = 'purchase'; where month(ev ent_time) = 10 and event_type = 'purchase'; where month(eve nt_time) = 10 and event_type = 'purchase'; where month(even t_time) = 10 and event_type = 'purchase'; where month(event _time) = 10 and event_type = 'purchase'; where month(event_ time) = 10 and event_type = 'purchase'; where month(event_t ime) = 10 and event_type = 'purchase'; where month(event_ti me) = 10 and event_type = 'purchase'; where month(event_tim e) = 10 and event_type = 'purchase'; where month(event_time ) = 10 and event_type = 'purchase'; where month(event_time)  = 10 and event_type = 'purchase'; where month(event_time)  = 10 and event_type = 'purchase'; where month(event_time) =  10 and event_type = 'purchase'; where month(event_time) =  10 and event_type = 'purchase'; where month(event_time) = 1 0 and event_type = 'purchase'; where month(event_time) = 10  and event_type = 'purchase';p where month(event_time) = 1 0 and event_type = 'purchase';a where month(event_time) =  10 and event_type = 'purchase';r where month(event_time) =  10 and event_type = 'purchase';t where month(event_time)  = 10 and event_type = 'purchase';_ where month(event_time)  = 10 and event_type = 'purchase';m where month(event_time ) = 10 and event_type = 'purchase';n where month(event_tim e) = 10 and event_type = 'purchase';t where month(event_ti me) = 10 and event_type = 'purchase';h where month(event_t ime) = 10 and event_type = 'purchase';_ where month(event_ time) = 10 and event_type = 'purchase';b where month(event _time) = 10 and event_type = 'purchase';u where month(even t_time) = 10 and event_type = 'purchase';c where month(eve nt_time) = 10 and event_type = 'purchase';k where month(ev ent_time) = 10 and event_type = 'purchase';_ where month(e vent_time) = 10 and event_type = 'purchase';t where month( event_time) = 10 and event_type = 'purchase';y where month (event_time) = 10 and event_type = 'purchase';p where mont h(event_time) = 10 and event_type = 'purchase';e where mon th(event_time) = 10 and event_type = 'purchase';_ where mo nth(event_time) = 10 and event_type = 'purchase';t where m onth(event_time) = 10 and event_type = 'purchase';b where  month(event_time) = 10 and event_type = 'purchase';l where  month(event_time) = 10 and event_type = 'purchase';
INFO  : Compiling command(queryId=hive_20220717072008_8fc231b6-baa2-4c88-8546-43a9a2390e18): select round(sum(price),2) as Oct_Revenue from part_mnth_buck_type_tbl where month(event_time) = 10 and event_type = 'purchase'
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:oct_revenue, type:double, comment:null)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717072008_8fc231b6-baa2-4c88-8546-43a9a2390e18 : STAGE DEPENDENCIES:
  Stage-1 is a root stage [MAPRED]
  Stage-0 depends on stages: Stage-1 [FETCH]

STAGE PLANS:
  Stage: Stage-1
    Tez
      DagId: hive_20220717072008_8fc231b6-baa2-4c88-8546-43a9a2390e18:10
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
      DagName: 
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part_mnth_buck_type_tbl
                  Statistics: Num rows: 8738120 Data size: 1255572626 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: ((month(event_time) = 10) and (event_type = 'purchase')) (type: boolean)
                    Statistics: Num rows: 2184530 Data size: 313893156 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: price (type: string)
                      outputColumnNames: price
                      Statistics: Num rows: 2184530 Data size: 313893156 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        aggregations: sum(price)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          null sort order: 
                          sort order: 
                          Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                          tag: -1
                          value expressions: _col0 (type: double)
                          auto parallelism: false
            Path -> Alias:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl/mnth=10 [part_mnth_buck_type_tbl]
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl/mnth=11 [part_mnth_buck_type_tbl]
            Path -> Partition:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl/mnth=10 
                Partition
                  base file name: mnth=10
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    mnth 10
                  properties:
                    COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
                    bucket_count 4
                    bucket_field_name event_type
                    column.name.delimiter ,
                    columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                    columns.comments 
                    columns.types string:string:string:string:string:string:decimal(10,3):bigint:string
                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl/mnth=10
                    name clickstream.part_mnth_buck_type_tbl
                    numFiles 3
                    numRows 4102283
                    partition_columns mnth
                    partition_columns.types int
                    rawDataSize 0
                    serialization.ddl struct part_mnth_buck_type_tbl { string event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                    totalSize 556383280
                    transient_lastDdlTime 1658042010
                  serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count 4
                      bucket_field_name event_type
                      column.name.delimiter ,
                      columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                      columns.comments 
                      columns.types string:string:string:string:string:string:decimal(10,3):bigint:string
                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl
                      name clickstream.part_mnth_buck_type_tbl
                      partition_columns mnth
                      partition_columns.types int
                      serialization.ddl struct part_mnth_buck_type_tbl { string event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                      transient_lastDdlTime 1658041789
                    serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                    name: clickstream.part_mnth_buck_type_tbl
                  name: clickstream.part_mnth_buck_type_tbl
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl/mnth=11 
                Partition
                  base file name: mnth=11
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    mnth 11
                  properties:
                    COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
                    bucket_count 4
                    bucket_field_name event_type
                    column.name.delimiter ,
                    columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                    columns.comments 
                    columns.types string:string:string:string:string:string:decimal(10,3):bigint:string
                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl/mnth=11
                    name clickstream.part_mnth_buck_type_tbl
                    numFiles 3
                    numRows 4635837
                    partition_columns mnth
                    partition_columns.types int
                    rawDataSize 0
                    serialization.ddl struct part_mnth_buck_type_tbl { string event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                    totalSize 629284386
                    transient_lastDdlTime 1658042011
                  serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count 4
                      bucket_field_name event_type
                      column.name.delimiter ,
                      columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                      columns.comments 
                      columns.types string:string:string:string:string:string:decimal(10,3):bigint:string
                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl
                      name clickstream.part_mnth_buck_type_tbl
                      partition_columns mnth
                      partition_columns.types int
                      serialization.ddl struct part_mnth_buck_type_tbl { string event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                      transient_lastDdlTime 1658041789
                    serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                    name: clickstream.part_mnth_buck_type_tbl
                  name: clickstream.part_mnth_buck_type_tbl
            Truncated Path -> Alias:
              /clickstream.db/part_mnth_buck_type_tbl/mnth=10 [part_mnth_buck_type_tbl]
              /clickstream.db/part_mnth_buck_type_tbl/mnth=11 [part_mnth_buck_type_tbl]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0)
                mode: mergepartial
                outputColumnNames: _col0
                Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: round(_col0, 2) (type: double)
                  outputColumnNames: _col0
                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    GlobalTableId: 0
                    directory: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/c64b26ee-afee-44f3-bde1-17b8435a8c63/hive_2022-07-17_07-20-08_770_1430731686924020793-1/-mr-10001/.hive-staging_hive_2022-07-17_07-20-08_770_1430731686924020793-1/-ext-10002
                    NumFilesPerFileSink: 1
                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                    Stats Publishing Key Prefix: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/c64b26ee-afee-44f3-bde1-17b8435a8c63/hive_2022-07-17_07-20-08_770_1430731686924020793-1/-mr-10001/.hive-staging_hive_2022-07-17_07-20-08_770_1430731686924020793-1/-ext-10002/
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        properties:
                          columns _col0
                          columns.types double
                          escape.delim \
                          hive.serialization.extend.additional.nesting.levels true
                          serialization.escape.crlf true
                          serialization.format 1
                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    TotalFiles: 1
                    GatherStats: false
                    MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717072008_8fc231b6-baa2-4c88-8546-43a9a2390e18); Time taken: 0.675 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717072008_8fc231b6-baa2-4c88-8546-43a9a2390e18): select round(sum(price),2) as Oct_Revenue from part_mnth_buck_type_tbl where month(event_time) = 10 and event_type = 'purchase'
INFO  : Query ID = hive_20220717072008_8fc231b6-baa2-4c88-8546-43a9a2390e18
INFO  : Total jobs = 1
INFO  : Launching Job 1 out of 1
INFO  : Starting task [Stage-1:MAPRED] in serial mode
INFO  : Session is already open
INFO  : Dag name: select round(sum(price),2) as O...'purchase'(Stage-1)
INFO  : Status: Running (Executing on YARN cluster with App id application_1658032091232_0004)

INFO  : Map 1: 0/9Reducer 2: 0/1
INFO  : Map 1: 0/9Reducer 2: 0/1
INFO  : Map 1: 0/9Reducer 2: 0/1
INFO  : Map 1: 0(+1)/9Reducer 2: 0/1
INFO  : Map 1: 0(+3)/9Reducer 2: 0/1
INFO  : Map 1: 0(+3)/9Reducer 2: 0/1
INFO  : Map 1: 0(+3)/9Reducer 2: 0/1
INFO  : Map 1: 0(+3)/9Reducer 2: 0/1
INFO  : Map 1: 0(+3)/9Reducer 2: 0/1
INFO  : Map 1: 0(+3)/9Reducer 2: 0/1
INFO  : Map 1: 0(+3)/9Reducer 2: 0/1
INFO  : Map 1: 0(+3)/9Reducer 2: 0/1
INFO  : Map 1: 0(+3)/9Reducer 2: 0/1
INFO  : Map 1: 0(+3)/9Reducer 2: 0/1
INFO  : Map 1: 0(+3)/9Reducer 2: 0/1
INFO  : Map 1: 0(+3)/9Reducer 2: 0/1
INFO  : Map 1: 1(+3)/9Reducer 2: 0/1
INFO  : Map 1: 2(+3)/9Reducer 2: 0/1
INFO  : Map 1: 3(+3)/9Reducer 2: 0/1
INFO  : Map 1: 3(+3)/9Reducer 2: 0/1
INFO  : Map 1: 3(+3)/9Reducer 2: 0/1
INFO  : Map 1: 3(+3)/9Reducer 2: 0/1
INFO  : Map 1: 3(+3)/9Reducer 2: 0/1
INFO  : Map 1: 3(+3)/9Reducer 2: 0/1
INFO  : Map 1: 4(+3)/9Reducer 2: 0/1
INFO  : Map 1: 5(+3)/9Reducer 2: 0/1
INFO  : Map 1: 6(+2)/9Reducer 2: 0/1
INFO  : Map 1: 6(+3)/9Reducer 2: 0/1
INFO  : Map 1: 7(+2)/9Reducer 2: 0(+1)/1
INFO  : Map 1: 7(+2)/9Reducer 2: 0(+1)/1
INFO  : Map 1: 7(+2)/9Reducer 2: 0(+1)/1
INFO  : Map 1: 7(+2)/9Reducer 2: 0(+1)/1
INFO  : Map 1: 8(+1)/9Reducer 2: 0(+1)/1
INFO  : Map 1: 8(+1)/9Reducer 2: 0(+1)/1
INFO  : Map 1: 9/9Reducer 2: 0(+1)/1
INFO  : Map 1: 9/9Reducer 2: 1/1
INFO  : Completed executing command(queryId=hive_20220717072008_8fc231b6-baa2-4c88-8546-43a9a2390e18); Time taken: 83.468 seconds
INFO  : OK
+--------------+
| oct_revenue  |
+--------------+
| 1211538.43   |
+--------------+
1 row selected (84.209 seconds)
0: jdbc:hive2://localhost:10000/default> select month)(event_time) as Month, sum(price) as Price from clickstream_tbl  where event_type = 'puchase' group by month(event_time);
INFO  : Compiling command(queryId=hive_20220717072425_b662a872-2f02-4e5d-9c12-24b728e97786): select month(event_time) as Month, sum(price) as Price from clickstream_tbl where event_type = 'puchase' group by month(event_time)
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:month, type:int, comment:null), FieldSchema(name:price, type:double, comment:null)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717072425_b662a872-2f02-4e5d-9c12-24b728e97786 : STAGE DEPENDENCIES:
  Stage-1 is a root stage [MAPRED]
  Stage-0 depends on stages: Stage-1 [FETCH]

STAGE PLANS:
  Stage: Stage-1
    Tez
      DagId: hive_20220717072425_b662a872-2f02-4e5d-9c12-24b728e97786:11
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
      DagName: 
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: clickstream_tbl
                  Statistics: Num rows: 3427938 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: (event_type = 'puchase') (type: boolean)
                    Statistics: Num rows: 1713969 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: month(event_time) (type: int), price (type: string)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 1713969 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        aggregations: sum(_col1)
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0, _col1
                        Statistics: Num rows: 1713969 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          null sort order: a
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Statistics: Num rows: 1713969 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                          tag: -1
                          value expressions: _col1 (type: double)
                          auto parallelism: true
            Path -> Alias:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl [clickstream_tbl]
            Path -> Partition:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl 
                Partition
                  base file name: clickstream_tbl
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    column.name.delimiter ,
                    columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                    columns.comments 
                    columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                    escapeChar \
                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                    name clickstream.clickstream_tbl
                    numFiles 2
                    numRows 0
                    quoteChar "
                    rawDataSize 0
                    separatorChar ,
                    serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                    skip.header.line.count 1
                    totalSize 1028381690
                    transient_lastDdlTime 1658039808
                  serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      column.name.delimiter ,
                      columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                      columns.comments 
                      columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                      escapeChar \
                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                      name clickstream.clickstream_tbl
                      numFiles 2
                      numRows 0
                      quoteChar "
                      rawDataSize 0
                      separatorChar ,
                      serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                      skip.header.line.count 1
                      totalSize 1028381690
                      transient_lastDdlTime 1658039808
                    serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                    name: clickstream.clickstream_tbl
                  name: clickstream.clickstream_tbl
            Truncated Path -> Alias:
              /clickstream.db/clickstream_tbl [clickstream_tbl]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0)
                keys: KEY._col0 (type: int)
                mode: mergepartial
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 856984 Data size: 257095273 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
                  directory: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/c64b26ee-afee-44f3-bde1-17b8435a8c63/hive_2022-07-17_07-24-25_713_1447538591436553804-1/-mr-10001/.hive-staging_hive_2022-07-17_07-24-25_713_1447538591436553804-1/-ext-10002
                  NumFilesPerFileSink: 1
                  Statistics: Num rows: 856984 Data size: 257095273 Basic stats: COMPLETE Column stats: NONE
                  Stats Publishing Key Prefix: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/c64b26ee-afee-44f3-bde1-17b8435a8c63/hive_2022-07-17_07-24-25_713_1447538591436553804-1/-mr-10001/.hive-staging_hive_2022-07-17_07-24-25_713_1447538591436553804-1/-ext-10002/
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      properties:
                        columns _col0,_col1
                        columns.types int:double
                        escape.delim \
                        hive.serialization.extend.additional.nesting.levels true
                        serialization.escape.crlf true
                        serialization.format 1
                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  TotalFiles: 1
                  GatherStats: false
                  MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717072425_b662a872-2f02-4e5d-9c12-24b728e97786); Time taken: 0.315 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717072425_b662a872-2f02-4e5d-9c12-24b728e97786): select month(event_time) as Month, sum(price) as Price from clickstream_tbl where event_type = 'puchase' group by month(event_time)
INFO  : Query ID = hive_20220717072425_b662a872-2f02-4e5d-9c12-24b728e97786
INFO  : Total jobs = 1
INFO  : Launching Job 1 out of 1
INFO  : Starting task [Stage-1:MAPRED] in serial mode
INFO  : Session is already open
INFO  : Dag name: select month(event_time)...month(event_time)(Stage-1)
INFO  : Status: Running (Executing on YARN cluster with App id application_1658032091232_0004)

INFO  : Map 1: 0/2Reducer 2: 0/6
INFO  : Map 1: 0/2Reducer 2: 0/6
INFO  : Map 1: 0(+1)/2Reducer 2: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6
INFO  : Map 1: 1(+1)/2Reducer 2: 0(+1)/6
INFO  : Map 1: 1(+1)/2Reducer 2: 0(+1)/6
INFO  : Map 1: 2/2Reducer 2: 0(+2)/6
INFO  : Map 1: 2/2Reducer 2: 1(+2)/6
INFO  : Map 1: 2/2Reducer 2: 2(+1)/6
INFO  : Map 1: 2/2Reducer 2: 3(+2)/6
INFO  : Map 1: 2/2Reducer 2: 4(+1)/6
INFO  : Map 1: 2/2Reducer 2: 5(+0)/6
INFO  : Map 1: 2/2Reducer 2: 5(+1)/6
INFO  : Map 1: 2/2Reducer 2: 6/6
INFO  : Completed executing command(queryId=hive_20220717072425_b662a872-2f02-4e5d-9c12-24b728e97786); Time taken: 57.693 seconds
INFO  : OK
+--------+--------+
| month  | price  |
+--------+--------+
+--------+--------+
No rows selected (58.021 seconds)
0: jdbc:hive2://localhost:10000/default> select month(event_time) as Month, sum(price) as Price from clickstream_tbl where event_type = 'puchase' group by month(event_time);rchase' group by month(event_time);
INFO  : Compiling command(queryId=hive_20220717072700_a93bc522-967b-48f4-b479-1bb54663833e): select month(event_time) as Month, sum(price) as Price from clickstream_tbl where event_type = 'purchase' group by month(event_time)
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:month, type:int, comment:null), FieldSchema(name:price, type:double, comment:null)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717072700_a93bc522-967b-48f4-b479-1bb54663833e : STAGE DEPENDENCIES:
  Stage-1 is a root stage [MAPRED]
  Stage-0 depends on stages: Stage-1 [FETCH]

STAGE PLANS:
  Stage: Stage-1
    Tez
      DagId: hive_20220717072700_a93bc522-967b-48f4-b479-1bb54663833e:12
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
      DagName: 
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: clickstream_tbl
                  Statistics: Num rows: 3427938 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: (event_type = 'purchase') (type: boolean)
                    Statistics: Num rows: 1713969 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: month(event_time) (type: int), price (type: string)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 1713969 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        aggregations: sum(_col1)
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0, _col1
                        Statistics: Num rows: 1713969 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          null sort order: a
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Statistics: Num rows: 1713969 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                          tag: -1
                          value expressions: _col1 (type: double)
                          auto parallelism: true
            Path -> Alias:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl [clickstream_tbl]
            Path -> Partition:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl 
                Partition
                  base file name: clickstream_tbl
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    column.name.delimiter ,
                    columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                    columns.comments 
                    columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                    escapeChar \
                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                    name clickstream.clickstream_tbl
                    numFiles 2
                    numRows 0
                    quoteChar "
                    rawDataSize 0
                    separatorChar ,
                    serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                    skip.header.line.count 1
                    totalSize 1028381690
                    transient_lastDdlTime 1658039808
                  serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      column.name.delimiter ,
                      columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                      columns.comments 
                      columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                      escapeChar \
                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                      name clickstream.clickstream_tbl
                      numFiles 2
                      numRows 0
                      quoteChar "
                      rawDataSize 0
                      separatorChar ,
                      serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                      skip.header.line.count 1
                      totalSize 1028381690
                      transient_lastDdlTime 1658039808
                    serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                    name: clickstream.clickstream_tbl
                  name: clickstream.clickstream_tbl
            Truncated Path -> Alias:
              /clickstream.db/clickstream_tbl [clickstream_tbl]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0)
                keys: KEY._col0 (type: int)
                mode: mergepartial
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 856984 Data size: 257095273 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
                  directory: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/c64b26ee-afee-44f3-bde1-17b8435a8c63/hive_2022-07-17_07-27-00_621_4716631386013898922-1/-mr-10001/.hive-staging_hive_2022-07-17_07-27-00_621_4716631386013898922-1/-ext-10002
                  NumFilesPerFileSink: 1
                  Statistics: Num rows: 856984 Data size: 257095273 Basic stats: COMPLETE Column stats: NONE
                  Stats Publishing Key Prefix: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/c64b26ee-afee-44f3-bde1-17b8435a8c63/hive_2022-07-17_07-27-00_621_4716631386013898922-1/-mr-10001/.hive-staging_hive_2022-07-17_07-27-00_621_4716631386013898922-1/-ext-10002/
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      properties:
                        columns _col0,_col1
                        columns.types int:double
                        escape.delim \
                        hive.serialization.extend.additional.nesting.levels true
                        serialization.escape.crlf true
                        serialization.format 1
                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  TotalFiles: 1
                  GatherStats: false
                  MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717072700_a93bc522-967b-48f4-b479-1bb54663833e); Time taken: 0.168 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717072700_a93bc522-967b-48f4-b479-1bb54663833e): select month(event_time) as Month, sum(price) as Price from clickstream_tbl where event_type = 'purchase' group by month(event_time)
INFO  : Query ID = hive_20220717072700_a93bc522-967b-48f4-b479-1bb54663833e
INFO  : Total jobs = 1
INFO  : Launching Job 1 out of 1
INFO  : Starting task [Stage-1:MAPRED] in serial mode
INFO  : Session is already open
INFO  : Dag name: select month(event_time)...month(event_time)(Stage-1)
INFO  : Status: Running (Executing on YARN cluster with App id application_1658032091232_0004)

INFO  : Map 1: 0/2Reducer 2: 0/6
INFO  : Map 1: 0/2Reducer 2: 0/6
INFO  : Map 1: 0(+1)/2Reducer 2: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6
INFO  : Map 1: 1(+1)/2Reducer 2: 0(+1)/6
INFO  : Map 1: 1(+1)/2Reducer 2: 0(+1)/6
INFO  : Map 1: 1(+1)/2Reducer 2: 0(+2)/6
INFO  : Map 1: 2/2Reducer 2: 0(+3)/6
INFO  : Map 1: 2/2Reducer 2: 1(+3)/6
INFO  : Map 1: 2/2Reducer 2: 2(+3)/6
INFO  : Map 1: 2/2Reducer 2: 3(+3)/6
INFO  : Map 1: 2/2Reducer 2: 5(+1)/6
INFO  : Map 1: 2/2Reducer 2: 6/6
INFO  : Completed executing command(queryId=hive_20220717072700_a93bc522-967b-48f4-b479-1bb54663833e); Time taken: 60.367 seconds
INFO  : OK
+--------+---------------------+
| month  |        price        |
+--------+---------------------+
| 11     | 1531016.900000122   |
| 10     | 1211538.4299997438  |
+--------+---------------------+
2 rows selected (60.567 seconds)
0: jdbc:hive2://localhost:10000/default> Closing: 0: jdbc:hive2://localhost:10000/default
[hadoop@ip-172-31-42-254 hive_cs]$ beeline -u jdbc:hive2://localhost:10000/default  -n hadoopcat 2019-Nov.csv | headOcthadoop fs -cat 2019-Oct.csv | wc -lcat 2019-Oct.csv | headNovbeeline -u jdbc:hive2://localhost:10000/default  -n hadoopbeeline -u jdbc:hive2://localhost:10000/default  -n hadoopbeeline -u jdbc:hive2://localhost:10000/default  -n hadoopcat 2019-Nov.csv | headOcthadoop fs -cat 2019-Oct.csv | wc -l/hive_cs fs -lslshdfs dfs -cat 2019-Oct.csv | wc -llswget https://e-commerce-events-ml.s3.amazonaws.com/2019-Nov.csvOct.csvcd hive_cs/lsmkdir hive_cslscd hive_cs/wget https://e-commerce-events-ml.s3.amazonaws.com/2019-Oct.csvNov.csvlsdfs -cat 2019-Oct.csv | wc -lhdfs lshadoop fs -ls/hive_cs fs -cat 2019-Oct.csv | wc -lcat 2019-Oct.csv | headNovbeeline -u jdbc:hive2://localhost:10000/default  -n hadoopselect month(event_time) as Month, sum(price) as Price from part_mnth_buck_type_tb l where event_type = 'purchase' group by month(event_time);
-bash: syntax error near unexpected token `('
[hadoop@ip-172-31-42-254 hive_cs]$ select month(event_time) as Month, sum(price) as Price from part_mnth_buck_type_tbll where event_type = 'purchase' group by month(event_time);beeline -u jdbc:hive2://localhost:10000/default  -n hadoop
cat 2019-Nov.csv | headbeeline -u jdbc:hive2://localhost:10000/default  -n hadoop
Connecting to jdbc:hive2://localhost:10000/default
Connected to: Apache Hive (version 2.3.9-amzn-2)
Driver: Hive JDBC (version 2.3.9-amzn-2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
Beeline version 2.3.9-amzn-2 by Apache Hive
0: jdbc:hive2://localhost:10000/default> select month(event_time) as Month, sum(price) as Price from clickstream_tbl where event_type = 'purchase' group by month(event_time);chase' group by month(event_time);rchase' group by month(event_time);select month(event_time) as Month, sum(price) as Price from clickstream_tbl where event_type = 'purchase' group by month(event_time);select month(event_time) as Month, sum(price) as Price from part_mnth_buck_t ype_tbl where event_type = 'purchase' group by month(event_time);
Error: Error while compiling statement: FAILED: SemanticException [Error 10001]: Line 1:60 Table not found 'part_mnth_buck_type_tbl' (state=42S02,code=10001)
0: jdbc:hive2://localhost:10000/default> show tables;
INFO  : Compiling command(queryId=hive_20220717073231_e4025311-81cf-486b-820c-1d175a597e85): show tables
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:tab_name, type:string, comment:from deserializer)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717073231_e4025311-81cf-486b-820c-1d175a597e85 : STAGE DEPENDENCIES:
  Stage-0 is a root stage [DDL]
  Stage-1 depends on stages: Stage-0 [FETCH]

STAGE PLANS:
  Stage: Stage-0
      Show Table Operator:
        Show Tables
          database name: default
          result file: file:/mnt/tmp/hive/2e887956-43ca-4370-950a-3b102d33ca75/hive_2022-07-17_07-32-31_870_4000630648229189506-14/-local-10000

  Stage: Stage-1
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717073231_e4025311-81cf-486b-820c-1d175a597e85); Time taken: 0.024 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717073231_e4025311-81cf-486b-820c-1d175a597e85): show tables
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20220717073231_e4025311-81cf-486b-820c-1d175a597e85); Time taken: 0.013 seconds
INFO  : OK
+-----------+
| tab_name  |
+-----------+
+-----------+
No rows selected (0.246 seconds)
0: jdbc:hive2://localhost:10000/default> use sclickstream;
INFO  : Compiling command(queryId=hive_20220717073239_8f634e4f-1205-44aa-b4c8-fa733b8de219): use clickstream
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : EXPLAIN output for queryid hive_20220717073239_8f634e4f-1205-44aa-b4c8-fa733b8de219 : STAGE DEPENDENCIES:
  Stage-0 is a root stage [DDL]

STAGE PLANS:
  Stage: Stage-0


INFO  : Completed compiling command(queryId=hive_20220717073239_8f634e4f-1205-44aa-b4c8-fa733b8de219); Time taken: 0.047 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717073239_8f634e4f-1205-44aa-b4c8-fa733b8de219): use clickstream
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20220717073239_8f634e4f-1205-44aa-b4c8-fa733b8de219); Time taken: 0.015 seconds
INFO  : OK
No rows affected (0.089 seconds)
0: jdbc:hive2://localhost:10000/default> use clickstream;show tables;
INFO  : Compiling command(queryId=hive_20220717073241_3493fd8b-8fea-41a4-a1e9-4d01ad728a4c): show tables
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:tab_name, type:string, comment:from deserializer)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717073241_3493fd8b-8fea-41a4-a1e9-4d01ad728a4c : STAGE DEPENDENCIES:
  Stage-0 is a root stage [DDL]
  Stage-1 depends on stages: Stage-0 [FETCH]

STAGE PLANS:
  Stage: Stage-0
      Show Table Operator:
        Show Tables
          database name: clickstream
          result file: file:/mnt/tmp/hive/2e887956-43ca-4370-950a-3b102d33ca75/hive_2022-07-17_07-32-41_706_2022857195404451992-14/-local-10000

  Stage: Stage-1
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717073241_3493fd8b-8fea-41a4-a1e9-4d01ad728a4c); Time taken: 0.035 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717073241_3493fd8b-8fea-41a4-a1e9-4d01ad728a4c): show tables
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20220717073241_3493fd8b-8fea-41a4-a1e9-4d01ad728a4c); Time taken: 0.02 seconds
INFO  : OK
+--------------------------+
|         tab_name         |
+--------------------------+
| clickstream_stats        |
| clickstream_tbl          |
| part_mnth_buck_type_tbl  |
+--------------------------+
3 rows selected (0.096 seconds)
0: jdbc:hive2://localhost:10000/default> show tables;use clickstream;show tables;elect month(event_time) as Month, sum(price) as Price from part_mnth_buck_type_tbl where event_type = 'purchase' group by month(event_time);
INFO  : Compiling command(queryId=hive_20220717073247_bf54c2a9-5646-47fd-b6cd-d6023c4a61b3): select month(event_time) as Month, sum(price) as Price from part_mnth_buck_type_tbl where event_type = 'purchase' group by month(event_time)
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:month, type:int, comment:null), FieldSchema(name:price, type:double, comment:null)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717073247_bf54c2a9-5646-47fd-b6cd-d6023c4a61b3 : STAGE DEPENDENCIES:
  Stage-1 is a root stage [MAPRED]
  Stage-0 depends on stages: Stage-1 [FETCH]

STAGE PLANS:
  Stage: Stage-1
    Tez
      DagId: hive_20220717073247_bf54c2a9-5646-47fd-b6cd-d6023c4a61b3:13
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
      DagName: 
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part_mnth_buck_type_tbl
                  Statistics: Num rows: 8738120 Data size: 1255572626 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: (event_type = 'purchase') (type: boolean)
                    Statistics: Num rows: 4369060 Data size: 627786313 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: month(event_time) (type: int), price (type: string)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 4369060 Data size: 627786313 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        aggregations: sum(_col1)
                        keys: _col0 (type: int)
                        mode: hash
                        outputColumnNames: _col0, _col1
                        Statistics: Num rows: 4369060 Data size: 627786313 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: int)
                          null sort order: a
                          sort order: +
                          Map-reduce partition columns: _col0 (type: int)
                          Statistics: Num rows: 4369060 Data size: 627786313 Basic stats: COMPLETE Column stats: NONE
                          tag: -1
                          value expressions: _col1 (type: double)
                          auto parallelism: true
            Path -> Alias:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl/mnth=10 [part_mnth_buck_type_tbl]
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl/mnth=11 [part_mnth_buck_type_tbl]
            Path -> Partition:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl/mnth=10 
                Partition
                  base file name: mnth=10
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    mnth 10
                  properties:
                    COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
                    bucket_count 4
                    bucket_field_name event_type
                    column.name.delimiter ,
                    columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                    columns.comments 
                    columns.types string:string:string:string:string:string:decimal(10,3):bigint:string
                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl/mnth=10
                    name clickstream.part_mnth_buck_type_tbl
                    numFiles 3
                    numRows 4102283
                    partition_columns mnth
                    partition_columns.types int
                    rawDataSize 0
                    serialization.ddl struct part_mnth_buck_type_tbl { string event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                    totalSize 556383280
                    transient_lastDdlTime 1658042010
                  serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count 4
                      bucket_field_name event_type
                      column.name.delimiter ,
                      columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                      columns.comments 
                      columns.types string:string:string:string:string:string:decimal(10,3):bigint:string
                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl
                      name clickstream.part_mnth_buck_type_tbl
                      partition_columns mnth
                      partition_columns.types int
                      serialization.ddl struct part_mnth_buck_type_tbl { string event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                      transient_lastDdlTime 1658041789
                    serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                    name: clickstream.part_mnth_buck_type_tbl
                  name: clickstream.part_mnth_buck_type_tbl
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl/mnth=11 
                Partition
                  base file name: mnth=11
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    mnth 11
                  properties:
                    COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
                    bucket_count 4
                    bucket_field_name event_type
                    column.name.delimiter ,
                    columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                    columns.comments 
                    columns.types string:string:string:string:string:string:decimal(10,3):bigint:string
                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl/mnth=11
                    name clickstream.part_mnth_buck_type_tbl
                    numFiles 3
                    numRows 4635837
                    partition_columns mnth
                    partition_columns.types int
                    rawDataSize 0
                    serialization.ddl struct part_mnth_buck_type_tbl { string event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                    totalSize 629284386
                    transient_lastDdlTime 1658042011
                  serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count 4
                      bucket_field_name event_type
                      column.name.delimiter ,
                      columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                      columns.comments 
                      columns.types string:string:string:string:string:string:decimal(10,3):bigint:string
                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl
                      name clickstream.part_mnth_buck_type_tbl
                      partition_columns mnth
                      partition_columns.types int
                      serialization.ddl struct part_mnth_buck_type_tbl { string event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                      transient_lastDdlTime 1658041789
                    serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                    name: clickstream.part_mnth_buck_type_tbl
                  name: clickstream.part_mnth_buck_type_tbl
            Truncated Path -> Alias:
              /clickstream.db/part_mnth_buck_type_tbl/mnth=10 [part_mnth_buck_type_tbl]
              /clickstream.db/part_mnth_buck_type_tbl/mnth=11 [part_mnth_buck_type_tbl]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0)
                keys: KEY._col0 (type: int)
                mode: mergepartial
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 2184530 Data size: 313893156 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
                  directory: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/2e887956-43ca-4370-950a-3b102d33ca75/hive_2022-07-17_07-32-47_499_5882630918797943482-14/-mr-10001/.hive-staging_hive_2022-07-17_07-32-47_499_5882630918797943482-14/-ext-10002
                  NumFilesPerFileSink: 1
                  Statistics: Num rows: 2184530 Data size: 313893156 Basic stats: COMPLETE Column stats: NONE
                  Stats Publishing Key Prefix: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/2e887956-43ca-4370-950a-3b102d33ca75/hive_2022-07-17_07-32-47_499_5882630918797943482-14/-mr-10001/.hive-staging_hive_2022-07-17_07-32-47_499_5882630918797943482-14/-ext-10002/
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      properties:
                        columns _col0,_col1
                        columns.types int:double
                        escape.delim \
                        hive.serialization.extend.additional.nesting.levels true
                        serialization.escape.crlf true
                        serialization.format 1
                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  TotalFiles: 1
                  GatherStats: false
                  MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717073247_bf54c2a9-5646-47fd-b6cd-d6023c4a61b3); Time taken: 0.366 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717073247_bf54c2a9-5646-47fd-b6cd-d6023c4a61b3): select month(event_time) as Month, sum(price) as Price from part_mnth_buck_type_tbl where event_type = 'purchase' group by month(event_time)
INFO  : Query ID = hive_20220717073247_bf54c2a9-5646-47fd-b6cd-d6023c4a61b3
INFO  : Total jobs = 1
INFO  : Launching Job 1 out of 1
INFO  : Starting task [Stage-1:MAPRED] in serial mode
INFO  : Tez session hasn't been created yet. Opening session
INFO  : Dag name: select month(event_time)...month(event_time)(Stage-1)
INFO  : Status: Running (Executing on YARN cluster with App id application_1658032091232_0005)

INFO  : Map 1: 0/9Reducer 2: 0/6
INFO  : Map 1: 0/9Reducer 2: 0/6
INFO  : Map 1: 0/9Reducer 2: 0/6
INFO  : Map 1: 0(+1)/9Reducer 2: 0/6
INFO  : Map 1: 0(+2)/9Reducer 2: 0/6
INFO  : Map 1: 0(+3)/9Reducer 2: 0/6
INFO  : Map 1: 0(+3)/9Reducer 2: 0/6
INFO  : Map 1: 0(+3)/9Reducer 2: 0/6
INFO  : Map 1: 0(+3)/9Reducer 2: 0/6
INFO  : Map 1: 0(+3)/9Reducer 2: 0/6
INFO  : Map 1: 0(+3)/9Reducer 2: 0/6
INFO  : Map 1: 0(+3)/9Reducer 2: 0/6
INFO  : Map 1: 0(+3)/9Reducer 2: 0/6
INFO  : Map 1: 0(+3)/9Reducer 2: 0/6
INFO  : Map 1: 0(+3)/9Reducer 2: 0/6
INFO  : Map 1: 1(+3)/9Reducer 2: 0/6
INFO  : Map 1: 2(+3)/9Reducer 2: 0/6
INFO  : Map 1: 2(+2)/9Reducer 2: 0/6
INFO  : Map 1: 3(+3)/9Reducer 2: 0/6
INFO  : Map 1: 3(+3)/9Reducer 2: 0/6
INFO  : Map 1: 3(+3)/9Reducer 2: 0/6
INFO  : Map 1: 3(+3)/9Reducer 2: 0/6
INFO  : Map 1: 3(+3)/9Reducer 2: 0/6
INFO  : Map 1: 3(+3)/9Reducer 2: 0/6
INFO  : Map 1: 4(+3)/9Reducer 2: 0/6
INFO  : Map 1: 5(+2)/9Reducer 2: 0/6
INFO  : Map 1: 5(+3)/9Reducer 2: 0/6
INFO  : Map 1: 6(+2)/9Reducer 2: 0/6
INFO  : Map 1: 6(+3)/9Reducer 2: 0/6
INFO  : Map 1: 7(+2)/9Reducer 2: 0/6
INFO  : Map 1: 7(+2)/9Reducer 2: 0(+1)/6
INFO  : Map 1: 7(+2)/9Reducer 2: 0(+1)/6
INFO  : Map 1: 7(+2)/9Reducer 2: 0(+1)/6
INFO  : Map 1: 8(+1)/9Reducer 2: 0(+2)/6
INFO  : Map 1: 8(+1)/9Reducer 2: 0(+2)/6
INFO  : Map 1: 9/9Reducer 2: 0(+3)/6
INFO  : Map 1: 9/9Reducer 2: 1(+3)/6
INFO  : Map 1: 9/9Reducer 2: 2(+3)/6
INFO  : Map 1: 9/9Reducer 2: 4(+1)/6
INFO  : Map 1: 9/9Reducer 2: 5(+1)/6
INFO  : Map 1: 9/9Reducer 2: 6/6
INFO  : Completed executing command(queryId=hive_20220717073247_bf54c2a9-5646-47fd-b6cd-d6023c4a61b3); Time taken: 86.259 seconds
INFO  : OK
+--------+---------------------+
| month  |        price        |
+--------+---------------------+
| 11     | 1531016.899999858   |
| 10     | 1211538.4299998446  |
+--------+---------------------+
2 rows selected (86.715 seconds)
0: jdbc:hive2://localhost:10000/default> Closing: 0: jdbc:hive2://localhost:10000/default
[hadoop@ip-172-31-42-254 hive_cs]$ select october_sum,november_sum,november_sum - october)_ussum as Difference from (sel ect sum(price() beeline -u jdbc:hive2://localhost:10000/default  -n hadoop

Connecting to jdbc:hive2://localhost:10000/default
Connected to: Apache Hive (version 2.3.9-amzn-2)
Driver: Hive JDBC (version 2.3.9-amzn-2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
Beeline version 2.3.9-amzn-2 by Apache Hive
0: jdbc:hive2://localhost:10000/default> select month(event_time) as Month, sum(price) as Price from part_mnth_buck_type_tbl where event_type = 'purchase' group by month(event_time);t october_sum,november _sum ,november_sum - october_sum as Difference fro m (select sum(price) as Price fromwhere month(event_time) = '10sselect sum(price) as Price where month(event_time) = 10eselect sum(price) as Price where month(event_time) = 10lselect sum(price) as Price where month(event_time) = 10eselect sum(price) as Price where month(event_time) = 10cselect sum(price) as Price where month(event_time) = 10tselect sum(price) as Price where month(event_time) = 10 select sum(price) as Price where month(event_time) = 10*select sum(price) as Price where month(event_time) = 10 select sum(price) as Price where month(event_time) = 10fselect sum(price) as Price where month(event_time) = 10rselect sum(price) as Price where month(event_time) = 10oselect sum(price) as Price where month(event_time) = 10mselect sum(price) as Price where month(event_time) = 10 select sum(price) as Price where month(event_time) = 10select sum(price) as Price where month(event_time) = 10select sum(price) as Price where month(event_time) = 10select sum(price) as Price where month(event_time) = 10select sum(price) as Price where month(event_time) = 10select sum(price) as Price where month(event_time) = 10select sum(price) as Price where month(event_time) = 10select sum(price) as Price where month(event_time) = 10select sum(price) as Price where month(event_time) = 10select sum(price) as Price where month(event_time) = 10select sum(price) as Price where month(event_time) = 10select sum(price) as Price where month(event_time) = 10select sum(price) as Price where month(event_time) = 10select sum(price) as Price where month(event_time) = 10select sum(price) as Price where month(event_time) = 10 and eventy_type = 'puchaserchase',,  se;lect(sut sum(price) as Price wh Nov_Pric e as where monhtth(event_time) = 11 and event_type = 'purcahase');
Error: Error while compiling statement: FAILED: ParseException line 1:162 mismatched input ',' expecting ) near ''purchase'' in subquery source (state=42000,code=40000)
0: jdbc:hive2://localhost:10000/default> select october_sum,november_sum,november_sum - october_sum as Difference from (select sum(price) as Price where month(event_time) = 10 and event_type = 'purchase', select sum(price) as Nov_Price where month(event_time) = 11 and event_type = 'purchase');month(event_time) = 11 and event_type = 'purchase');month(event_time) as Month, sum(price) as Price from part_mnth_buck_type_tbl where event_type = 'purchase' group by month(event_time);how tables;elect month(event_time) as Month, sum(price) as Price from part_mnth_buck_type_tbl where event_type = 'purchase' group by month(event_time);october_sum,november_sum,november_sum - october_sum as Difference from (select sum(price) as Price where month(event_time) = 10 and event_type = 'purchase', select sum(price) as Nov_Price where month(event_time) = 11 and event_type = 'purchase');select october_sum,november_sum,november_sum - october_sum as Difference from (select sum(price) as Price where month(event_time) = 10 and event_type = 'purchase', select sum(price) as Nov_Price where month(event_time) = 11 and event_type = 'purchase');sselect sum(price) as Price where month(event_time) = 10 and event_type = 'purchase', select sum(price) as Nov_Pri ce where month(event_time) = 11 and event_type = 'purchase');eselect sum(price) as Price where month(event_time) = 10 and event_type = 'purchase', select sum(price) as Nov_Pr ice where month(event_time) = 11 and event_type = 'purchase');lselect sum(price) as Price where month(event_time) = 10 and event_type = 'purchase', select sum(price) as Nov_P rice where month(event_time) = 11 and event_type = 'purchase');eselect sum(price) as Price where month(event_time) = 10 and event_type = 'purchase', select sum(price) as Nov_ Price where month(event_time) = 11 and event_type = 'purchase');cselect sum(price) as Price where month(event_time) = 10 and event_type = 'purchase', select sum(price) as Nov _Price where month(event_time) = 11 and event_type = 'purchase');tselect sum(price) as Price where month(event_time) = 10 and event_type = 'purchase', select sum(price) as No v_Price where month(event_time) = 11 and event_type = 'purchase'); select sum(price) as Price where month(event_time) = 10 and event_type = 'purchase', select sum(price) as N ov_Price where month(event_time) = 11 and event_type = 'purchase');*select sum(price) as Price where month(event_time) = 10 and event_type = 'purchase', select sum(price) as  Nov_Price where month(event_time) = 11 and event_type = 'purchase'); select sum(price) as Price where month(event_time) = 10 and event_type = 'purchase', select sum(price) as  Nov_Price where month(event_time) = 11 and event_type = 'purchase');fselect sum(price) as Price where month(event_time) = 10 and event_type = 'purchase', select sum(price) a s Nov_Price where month(event_time) = 11 and event_type = 'purchase');rselect sum(price) as Price where month(event_time) = 10 and event_type = 'purchase', select sum(price)  as Nov_Price where month(event_time) = 11 and event_type = 'purchase');oselect sum(price) as Price where month(event_time) = 10 and event_type = 'purchase', select sum(price)  as Nov_Price where month(event_time) = 11 and event_type = 'purchase');mselect sum(price) as Price where month(event_time) = 10 and event_type = 'purchase', select sum(price ) as Nov_Price where month(event_time) = 11 and event_type = 'purchase'); select sum(price) as Price where month(event_time) = 10 and event_type = 'purchase', select sum(pric e) as Nov_Price where month(event_time) = 11 and event_type = 'purchase');(select sum(price) as Price where month(event_time) = 10 and event_type = 'purchase', select sum(pri ce) as Nov_Price where month(event_time) = 11 and event_type = 'purchase');), select sum(pr ice) as Nov_Price where month(event_time) = 11 and event_type = 'purchase');( select sum(p rice) as Nov_Price where month(event_time) = 11 and event_type = 'purchase');select sum(pr ice) as Nov_Price where month(event_time) = 11 and event_type = 'purchase');));
Error: Error while compiling statement: FAILED: ParseException line 1:178 cannot recognize input near ',' '(' 'select' in subquery source (state=42000,code=40000)
0: jdbc:hive2://localhost:10000/default> select october_sum,november_sum,november_sum - october_sum as Difference fro m (select * from (select sum(price) where month(event_time) = 10 and event_type = 'purchase') as october_sum,(select  sum(price) where month(event_time) = 11 and event_type = 'purchase') as november_sum);
Error: Error while compiling statement: FAILED: ParseException line 1:278 cannot recognize input near '<EOF>' '<EOF>' '<EOF>' in subquery source (state=42000,code=40000)
0: jdbc:hive2://localhost:10000/default> select october_sum,november_sum,november_sum - october_sum as Difference fro m (select sum(price) where month(event_time) = 10 and event_type = 'purchase' as october_sum,sum(price) where month(e vent_time) = 11 and event_type = 'purchase') as november_sum );
Error: Error while compiling statement: FAILED: ParseException line 1:154 missing ) at 'as' near ',' in joinSourcePart
line 1:173 cannot recognize input near 'sum' '(' 'price' in joinSourcePart (state=42000,code=40000)
0: jdbc:hive2://localhost:10000/default> select october_sum,november_sum,november_sum - october_sum as Difference fro m (select sum(price) where month(event_time) = 10 and event_type = 'purchase' as october_sum,sum(price) where month(e vent_time) = 11 and event_type = 'purchase') as november_sum from clickstream_tbl);
Error: Error while compiling statement: FAILED: ParseException line 1:154 missing ) at 'as' near ',' in joinSourcePart
line 1:173 cannot recognize input near 'sum' '(' 'price' in joinSourcePart (state=42000,code=40000)
0: jdbc:hive2://localhost:10000/default> select sum(price) where month(event_time) = 10 and event_type = 'purchase' a s october_sum,sum(price) where month(event_time) = 11 and event_type = 'purchase' as november_sum from clickstream_tb l;
Error: Error while compiling statement: FAILED: ParseException line 1:75 missing EOF at 'as' near ''purchase'' (state=42000,code=40000)
0: jdbc:hive2://localhost:10000/default> Closing: 0: jdbc:hive2://localhost:10000/default
[hadoop@ip-172-31-42-254 hive_cs]$ beeline -u jdbc:hive2://localhost:10000/default  -n hadoop
Connecting to jdbc:hive2://localhost:10000/default
Connected to: Apache Hive (version 2.3.9-amzn-2)
Driver: Hive JDBC (version 2.3.9-amzn-2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
Beeline version 2.3.9-amzn-2 by Apache Hive
0: jdbc:hive2://localhost:10000/default> use clickstream;
INFO  : Compiling command(queryId=hive_20220717075741_878b1b8c-5f63-43d3-9728-c7f8fd567a1a): use clickstream
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : EXPLAIN output for queryid hive_20220717075741_878b1b8c-5f63-43d3-9728-c7f8fd567a1a : STAGE DEPENDENCIES:
  Stage-0 is a root stage [DDL]

STAGE PLANS:
  Stage: Stage-0


INFO  : Completed compiling command(queryId=hive_20220717075741_878b1b8c-5f63-43d3-9728-c7f8fd567a1a); Time taken: 0.066 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717075741_878b1b8c-5f63-43d3-9728-c7f8fd567a1a): use clickstream
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20220717075741_878b1b8c-5f63-43d3-9728-c7f8fd567a1a); Time taken: 0.07 seconds
INFO  : OK
No rows affected (0.33 seconds)
0: jdbc:hive2://localhost:10000/default> select sum(price) as october_sum where month(event_time) = 10 and event_type  = 'purchase',sum(price) as november_sum where month(event_time) = 11 and event_type = 'purchase'  from clickstream_t bl;
Error: Error while compiling statement: FAILED: ParseException line 1:89 missing EOF at ',' near ''purchase'' (state=42000,code=40000)
0: jdbc:hive2://localhost:10000/default> select sum(price) as october_sum where month(event_time) = 10 and event_type  = 'purchase' from clickstream_tbl; 
Error: Error while compiling statement: FAILED: ParseException line 1:90 missing EOF at 'from' near ''purchase'' (state=42000,code=40000)
0: jdbc:hive2://localhost:10000/default> select sum(price) as october_sum from clickstream_tbl where month(event_time ) = 10 and event_type = 'purchase'; 
INFO  : Compiling command(queryId=hive_20220717075932_783fa7a0-250e-4e80-99ab-9b6380d3413c): select sum(price) as october_sum from clickstream_tbl where month(event_time) = 10 and event_type = 'purchase'
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:october_sum, type:double, comment:null)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717075932_783fa7a0-250e-4e80-99ab-9b6380d3413c : STAGE DEPENDENCIES:
  Stage-1 is a root stage [MAPRED]
  Stage-0 depends on stages: Stage-1 [FETCH]

STAGE PLANS:
  Stage: Stage-1
    Tez
      DagId: hive_20220717075932_783fa7a0-250e-4e80-99ab-9b6380d3413c:14
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
      DagName: 
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: clickstream_tbl
                  Statistics: Num rows: 3427938 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: ((month(event_time) = 10) and (event_type = 'purchase')) (type: boolean)
                    Statistics: Num rows: 856984 Data size: 257095273 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: price (type: string)
                      outputColumnNames: price
                      Statistics: Num rows: 856984 Data size: 257095273 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        aggregations: sum(price)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          null sort order: 
                          sort order: 
                          Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                          tag: -1
                          value expressions: _col0 (type: double)
                          auto parallelism: false
            Path -> Alias:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl [clickstream_tbl]
            Path -> Partition:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl 
                Partition
                  base file name: clickstream_tbl
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    column.name.delimiter ,
                    columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                    columns.comments 
                    columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                    escapeChar \
                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                    name clickstream.clickstream_tbl
                    numFiles 2
                    numRows 0
                    quoteChar "
                    rawDataSize 0
                    separatorChar ,
                    serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                    skip.header.line.count 1
                    totalSize 1028381690
                    transient_lastDdlTime 1658039808
                  serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      column.name.delimiter ,
                      columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                      columns.comments 
                      columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                      escapeChar \
                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                      name clickstream.clickstream_tbl
                      numFiles 2
                      numRows 0
                      quoteChar "
                      rawDataSize 0
                      separatorChar ,
                      serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                      skip.header.line.count 1
                      totalSize 1028381690
                      transient_lastDdlTime 1658039808
                    serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                    name: clickstream.clickstream_tbl
                  name: clickstream.clickstream_tbl
            Truncated Path -> Alias:
              /clickstream.db/clickstream_tbl [clickstream_tbl]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0)
                mode: mergepartial
                outputColumnNames: _col0
                Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
                  directory: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/9f3225c4-57a7-4bae-aa3f-82d454bae006/hive_2022-07-17_07-59-32_178_8803325391557029660-16/-mr-10001/.hive-staging_hive_2022-07-17_07-59-32_178_8803325391557029660-16/-ext-10002
                  NumFilesPerFileSink: 1
                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                  Stats Publishing Key Prefix: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/9f3225c4-57a7-4bae-aa3f-82d454bae006/hive_2022-07-17_07-59-32_178_8803325391557029660-16/-mr-10001/.hive-staging_hive_2022-07-17_07-59-32_178_8803325391557029660-16/-ext-10002/
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      properties:
                        columns _col0
                        columns.types double
                        escape.delim \
                        hive.serialization.extend.additional.nesting.levels true
                        serialization.escape.crlf true
                        serialization.format 1
                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  TotalFiles: 1
                  GatherStats: false
                  MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717075932_783fa7a0-250e-4e80-99ab-9b6380d3413c); Time taken: 0.213 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717075932_783fa7a0-250e-4e80-99ab-9b6380d3413c): select sum(price) as october_sum from clickstream_tbl where month(event_time) = 10 and event_type = 'purchase'
INFO  : Query ID = hive_20220717075932_783fa7a0-250e-4e80-99ab-9b6380d3413c
INFO  : Total jobs = 1
INFO  : Launching Job 1 out of 1
INFO  : Starting task [Stage-1:MAPRED] in serial mode
INFO  : Tez session hasn't been created yet. Opening session
INFO  : Dag name: select sum(price) as october_su...'purchase'(Stage-1)
INFO  : Status: Running (Executing on YARN cluster with App id application_1658032091232_0006)

INFO  : Map 1: -/-Reducer 2: 0/1
INFO  : Map 1: 0/2Reducer 2: 0/1
INFO  : Map 1: 0/2Reducer 2: 0/1
INFO  : Map 1: 0(+1)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 1(+1)/2Reducer 2: 0/1
INFO  : Map 1: 1(+1)/2Reducer 2: 0(+1)/1
INFO  : Map 1: 2/2Reducer 2: 0(+1)/1
INFO  : Map 1: 2/2Reducer 2: 1/1
INFO  : Completed executing command(queryId=hive_20220717075932_783fa7a0-250e-4e80-99ab-9b6380d3413c); Time taken: 77.904 seconds
INFO  : OK
+---------------------+
|     october_sum     |
+---------------------+
| 1211538.4299997438  |
+---------------------+
1 row selected (78.212 seconds)
0: jdbc:hive2://localhost:10000/default> select all.october_sum,all.november_sum from ( 
. . . . . . . . . . . . . . . . . . . .> select sum(price) as october_sum from clickstream_tbl where month(event_time ) = 10 and event_type = 'purchase'
. . . . . . . . . . . . . . . . . . . .> UNION ALL
. . . . . . . . . . . . . . . . . . . .> select sum(price) as november_sum from clickstream_tbl where month(event_tim e) = 11 and event_type = 'purchase' ) all;
Error: Error while compiling statement: FAILED: ParseException line 1:10 cannot recognize input near '.' 'october_sum' ',' in selection target (state=42000,code=40000)
0: jdbc:hive2://localhost:10000/default> select october_sum,november_sum from( 
. . . . . . . . . . . . . . . . . . . .> select sum(price) as october_sum from clickstream_tbl where month(event_time ) = 10 and event_type = 'purchase'
. . . . . . . . . . . . . . . . . . . .> UNION ALL
. . . . . . . . . . . . . . . . . . . .> select sum(price) as november_sum from clickstream_tbl where month(event_tim e) = 11 and event_type = 'purchase' );
Error: Error while compiling statement: FAILED: ParseException line 4:113 cannot recognize input near '<EOF>' '<EOF>' '<EOF>' in subquery source (state=42000,code=40000)
0: jdbc:hive2://localhost:10000/default> select October, November, November - October as Difference from( 
. . . . . . . . . . . . . . . . . . . .> SELECT sum(case when month(event_time)=10 then price else 0 end) as October_ price, sum(case when month(event_time)=11 then price else 0 end) as November_price from clickstream_tbl WHERE month(e vent_time)in (10,11) and event_type='purchase')s;
Error: Error while compiling statement: FAILED: SemanticException [Error 10004]: Line 1:7 Invalid table alias or column reference 'October': (possible column names are: october_price, november_price) (state=42000,code=10004)
0: jdbc:hive2://localhost:10000/default> select October_price, November_price, November_price - October_price as Diff erence from( 
. . . . . . . . . . . . . . . . . . . .> SELECT sum(case when month(event_time)=10 then price else 0 end) as October_ price, sum(case when month(event_time)=11 then price else 0 end) as November_price from clickstream_tbl WHERE month(e vent_time)in (10,11) and event_type='purchase')s;
INFO  : Compiling command(queryId=hive_20220717080906_04fdbeb0-296f-47c8-bb3c-a9d29995b98a): select October_price, November_price, November_price - October_price as Difference from(
SELECT sum(case when month(event_time)=10 then price else 0 end) as October_price, sum(case when month(event_time)=11 then price else 0 end) as November_price from clickstream_tbl WHERE month(event_time)in (10,11) and event_type='purchase')s
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:october_price, type:double, comment:null), FieldSchema(name:november_price, type:double, comment:null), FieldSchema(name:difference, type:double, comment:null)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717080906_04fdbeb0-296f-47c8-bb3c-a9d29995b98a : STAGE DEPENDENCIES:
  Stage-1 is a root stage [MAPRED]
  Stage-0 depends on stages: Stage-1 [FETCH]

STAGE PLANS:
  Stage: Stage-1
    Tez
      DagId: hive_20220717080906_04fdbeb0-296f-47c8-bb3c-a9d29995b98a:15
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
      DagName: 
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: clickstream_tbl
                  Statistics: Num rows: 4944142 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: ((month(event_time)) IN (10, 11) and (event_type = 'purchase')) (type: boolean)
                    Statistics: Num rows: 1236035 Data size: 257095319 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: event_time (type: string), price (type: string)
                      outputColumnNames: event_time, price
                      Statistics: Num rows: 1236035 Data size: 257095319 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        aggregations: sum(CASE WHEN ((month(event_time) = 10)) THEN (price) ELSE (0) END), sum(CASE WHEN ((month(event_time) = 11)) THEN (price) ELSE (0) END)
                        mode: hash
                        outputColumnNames: _col0, _col1
                        Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          null sort order: 
                          sort order: 
                          Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
                          tag: -1
                          value expressions: _col0 (type: double), _col1 (type: double)
                          auto parallelism: false
            Path -> Alias:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl [clickstream_tbl]
            Path -> Partition:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl 
                Partition
                  base file name: clickstream_tbl
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    column.name.delimiter ,
                    columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                    columns.comments 
                    columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                    escapeChar \
                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                    name clickstream.clickstream_tbl
                    numFiles 2
                    numRows 0
                    quoteChar "
                    rawDataSize 0
                    separatorChar ,
                    serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                    skip.header.line.count 1
                    totalSize 1028381690
                    transient_lastDdlTime 1658039808
                  serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      column.name.delimiter ,
                      columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                      columns.comments 
                      columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                      escapeChar \
                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                      name clickstream.clickstream_tbl
                      numFiles 2
                      numRows 0
                      quoteChar "
                      rawDataSize 0
                      separatorChar ,
                      serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                      skip.header.line.count 1
                      totalSize 1028381690
                      transient_lastDdlTime 1658039808
                    serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                    name: clickstream.clickstream_tbl
                  name: clickstream.clickstream_tbl
            Truncated Path -> Alias:
              /clickstream.db/clickstream_tbl [clickstream_tbl]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0), sum(VALUE._col1)
                mode: mergepartial
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: _col0 (type: double), _col1 (type: double), (_col1 - _col0) (type: double)
                  outputColumnNames: _col0, _col1, _col2
                  Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    GlobalTableId: 0
                    directory: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/9f3225c4-57a7-4bae-aa3f-82d454bae006/hive_2022-07-17_08-09-06_062_3378998536592036216-16/-mr-10001/.hive-staging_hive_2022-07-17_08-09-06_062_3378998536592036216-16/-ext-10002
                    NumFilesPerFileSink: 1
                    Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
                    Stats Publishing Key Prefix: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/9f3225c4-57a7-4bae-aa3f-82d454bae006/hive_2022-07-17_08-09-06_062_3378998536592036216-16/-mr-10001/.hive-staging_hive_2022-07-17_08-09-06_062_3378998536592036216-16/-ext-10002/
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        properties:
                          columns _col0,_col1,_col2
                          columns.types double:double:double
                          escape.delim \
                          hive.serialization.extend.additional.nesting.levels true
                          serialization.escape.crlf true
                          serialization.format 1
                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    TotalFiles: 1
                    GatherStats: false
                    MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717080906_04fdbeb0-296f-47c8-bb3c-a9d29995b98a); Time taken: 0.145 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717080906_04fdbeb0-296f-47c8-bb3c-a9d29995b98a): select October_price, November_price, November_price - October_price as Difference from(
SELECT sum(case when month(event_time)=10 then price else 0 end) as October_price, sum(case when month(event_time)=11 then price else 0 end) as November_price from clickstream_tbl WHERE month(event_time)in (10,11) and event_type='purchase')s
INFO  : Query ID = hive_20220717080906_04fdbeb0-296f-47c8-bb3c-a9d29995b98a
INFO  : Total jobs = 1
INFO  : Launching Job 1 out of 1
INFO  : Starting task [Stage-1:MAPRED] in serial mode
INFO  : Session is already open
INFO  : Dag name: select October_price,...nt_type='purchase')s(Stage-1)
INFO  : Tez session was closed. Reopening...
INFO  : Session re-established.
INFO  : Status: Running (Executing on YARN cluster with App id application_1658032091232_0007)

INFO  : Map 1: 0/2Reducer 2: 0/1
INFO  : Map 1: 0/2Reducer 2: 0/1
INFO  : Map 1: 0(+1)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/1
INFO  : Map 1: 1(+1)/2Reducer 2: 0/1
INFO  : Map 1: 1(+1)/2Reducer 2: 0(+1)/1
INFO  : Map 1: 1(+1)/2Reducer 2: 0(+1)/1
INFO  : Map 1: 2/2Reducer 2: 0(+1)/1
INFO  : Map 1: 2/2Reducer 2: 1/1
INFO  : Completed executing command(queryId=hive_20220717080906_04fdbeb0-296f-47c8-bb3c-a9d29995b98a); Time taken: 79.405 seconds
INFO  : OK
+---------------------+--------------------+--------------------+
|    october_price    |   november_price   |     difference     |
+---------------------+--------------------+--------------------+
| 1211538.4299997438  | 1531016.900000122  | 319478.4700003781  |
+---------------------+--------------------+--------------------+
1 row selected (79.576 seconds)
0: jdbc:hive2://localhost:10000/default> Closing: 0: jdbc:hive2://localhost:10000/default
[hadoop@ip-172-31-42-254 hive_cs]$ ^C
[hadoop@ip-172-31-42-254 hive_cs]$ beeline -u jdbc:hive2://localhost:10000/default  -n hadoop
Connecting to jdbc:hive2://localhost:10000/default
Connected to: Apache Hive (version 2.3.9-amzn-2)
Driver: Hive JDBC (version 2.3.9-amzn-2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
Beeline version 2.3.9-amzn-2 by Apache Hive
0: jdbc:hive2://localhost:10000/default> SELECT sum(case when month(event_time)=10 then price else 0 end) as October_ price, sum(case when month(event_time)=11 then price else 0 end) as November_price from part_mnth_buck_type_tbl WHERE  month(event_time)in (10,11) and event_type='purchase')all;
Error: Error while compiling statement: FAILED: ParseException line 1:247 missing EOF at ')' near ''purchase'' (state=42000,code=40000)
0: jdbc:hive2://localhost:10000/default> select October_price, November_price, November_price - October_price as Diff erence from( 
. . . . . . . . . . . . . . . . . . . .> SELECT sum(case when month(event_time)=10 then price else 0 end) as October_ price, sum(case when month(event_time)=11 then price else 0 end) as November_price from part_mnth_buck_type_tbl WHERE  month(event_time)in (10,11) and event_type='purchase')all;
Error: Error while compiling statement: FAILED: ParseException line 2:248 cannot recognize input near 'all' '<EOF>' '<EOF>' in subquery source (state=42000,code=40000)
0: jdbc:hive2://localhost:10000/default> select October_price, November_price, November_price - October_price as Diff erence from(select sum(case when month(event_time)=10 then price else 0 end) as October_price, sum(case when month(ev ent_time)=11 then price else 0 end) as November_price from part_mnth_buck_type_tbl WHERE month(event_time)in (10,11)  and event_type='purchase')all;
Error: Error while compiling statement: FAILED: ParseException line 1:336 cannot recognize input near 'all' '<EOF>' '<EOF>' in subquery source (state=42000,code=40000)
0: jdbc:hive2://localhost:10000/default> select October_price, November_price, November_price - October_price as Diff erence from(select sum(case when month(event_time)=10 then price else 0 end) as October_price, sum(case when month(ev ent_time)=11 then price else 0 end) as November_price from part_mnth_buck_type_tbl WHERE month(event_time)in (10,11)  and event_type='purchase')a;
Error: Error while compiling statement: FAILED: SemanticException [Error 10001]: Line 1:252 Table not found 'part_mnth_buck_type_tbl' (state=42S02,code=10001)
0: jdbc:hive2://localhost:10000/default> select October_price, November_price, November_price - October_price as Diff erence from(select sum(case when month(event_time)=10 then price else 0 end) as October_price, sum(case when month(ev ent_time)=11 then price else 0 end) as November_price from part_mnth_buck_type_tbl WHERE month(event_time)in (10,11)  and event_type='purchase')s;
Error: Error while compiling statement: FAILED: SemanticException [Error 10001]: Line 1:252 Table not found 'part_mnth_buck_type_tbl' (state=42S02,code=10001)
0: jdbc:hive2://localhost:10000/default> use clickstream;
INFO  : Compiling command(queryId=hive_20220717081421_b608d4f2-1987-4e9e-8c7c-1bb6d9cc11de): use clickstream
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : EXPLAIN output for queryid hive_20220717081421_b608d4f2-1987-4e9e-8c7c-1bb6d9cc11de : STAGE DEPENDENCIES:
  Stage-0 is a root stage [DDL]

STAGE PLANS:
  Stage: Stage-0


INFO  : Completed compiling command(queryId=hive_20220717081421_b608d4f2-1987-4e9e-8c7c-1bb6d9cc11de); Time taken: 0.024 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717081421_b608d4f2-1987-4e9e-8c7c-1bb6d9cc11de): use clickstream
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20220717081421_b608d4f2-1987-4e9e-8c7c-1bb6d9cc11de); Time taken: 0.017 seconds
INFO  : OK
No rows affected (0.156 seconds)
0: jdbc:hive2://localhost:10000/default> select October_price, November_price, November_price - October_price as Diff erence from(select sum(case when month(event_time)=10 then price else 0 end) as October_price, sum(case when month(ev ent_time)=11 then price else 0 end) as November_price from part_mnth_buck_type_tbl WHERE month(event_time)in (10,11)  and event_type='purchase')all;
Error: Error while compiling statement: FAILED: ParseException line 1:336 cannot recognize input near 'all' '<EOF>' '<EOF>' in subquery source (state=42000,code=40000)
0: jdbc:hive2://localhost:10000/default> select October_price, November_price, November_price - October_price as Diff erence from(select sum(case when month(event_time)=10 then price else 0 end) as October_price, sum(case when month(ev ent_time)=11 then price else 0 end) as November_price from part_mnth_buck_type_tbl WHERE month(event_time)in (10,11)  and event_type='purchase')s;
INFO  : Compiling command(queryId=hive_20220717081501_bdd33f86-816d-4df7-8236-b707640fc779): select October_price, November_price, November_price - October_price as Difference from(select sum(case when month(event_time)=10 then price else 0 end) as October_price, sum(case when month(event_time)=11 then price else 0 end) as November_price from part_mnth_buck_type_tbl WHERE month(event_time)in (10,11) and event_type='purchase')s
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:october_price, type:double, comment:null), FieldSchema(name:november_price, type:double, comment:null), FieldSchema(name:difference, type:double, comment:null)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717081501_bdd33f86-816d-4df7-8236-b707640fc779 : STAGE DEPENDENCIES:
  Stage-1 is a root stage [MAPRED]
  Stage-0 depends on stages: Stage-1 [FETCH]

STAGE PLANS:
  Stage: Stage-1
    Tez
      DagId: hive_20220717081501_bdd33f86-816d-4df7-8236-b707640fc779:16
      Edges:
        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
      DagName: 
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part_mnth_buck_type_tbl
                  Statistics: Num rows: 8738120 Data size: 1255572626 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: ((month(event_time)) IN (10, 11) and (event_type = 'purchase')) (type: boolean)
                    Statistics: Num rows: 2184530 Data size: 313893156 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: event_time (type: string), price (type: string)
                      outputColumnNames: event_time, price
                      Statistics: Num rows: 2184530 Data size: 313893156 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        aggregations: sum(CASE WHEN ((month(event_time) = 10)) THEN (price) ELSE (0) END), sum(CASE WHEN ((month(event_time) = 11)) THEN (price) ELSE (0) END)
                        mode: hash
                        outputColumnNames: _col0, _col1
                        Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          null sort order: 
                          sort order: 
                          Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
                          tag: -1
                          value expressions: _col0 (type: double), _col1 (type: double)
                          auto parallelism: false
            Path -> Alias:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl/mnth=10 [part_mnth_buck_type_tbl]
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl/mnth=11 [part_mnth_buck_type_tbl]
            Path -> Partition:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl/mnth=10 
                Partition
                  base file name: mnth=10
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    mnth 10
                  properties:
                    COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
                    bucket_count 4
                    bucket_field_name event_type
                    column.name.delimiter ,
                    columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                    columns.comments 
                    columns.types string:string:string:string:string:string:decimal(10,3):bigint:string
                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl/mnth=10
                    name clickstream.part_mnth_buck_type_tbl
                    numFiles 3
                    numRows 4102283
                    partition_columns mnth
                    partition_columns.types int
                    rawDataSize 0
                    serialization.ddl struct part_mnth_buck_type_tbl { string event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                    totalSize 556383280
                    transient_lastDdlTime 1658042010
                  serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count 4
                      bucket_field_name event_type
                      column.name.delimiter ,
                      columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                      columns.comments 
                      columns.types string:string:string:string:string:string:decimal(10,3):bigint:string
                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl
                      name clickstream.part_mnth_buck_type_tbl
                      partition_columns mnth
                      partition_columns.types int
                      serialization.ddl struct part_mnth_buck_type_tbl { string event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                      transient_lastDdlTime 1658041789
                    serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                    name: clickstream.part_mnth_buck_type_tbl
                  name: clickstream.part_mnth_buck_type_tbl
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl/mnth=11 
                Partition
                  base file name: mnth=11
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    mnth 11
                  properties:
                    COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
                    bucket_count 4
                    bucket_field_name event_type
                    column.name.delimiter ,
                    columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                    columns.comments 
                    columns.types string:string:string:string:string:string:decimal(10,3):bigint:string
                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl/mnth=11
                    name clickstream.part_mnth_buck_type_tbl
                    numFiles 3
                    numRows 4635837
                    partition_columns mnth
                    partition_columns.types int
                    rawDataSize 0
                    serialization.ddl struct part_mnth_buck_type_tbl { string event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                    totalSize 629284386
                    transient_lastDdlTime 1658042011
                  serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count 4
                      bucket_field_name event_type
                      column.name.delimiter ,
                      columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                      columns.comments 
                      columns.types string:string:string:string:string:string:decimal(10,3):bigint:string
                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl
                      name clickstream.part_mnth_buck_type_tbl
                      partition_columns mnth
                      partition_columns.types int
                      serialization.ddl struct part_mnth_buck_type_tbl { string event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                      transient_lastDdlTime 1658041789
                    serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                    name: clickstream.part_mnth_buck_type_tbl
                  name: clickstream.part_mnth_buck_type_tbl
            Truncated Path -> Alias:
              /clickstream.db/part_mnth_buck_type_tbl/mnth=10 [part_mnth_buck_type_tbl]
              /clickstream.db/part_mnth_buck_type_tbl/mnth=11 [part_mnth_buck_type_tbl]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0), sum(VALUE._col1)
                mode: mergepartial
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: _col0 (type: double), _col1 (type: double), (_col1 - _col0) (type: double)
                  outputColumnNames: _col0, _col1, _col2
                  Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    GlobalTableId: 0
                    directory: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/d54829f2-1af3-4d65-b35a-946ad7499ac6/hive_2022-07-17_08-15-01_986_5635997424666977332-19/-mr-10001/.hive-staging_hive_2022-07-17_08-15-01_986_5635997424666977332-19/-ext-10002
                    NumFilesPerFileSink: 1
                    Statistics: Num rows: 1 Data size: 16 Basic stats: COMPLETE Column stats: NONE
                    Stats Publishing Key Prefix: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/d54829f2-1af3-4d65-b35a-946ad7499ac6/hive_2022-07-17_08-15-01_986_5635997424666977332-19/-mr-10001/.hive-staging_hive_2022-07-17_08-15-01_986_5635997424666977332-19/-ext-10002/
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        properties:
                          columns _col0,_col1,_col2
                          columns.types double:double:double
                          escape.delim \
                          hive.serialization.extend.additional.nesting.levels true
                          serialization.escape.crlf true
                          serialization.format 1
                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    TotalFiles: 1
                    GatherStats: false
                    MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717081501_bdd33f86-816d-4df7-8236-b707640fc779); Time taken: 0.17 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717081501_bdd33f86-816d-4df7-8236-b707640fc779): select October_price, November_price, November_price - October_price as Difference from(select sum(case when month(event_time)=10 then price else 0 end) as October_price, sum(case when month(event_time)=11 then price else 0 end) as November_price from part_mnth_buck_type_tbl WHERE month(event_time)in (10,11) and event_type='purchase')s
INFO  : Query ID = hive_20220717081501_bdd33f86-816d-4df7-8236-b707640fc779
INFO  : Total jobs = 1
INFO  : Launching Job 1 out of 1
INFO  : Starting task [Stage-1:MAPRED] in serial mode
INFO  : Tez session hasn't been created yet. Opening session
INFO  : Dag name: select October_price,...nt_type='purchase')s(Stage-1)
INFO  : Status: Running (Executing on YARN cluster with App id application_1658032091232_0008)

INFO  : Map 1: -/-Reducer 2: 0/1
INFO  : Map 1: 0/9Reducer 2: 0/1
INFO  : Map 1: 0/9Reducer 2: 0/1
INFO  : Map 1: 0/9Reducer 2: 0/1
INFO  : Map 1: 0(+1)/9Reducer 2: 0/1
INFO  : Map 1: 0(+2)/9Reducer 2: 0/1
INFO  : Map 1: 0(+3)/9Reducer 2: 0/1
INFO  : Map 1: 0(+3)/9Reducer 2: 0/1
INFO  : Map 1: 0(+3)/9Reducer 2: 0/1
INFO  : Map 1: 0(+3)/9Reducer 2: 0/1
INFO  : Map 1: 0(+3)/9Reducer 2: 0/1
INFO  : Map 1: 0(+3)/9Reducer 2: 0/1
INFO  : Map 1: 0(+3)/9Reducer 2: 0/1
INFO  : Map 1: 0(+3)/9Reducer 2: 0/1
INFO  : Map 1: 0(+3)/9Reducer 2: 0/1
INFO  : Map 1: 0(+3)/9Reducer 2: 0/1
INFO  : Map 1: 0(+3)/9Reducer 2: 0/1
INFO  : Map 1: 1(+3)/9Reducer 2: 0/1
INFO  : Map 1: 2(+3)/9Reducer 2: 0/1
INFO  : Map 1: 3(+3)/9Reducer 2: 0/1
INFO  : Map 1: 3(+3)/9Reducer 2: 0/1
INFO  : Map 1: 3(+3)/9Reducer 2: 0/1
INFO  : Map 1: 3(+3)/9Reducer 2: 0/1
INFO  : Map 1: 3(+3)/9Reducer 2: 0/1
INFO  : Map 1: 3(+3)/9Reducer 2: 0/1
INFO  : Map 1: 3(+3)/9Reducer 2: 0/1
INFO  : Map 1: 4(+3)/9Reducer 2: 0/1
INFO  : Map 1: 4(+3)/9Reducer 2: 0/1
INFO  : Map 1: 5(+3)/9Reducer 2: 0/1
INFO  : Map 1: 6(+2)/9Reducer 2: 0/1
INFO  : Map 1: 6(+3)/9Reducer 2: 0/1
INFO  : Map 1: 7(+2)/9Reducer 2: 0(+1)/1
INFO  : Map 1: 7(+2)/9Reducer 2: 0(+1)/1
INFO  : Map 1: 7(+2)/9Reducer 2: 0(+1)/1
INFO  : Map 1: 8(+1)/9Reducer 2: 0(+1)/1
INFO  : Map 1: 8(+1)/9Reducer 2: 0(+1)/1
INFO  : Map 1: 8(+1)/9Reducer 2: 0(+1)/1
INFO  : Map 1: 9/9Reducer 2: 0(+1)/1
INFO  : Map 1: 9/9Reducer 2: 1/1
INFO  : Completed executing command(queryId=hive_20220717081501_bdd33f86-816d-4df7-8236-b707640fc779); Time taken: 97.773 seconds
INFO  : OK
+---------------------+--------------------+--------------------+
|    october_price    |   november_price   |     difference     |
+---------------------+--------------------+--------------------+
| 1211538.4299998444  | 1531016.899999858  | 319478.4700000137  |
+---------------------+--------------------+--------------------+
1 row selected (98.083 seconds)
0: jdbc:hive2://localhost:10000/default> Closing: 0: jdbc:hive2://localhost:10000/default
[hadoop@ip-172-31-42-254 hive_cs]$ beeline -u jdbc:hive2://localhost:10000/default  -n hadoop\\
> beeline -u jdbc:hive2://localhost:10000/default  -n hadoop\select month(event_time) as Month, sum(price) as Price from part_mnth_buck_type_tbl where event_type = 'purchase' grroup by month(event_time);beeline -u jdbc:hive2://localhost:10000/default  -n hadoop

^C[hadoop@ip-172-31-42-254 hive_cs]$ beeline -u jdbc:hive2://localhost:10000/default  -n hadoopbeeline -u jdbc:hive2://llocalhost:10000/default  -n hadoop
beeline -u jdbc:hive2://llocalhost:10000/default  -n hadoop
Connecting to jdbc:hive2://localhost:10000/default
Connected to: Apache Hive (version 2.3.9-amzn-2)
Driver: Hive JDBC (version 2.3.9-amzn-2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
Beeline version 2.3.9-amzn-2 by Apache Hive
0: jdbc:hive2://localhost:10000/default> select distinct(category_Code) code) from clickstream_tbl where category_code is n ot Null and category code _code != "";
Error: Error while compiling statement: FAILED: SemanticException [Error 10001]: Line 1:36 Table not found 'clickstream_tbl' (state=42S02,code=10001)
0: jdbc:hive2://localhost:10000/default> use clicksterream;
INFO  : Compiling command(queryId=hive_20220717082428_6a1f8d31-98a5-4a07-859a-25b1d41fb832): use clickstream
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : EXPLAIN output for queryid hive_20220717082428_6a1f8d31-98a5-4a07-859a-25b1d41fb832 : STAGE DEPENDENCIES:
  Stage-0 is a root stage [DDL]

STAGE PLANS:
  Stage: Stage-0


INFO  : Completed compiling command(queryId=hive_20220717082428_6a1f8d31-98a5-4a07-859a-25b1d41fb832); Time taken: 0.021 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717082428_6a1f8d31-98a5-4a07-859a-25b1d41fb832): use clickstream
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20220717082428_6a1f8d31-98a5-4a07-859a-25b1d41fb832); Time taken: 0.037 seconds
INFO  : OK
No rows affected (0.133 seconds)
0: jdbc:hive2://localhost:10000/default> select distinct(category_code) from clickstream_tbl where category_code is n ot Null and category_code != "";
INFO  : Compiling command(queryId=hive_20220717082438_6b1cf547-a8b5-42ef-bee1-3ac18b332e0f): select distinct(category_code) from clickstream_tbl where category_code is not Null and category_code != ""
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:category_code, type:string, comment:null)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717082438_6b1cf547-a8b5-42ef-bee1-3ac18b332e0f : STAGE DEPENDENCIES:
  Stage-1 is a root stage [MAPRED]
  Stage-0 depends on stages: Stage-1 [FETCH]

STAGE PLANS:
  Stage: Stage-1
    Tez
      DagId: hive_20220717082438_6b1cf547-a8b5-42ef-bee1-3ac18b332e0f:17
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
      DagName: 
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: clickstream_tbl
                  Statistics: Num rows: 10283816 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: (category_code <> '') (type: boolean)
                    Statistics: Num rows: 10283816 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      keys: category_code (type: string)
                      mode: hash
                      outputColumnNames: _col0
                      Statistics: Num rows: 10283816 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: string)
                        null sort order: a
                        sort order: +
                        Map-reduce partition columns: _col0 (type: string)
                        Statistics: Num rows: 10283816 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                        tag: -1
                        auto parallelism: true
            Path -> Alias:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl [clickstream_tbl]
            Path -> Partition:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl 
                Partition
                  base file name: clickstream_tbl
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    column.name.delimiter ,
                    columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                    columns.comments 
                    columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                    escapeChar \
                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                    name clickstream.clickstream_tbl
                    numFiles 2
                    numRows 0
                    quoteChar "
                    rawDataSize 0
                    separatorChar ,
                    serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                    skip.header.line.count 1
                    totalSize 1028381690
                    transient_lastDdlTime 1658039808
                  serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      column.name.delimiter ,
                      columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                      columns.comments 
                      columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                      escapeChar \
                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                      name clickstream.clickstream_tbl
                      numFiles 2
                      numRows 0
                      quoteChar "
                      rawDataSize 0
                      separatorChar ,
                      serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                      skip.header.line.count 1
                      totalSize 1028381690
                      transient_lastDdlTime 1658039808
                    serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                    name: clickstream.clickstream_tbl
                  name: clickstream.clickstream_tbl
            Truncated Path -> Alias:
              /clickstream.db/clickstream_tbl [clickstream_tbl]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Group By Operator
                keys: KEY._col0 (type: string)
                mode: mergepartial
                outputColumnNames: _col0
                Statistics: Num rows: 5141908 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
                  directory: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoopbeeline/4e9c1b42-fcb5-47eb-b575-a9476e38c8a8/hive_2022-07-17_08-24-38_603_8755508420878288403-19/-mr-10001/.hive-staging_hive_2022-07-17_08-24-38_603_8755508420878288403-19/-ext-10002
                  NumFilesPerFileSink: 1
                  Statistics: Num rows: 5141908 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                  Stats Publishing Key Prefix: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoopbeeline/4e9c1b42-fcb5-47eb-b575-a9476e38c8a8/hive_2022-07-17_08-24-38_603_8755508420878288403-19/-mr-10001/.hive-staging_hive_2022-07-17_08-24-38_603_8755508420878288403-19/-ext-10002/
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      properties:
                        columns _col0
                        columns.types string
                        escape.delim \
                        hive.serialization.extend.additional.nesting.levels true
                        serialization.escape.crlf true
                        serialization.format 1
                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  TotalFiles: 1
                  GatherStats: false
                  MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717082438_6b1cf547-a8b5-42ef-bee1-3ac18b332e0f); Time taken: 0.156 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717082438_6b1cf547-a8b5-42ef-bee1-3ac18b332e0f): select distinct(category_code) from clickstream_tbl where category_code is not Null and category_code != ""
INFO  : Query ID = hive_20220717082438_6b1cf547-a8b5-42ef-bee1-3ac18b332e0f
INFO  : Total jobs = 1
INFO  : Launching Job 1 out of 1
INFO  : Starting task [Stage-1:MAPRED] in serial mode
INFO  : Tez session hasn't been created yet. Opening session
ERROR : Failed to execute tez graph.
org.apache.hadoop.security.AccessControlException: Permission denied: user=hadoopbeeline, access=WRITE, inode="/user":hdfs:hdfsadmingroup:drwxr-xr-x
at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:351)
at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:251)
at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:189)
at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1756)
at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1740)
at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1699)
at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:60)
at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3017)
at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:1132)
at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:662)
at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:507)
at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1034)
at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1003)
at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:931)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:422)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1926)
at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2854)

at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:1.8.0_332]
at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[?:1.8.0_332]
at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_332]
at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_332]
at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2507) ~[hadoop-hdfs-client-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2480) ~[hadoop-hdfs-client-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1243) ~[hadoop-hdfs-client-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1240) ~[hadoop-hdfs-client-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:1257) ~[hadoop-hdfs-client-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:1232) ~[hadoop-hdfs-client-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:2269) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.hive.ql.exec.tez.DagUtils.getDefaultDestDir(DagUtils.java:823) ~[hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.exec.tez.DagUtils.getHiveJarDirectory(DagUtils.java:917) ~[hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.exec.tez.TezSessionState.createJarLocalResource(TezSessionState.java:621) ~[hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.exec.tez.TezSessionState.openInternal(TezSessionState.java:251) ~[hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.exec.tez.TezSessionPoolManager$TezSessionPoolSession.openInternal(TezSessionPoolManager.java:703) ~[hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.exec.tez.TezSessionState.open(TezSessionState.java:196) ~[hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.exec.tez.TezTask.updateSession(TezTask.java:304) ~[hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.exec.tez.TezTask.execute(TezTask.java:169) [hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:203) [hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:100) [hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:2183) [hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1839) [hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1526) [hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1237) [hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1232) [hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:252) [hive-service-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hive.service.cli.operation.SQLOperation.access$800(SQLOperation.java:88) [hive-service-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:345) [hive-service-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_332]
at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_332]
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1926) [hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:360) [hive-service-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_332]
at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_332]
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_332]
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_332]
at java.lang.Thread.run(Thread.java:750) [?:1.8.0_332]
Caused by: org.apache.hadoop.ipc.RemoteException: Permission denied: user=hadoopbeeline, access=WRITE, inode="/user":hdfs:hdfsadmingroup:drwxr-xr-x
at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:351)
at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:251)
at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:189)
at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1756)
at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1740)
at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1699)
at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:60)
at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3017)
at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:1132)
at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:662)
at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:507)
at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1034)
at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1003)
at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:931)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:422)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1926)
at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2854)

at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.ipc.Client.call(Client.java:1495) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.ipc.Client.call(Client.java:1394) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at com.sun.proxy.$Proxy30.mkdirs(Unknown Source) ~[?:?]
at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:589) ~[hadoop-hdfs-client-2.10.1-amzn-4.jar:?]
at sun.reflect.GeneratedMethodAccessor11.invoke(Unknown Source) ~[?:?]
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_332]
at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_332]
at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at com.sun.proxy.$Proxy31.mkdirs(Unknown Source) ~[?:?]
at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2505) ~[hadoop-hdfs-client-2.10.1-amzn-4.jar:?]
... 34 more
ERROR : FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.tez.TezTask
INFO  : Completed executing command(queryId=hive_20220717082438_6b1cf547-a8b5-42ef-bee1-3ac18b332e0f); Time taken: 2.003 seconds
Error: org.apache.hive.service.cli.HiveSQLException: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.tez.TezTask
at org.apache.hive.service.cli.operation.Operation.toSQLException(Operation.java:380)
at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:254)
at org.apache.hive.service.cli.operation.SQLOperation.access$800(SQLOperation.java:88)
at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:345)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:422)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1926)
at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:360)
at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
at java.util.concurrent.FutureTask.run(FutureTask.java:266)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
at java.lang.Thread.run(Thread.java:750) (state=08S01,code=1)
0: jdbc:hive2://localhost:10000/default> select distinct(category_code) from clickstream_tbl where category_code is not Null and category_code != "";code != "";select distinct(category_code) from clickstream_tbl where category_code is not Null and category_code != ""; category_code != ""; category_code != ""; category_code != "";o category_code != "";r category_code != "";  category_code != "";
INFO  : Compiling command(queryId=hive_20220717082515_62e200f4-690e-4b15-8e99-5caa100bef73): select distinct(category_code) from clickstream_tbl where category_code is not Null or  category_code != ""
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:category_code, type:string, comment:null)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717082515_62e200f4-690e-4b15-8e99-5caa100bef73 : STAGE DEPENDENCIES:
  Stage-1 is a root stage [MAPRED]
  Stage-0 depends on stages: Stage-1 [FETCH]

STAGE PLANS:
  Stage: Stage-1
    Tez
      DagId: hive_20220717082515_62e200f4-690e-4b15-8e99-5caa100bef73:18
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
      DagName: 
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: clickstream_tbl
                  Statistics: Num rows: 10283816 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: (category_code is not null or (category_code <> '')) (type: boolean)
                    Statistics: Num rows: 10283816 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      keys: category_code (type: string)
                      mode: hash
                      outputColumnNames: _col0
                      Statistics: Num rows: 10283816 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: string)
                        null sort order: a
                        sort order: +
                        Map-reduce partition columns: _col0 (type: string)
                        Statistics: Num rows: 10283816 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                        tag: -1
                        auto parallelism: true
            Path -> Alias:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl [clickstream_tbl]
            Path -> Partition:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl 
                Partition
                  base file name: clickstream_tbl
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    column.name.delimiter ,
                    columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                    columns.comments 
                    columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                    escapeChar \
                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                    name clickstream.clickstream_tbl
                    numFiles 2
                    numRows 0
                    quoteChar "
                    rawDataSize 0
                    separatorChar ,
                    serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                    skip.header.line.count 1
                    totalSize 1028381690
                    transient_lastDdlTime 1658039808
                  serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      column.name.delimiter ,
                      columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                      columns.comments 
                      columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                      escapeChar \
                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                      name clickstream.clickstream_tbl
                      numFiles 2
                      numRows 0
                      quoteChar "
                      rawDataSize 0
                      separatorChar ,
                      serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                      skip.header.line.count 1
                      totalSize 1028381690
                      transient_lastDdlTime 1658039808
                    serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                    name: clickstream.clickstream_tbl
                  name: clickstream.clickstream_tbl
            Truncated Path -> Alias:
              /clickstream.db/clickstream_tbl [clickstream_tbl]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Group By Operator
                keys: KEY._col0 (type: string)
                mode: mergepartial
                outputColumnNames: _col0
                Statistics: Num rows: 5141908 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
                  directory: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoopbeeline/4e9c1b42-fcb5-47eb-b575-a9476e38c8a8/hive_2022-07-17_08-25-15_178_2512114725309619928-19/-mr-10001/.hive-staging_hive_2022-07-17_08-25-15_178_2512114725309619928-19/-ext-10002
                  NumFilesPerFileSink: 1
                  Statistics: Num rows: 5141908 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                  Stats Publishing Key Prefix: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoopbeeline/4e9c1b42-fcb5-47eb-b575-a9476e38c8a8/hive_2022-07-17_08-25-15_178_2512114725309619928-19/-mr-10001/.hive-staging_hive_2022-07-17_08-25-15_178_2512114725309619928-19/-ext-10002/
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      properties:
                        columns _col0
                        columns.types string
                        escape.delim \
                        hive.serialization.extend.additional.nesting.levels true
                        serialization.escape.crlf true
                        serialization.format 1
                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  TotalFiles: 1
                  GatherStats: false
                  MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717082515_62e200f4-690e-4b15-8e99-5caa100bef73); Time taken: 0.185 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717082515_62e200f4-690e-4b15-8e99-5caa100bef73): select distinct(category_code) from clickstream_tbl where category_code is not Null or  category_code != ""
INFO  : Query ID = hive_20220717082515_62e200f4-690e-4b15-8e99-5caa100bef73
INFO  : Total jobs = 1
INFO  : Launching Job 1 out of 1
INFO  : Starting task [Stage-1:MAPRED] in serial mode
WARN  : The session: sessionId=be73530f-5e02-40dd-9620-631b606bd76d, queueName=null, user=hadoopbeeline, doAs=true, isOpen=false, isDefault=false has not been opened
INFO  : Tez session hasn't been created yet. Opening session
ERROR : Failed to execute tez graph.
org.apache.hadoop.security.AccessControlException: Permission denied: user=hadoopbeeline, access=WRITE, inode="/user":hdfs:hdfsadmingroup:drwxr-xr-x
at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:351)
at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:251)
at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:189)
at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1756)
at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1740)
at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1699)
at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:60)
at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3017)
at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:1132)
at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:662)
at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:507)
at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1034)
at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1003)
at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:931)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:422)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1926)
at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2854)

at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:1.8.0_332]
at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[?:1.8.0_332]
at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_332]
at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_332]
at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2507) ~[hadoop-hdfs-client-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2480) ~[hadoop-hdfs-client-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1243) ~[hadoop-hdfs-client-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1240) ~[hadoop-hdfs-client-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:1257) ~[hadoop-hdfs-client-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:1232) ~[hadoop-hdfs-client-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:2269) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.hive.ql.exec.tez.DagUtils.getDefaultDestDir(DagUtils.java:823) ~[hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.exec.tez.DagUtils.getHiveJarDirectory(DagUtils.java:917) ~[hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.exec.tez.TezSessionState.createJarLocalResource(TezSessionState.java:621) ~[hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.exec.tez.TezSessionState.openInternal(TezSessionState.java:251) ~[hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.exec.tez.TezSessionPoolManager$TezSessionPoolSession.openInternal(TezSessionPoolManager.java:703) ~[hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.exec.tez.TezSessionState.open(TezSessionState.java:196) ~[hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.exec.tez.TezTask.updateSession(TezTask.java:304) ~[hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.exec.tez.TezTask.execute(TezTask.java:169) [hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:203) [hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:100) [hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:2183) [hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1839) [hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1526) [hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1237) [hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1232) [hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:252) [hive-service-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hive.service.cli.operation.SQLOperation.access$800(SQLOperation.java:88) [hive-service-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:345) [hive-service-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_332]
at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_332]
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1926) [hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:360) [hive-service-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_332]
at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_332]
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_332]
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_332]
at java.lang.Thread.run(Thread.java:750) [?:1.8.0_332]
Caused by: org.apache.hadoop.ipc.RemoteException: Permission denied: user=hadoopbeeline, access=WRITE, inode="/user":hdfs:hdfsadmingroup:drwxr-xr-x
at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:351)
at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:251)
at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:189)
at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1756)
at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1740)
at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1699)
at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:60)
at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3017)
at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:1132)
at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:662)
at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:507)
at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1034)
at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1003)
at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:931)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:422)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1926)
at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2854)

at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.ipc.Client.call(Client.java:1495) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.ipc.Client.call(Client.java:1394) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at com.sun.proxy.$Proxy30.mkdirs(Unknown Source) ~[?:?]
at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:589) ~[hadoop-hdfs-client-2.10.1-amzn-4.jar:?]
at sun.reflect.GeneratedMethodAccessor11.invoke(Unknown Source) ~[?:?]
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_332]
at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_332]
at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at com.sun.proxy.$Proxy31.mkdirs(Unknown Source) ~[?:?]
at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2505) ~[hadoop-hdfs-client-2.10.1-amzn-4.jar:?]
... 34 more
ERROR : FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.tez.TezTask
INFO  : Completed executing command(queryId=hive_20220717082515_62e200f4-690e-4b15-8e99-5caa100bef73); Time taken: 0.396 seconds
Error: org.apache.hive.service.cli.HiveSQLException: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.tez.TezTask
at org.apache.hive.service.cli.operation.Operation.toSQLException(Operation.java:380)
at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:254)
at org.apache.hive.service.cli.operation.SQLOperation.access$800(SQLOperation.java:88)
at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:345)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:422)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1926)
at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:360)
at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
at java.util.concurrent.FutureTask.run(FutureTask.java:266)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
at java.lang.Thread.run(Thread.java:750) (state=08S01,code=1)
0: jdbc:hive2://localhost:10000/default> select distinct(category_code) from clickstream_tbl where category_code is not Null or  category_code != "";category_code != "";
INFO  : Compiling command(queryId=hive_20220717082534_773127cc-76e4-4375-aefc-8b15dbf6b83d): select distinct(category_code) from clickstream_tbl where category_code is not Null or category_code != ""
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:category_code, type:string, comment:null)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717082534_773127cc-76e4-4375-aefc-8b15dbf6b83d : STAGE DEPENDENCIES:
  Stage-1 is a root stage [MAPRED]
  Stage-0 depends on stages: Stage-1 [FETCH]

STAGE PLANS:
  Stage: Stage-1
    Tez
      DagId: hive_20220717082534_773127cc-76e4-4375-aefc-8b15dbf6b83d:19
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
      DagName: 
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: clickstream_tbl
                  Statistics: Num rows: 10283816 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: (category_code is not null or (category_code <> '')) (type: boolean)
                    Statistics: Num rows: 10283816 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      keys: category_code (type: string)
                      mode: hash
                      outputColumnNames: _col0
                      Statistics: Num rows: 10283816 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: string)
                        null sort order: a
                        sort order: +
                        Map-reduce partition columns: _col0 (type: string)
                        Statistics: Num rows: 10283816 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                        tag: -1
                        auto parallelism: true
            Path -> Alias:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl [clickstream_tbl]
            Path -> Partition:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl 
                Partition
                  base file name: clickstream_tbl
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    column.name.delimiter ,
                    columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                    columns.comments 
                    columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                    escapeChar \
                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                    name clickstream.clickstream_tbl
                    numFiles 2
                    numRows 0
                    quoteChar "
                    rawDataSize 0
                    separatorChar ,
                    serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                    skip.header.line.count 1
                    totalSize 1028381690
                    transient_lastDdlTime 1658039808
                  serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      column.name.delimiter ,
                      columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                      columns.comments 
                      columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                      escapeChar \
                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                      name clickstream.clickstream_tbl
                      numFiles 2
                      numRows 0
                      quoteChar "
                      rawDataSize 0
                      separatorChar ,
                      serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                      skip.header.line.count 1
                      totalSize 1028381690
                      transient_lastDdlTime 1658039808
                    serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                    name: clickstream.clickstream_tbl
                  name: clickstream.clickstream_tbl
            Truncated Path -> Alias:
              /clickstream.db/clickstream_tbl [clickstream_tbl]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Group By Operator
                keys: KEY._col0 (type: string)
                mode: mergepartial
                outputColumnNames: _col0
                Statistics: Num rows: 5141908 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
                  directory: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoopbeeline/4e9c1b42-fcb5-47eb-b575-a9476e38c8a8/hive_2022-07-17_08-25-34_274_862627695317630696-19/-mr-10001/.hive-staging_hive_2022-07-17_08-25-34_274_862627695317630696-19/-ext-10002
                  NumFilesPerFileSink: 1
                  Statistics: Num rows: 5141908 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                  Stats Publishing Key Prefix: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoopbeeline/4e9c1b42-fcb5-47eb-b575-a9476e38c8a8/hive_2022-07-17_08-25-34_274_862627695317630696-19/-mr-10001/.hive-staging_hive_2022-07-17_08-25-34_274_862627695317630696-19/-ext-10002/
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      properties:
                        columns _col0
                        columns.types string
                        escape.delim \
                        hive.serialization.extend.additional.nesting.levels true
                        serialization.escape.crlf true
                        serialization.format 1
                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  TotalFiles: 1
                  GatherStats: false
                  MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717082534_773127cc-76e4-4375-aefc-8b15dbf6b83d); Time taken: 0.228 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717082534_773127cc-76e4-4375-aefc-8b15dbf6b83d): select distinct(category_code) from clickstream_tbl where category_code is not Null or category_code != ""
INFO  : Query ID = hive_20220717082534_773127cc-76e4-4375-aefc-8b15dbf6b83d
INFO  : Total jobs = 1
INFO  : Launching Job 1 out of 1
INFO  : Starting task [Stage-1:MAPRED] in serial mode
WARN  : The session: sessionId=d2d4b401-c52c-41fc-b657-6979c72866f8, queueName=null, user=hadoopbeeline, doAs=true, isOpen=false, isDefault=false has not been opened
INFO  : Tez session hasn't been created yet. Opening session
ERROR : Failed to execute tez graph.
org.apache.hadoop.security.AccessControlException: Permission denied: user=hadoopbeeline, access=WRITE, inode="/user":hdfs:hdfsadmingroup:drwxr-xr-x
at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:351)
at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:251)
at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:189)
at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1756)
at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1740)
at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1699)
at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:60)
at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3017)
at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:1132)
at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:662)
at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:507)
at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1034)
at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1003)
at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:931)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:422)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1926)
at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2854)

at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:1.8.0_332]
at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[?:1.8.0_332]
at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_332]
at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_332]
at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2507) ~[hadoop-hdfs-client-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2480) ~[hadoop-hdfs-client-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1243) ~[hadoop-hdfs-client-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1240) ~[hadoop-hdfs-client-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:1257) ~[hadoop-hdfs-client-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:1232) ~[hadoop-hdfs-client-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:2269) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.hive.ql.exec.tez.DagUtils.getDefaultDestDir(DagUtils.java:823) ~[hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.exec.tez.DagUtils.getHiveJarDirectory(DagUtils.java:917) ~[hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.exec.tez.TezSessionState.createJarLocalResource(TezSessionState.java:621) ~[hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.exec.tez.TezSessionState.openInternal(TezSessionState.java:251) ~[hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.exec.tez.TezSessionPoolManager$TezSessionPoolSession.openInternal(TezSessionPoolManager.java:703) ~[hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.exec.tez.TezSessionState.open(TezSessionState.java:196) ~[hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.exec.tez.TezTask.updateSession(TezTask.java:304) ~[hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.exec.tez.TezTask.execute(TezTask.java:169) [hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:203) [hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:100) [hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:2183) [hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1839) [hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1526) [hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1237) [hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1232) [hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:252) [hive-service-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hive.service.cli.operation.SQLOperation.access$800(SQLOperation.java:88) [hive-service-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:345) [hive-service-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_332]
at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_332]
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1926) [hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:360) [hive-service-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_332]
at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_332]
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_332]
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_332]
at java.lang.Thread.run(Thread.java:750) [?:1.8.0_332]
Caused by: org.apache.hadoop.ipc.RemoteException: Permission denied: user=hadoopbeeline, access=WRITE, inode="/user":hdfs:hdfsadmingroup:drwxr-xr-x
at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:351)
at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:251)
at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:189)
at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1756)
at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1740)
at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1699)
at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:60)
at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3017)
at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:1132)
at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:662)
at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:507)
at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1034)
at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1003)
at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:931)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:422)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1926)
at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2854)

at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.ipc.Client.call(Client.java:1495) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.ipc.Client.call(Client.java:1394) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at com.sun.proxy.$Proxy30.mkdirs(Unknown Source) ~[?:?]
at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:589) ~[hadoop-hdfs-client-2.10.1-amzn-4.jar:?]
at sun.reflect.GeneratedMethodAccessor11.invoke(Unknown Source) ~[?:?]
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_332]
at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_332]
at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at com.sun.proxy.$Proxy31.mkdirs(Unknown Source) ~[?:?]
at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2505) ~[hadoop-hdfs-client-2.10.1-amzn-4.jar:?]
... 34 more
ERROR : FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.tez.TezTask
INFO  : Completed executing command(queryId=hive_20220717082534_773127cc-76e4-4375-aefc-8b15dbf6b83d); Time taken: 1.12 seconds
Error: org.apache.hive.service.cli.HiveSQLException: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.tez.TezTask
at org.apache.hive.service.cli.operation.Operation.toSQLException(Operation.java:380)
at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:254)
at org.apache.hive.service.cli.operation.SQLOperation.access$800(SQLOperation.java:88)
at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:345)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:422)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1926)
at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:360)
at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
at java.util.concurrent.FutureTask.run(FutureTask.java:266)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
at java.lang.Thread.run(Thread.java:750) (state=08S01,code=1)
0: jdbc:hive2://localhost:10000/default> show tables;
INFO  : Compiling command(queryId=hive_20220717082557_108b8700-0f02-4ae9-b6e6-a29f315d3c52): show tables
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:tab_name, type:string, comment:from deserializer)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717082557_108b8700-0f02-4ae9-b6e6-a29f315d3c52 : STAGE DEPENDENCIES:
  Stage-0 is a root stage [DDL]
  Stage-1 depends on stages: Stage-0 [FETCH]

STAGE PLANS:
  Stage: Stage-0
      Show Table Operator:
        Show Tables
          database name: clickstream
          result file: file:/mnt/tmp/hive/4e9c1b42-fcb5-47eb-b575-a9476e38c8a8/hive_2022-07-17_08-25-57_629_6020187856617508560-19/-local-10000

  Stage: Stage-1
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717082557_108b8700-0f02-4ae9-b6e6-a29f315d3c52); Time taken: 0.019 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717082557_108b8700-0f02-4ae9-b6e6-a29f315d3c52): show tables
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20220717082557_108b8700-0f02-4ae9-b6e6-a29f315d3c52); Time taken: 0.01 seconds
INFO  : OK
+--------------------------+
|         tab_name         |
+--------------------------+
| clickstream_stats        |
| clickstream_tbl          |
| part_mnth_buck_type_tbl  |
+--------------------------+
3 rows selected (0.114 seconds)
0: jdbc:hive2://localhost:10000/default> select distinct(category_code) from clickstream_tbl where category_code!=""  and category_code is not null ;
INFO  : Compiling command(queryId=hive_20220717082634_74d6451a-aeeb-416d-8095-47790d242885): select distinct(category_code) from clickstream_tbl where category_code!="" and category_code is not null
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:category_code, type:string, comment:null)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717082634_74d6451a-aeeb-416d-8095-47790d242885 : STAGE DEPENDENCIES:
  Stage-1 is a root stage [MAPRED]
  Stage-0 depends on stages: Stage-1 [FETCH]

STAGE PLANS:
  Stage: Stage-1
    Tez
      DagId: hive_20220717082634_74d6451a-aeeb-416d-8095-47790d242885:20
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
      DagName: 
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: clickstream_tbl
                  Statistics: Num rows: 10283816 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: (category_code <> '') (type: boolean)
                    Statistics: Num rows: 10283816 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      keys: category_code (type: string)
                      mode: hash
                      outputColumnNames: _col0
                      Statistics: Num rows: 10283816 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: string)
                        null sort order: a
                        sort order: +
                        Map-reduce partition columns: _col0 (type: string)
                        Statistics: Num rows: 10283816 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                        tag: -1
                        auto parallelism: true
            Path -> Alias:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl [clickstream_tbl]
            Path -> Partition:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl 
                Partition
                  base file name: clickstream_tbl
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    column.name.delimiter ,
                    columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                    columns.comments 
                    columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                    escapeChar \
                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                    name clickstream.clickstream_tbl
                    numFiles 2
                    numRows 0
                    quoteChar "
                    rawDataSize 0
                    separatorChar ,
                    serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                    skip.header.line.count 1
                    totalSize 1028381690
                    transient_lastDdlTime 1658039808
                  serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      column.name.delimiter ,
                      columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                      columns.comments 
                      columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                      escapeChar \
                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                      name clickstream.clickstream_tbl
                      numFiles 2
                      numRows 0
                      quoteChar "
                      rawDataSize 0
                      separatorChar ,
                      serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                      skip.header.line.count 1
                      totalSize 1028381690
                      transient_lastDdlTime 1658039808
                    serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                    name: clickstream.clickstream_tbl
                  name: clickstream.clickstream_tbl
            Truncated Path -> Alias:
              /clickstream.db/clickstream_tbl [clickstream_tbl]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Group By Operator
                keys: KEY._col0 (type: string)
                mode: mergepartial
                outputColumnNames: _col0
                Statistics: Num rows: 5141908 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
                  directory: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoopbeeline/4e9c1b42-fcb5-47eb-b575-a9476e38c8a8/hive_2022-07-17_08-26-34_759_6300441838565881501-19/-mr-10001/.hive-staging_hive_2022-07-17_08-26-34_759_6300441838565881501-19/-ext-10002
                  NumFilesPerFileSink: 1
                  Statistics: Num rows: 5141908 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                  Stats Publishing Key Prefix: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoopbeeline/4e9c1b42-fcb5-47eb-b575-a9476e38c8a8/hive_2022-07-17_08-26-34_759_6300441838565881501-19/-mr-10001/.hive-staging_hive_2022-07-17_08-26-34_759_6300441838565881501-19/-ext-10002/
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      properties:
                        columns _col0
                        columns.types string
                        escape.delim \
                        hive.serialization.extend.additional.nesting.levels true
                        serialization.escape.crlf true
                        serialization.format 1
                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  TotalFiles: 1
                  GatherStats: false
                  MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717082634_74d6451a-aeeb-416d-8095-47790d242885); Time taken: 0.175 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717082634_74d6451a-aeeb-416d-8095-47790d242885): select distinct(category_code) from clickstream_tbl where category_code!="" and category_code is not null
INFO  : Query ID = hive_20220717082634_74d6451a-aeeb-416d-8095-47790d242885
INFO  : Total jobs = 1
INFO  : Launching Job 1 out of 1
INFO  : Starting task [Stage-1:MAPRED] in serial mode
WARN  : The session: sessionId=0c018033-c803-4da1-a412-07b547e1abd1, queueName=null, user=hadoopbeeline, doAs=true, isOpen=false, isDefault=false has not been opened
INFO  : Tez session hasn't been created yet. Opening session
ERROR : Failed to execute tez graph.
org.apache.hadoop.security.AccessControlException: Permission denied: user=hadoopbeeline, access=WRITE, inode="/user":hdfs:hdfsadmingroup:drwxr-xr-x
at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:351)
at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:251)
at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:189)
at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1756)
at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1740)
at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1699)
at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:60)
at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3017)
at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:1132)
at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:662)
at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:507)
at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1034)
at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1003)
at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:931)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:422)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1926)
at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2854)

at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:1.8.0_332]
at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[?:1.8.0_332]
at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_332]
at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_332]
at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2507) ~[hadoop-hdfs-client-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2480) ~[hadoop-hdfs-client-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1243) ~[hadoop-hdfs-client-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1240) ~[hadoop-hdfs-client-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:1257) ~[hadoop-hdfs-client-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:1232) ~[hadoop-hdfs-client-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:2269) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.hive.ql.exec.tez.DagUtils.getDefaultDestDir(DagUtils.java:823) ~[hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.exec.tez.DagUtils.getHiveJarDirectory(DagUtils.java:917) ~[hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.exec.tez.TezSessionState.createJarLocalResource(TezSessionState.java:621) ~[hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.exec.tez.TezSessionState.openInternal(TezSessionState.java:251) ~[hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.exec.tez.TezSessionPoolManager$TezSessionPoolSession.openInternal(TezSessionPoolManager.java:703) ~[hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.exec.tez.TezSessionState.open(TezSessionState.java:196) ~[hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.exec.tez.TezTask.updateSession(TezTask.java:304) ~[hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.exec.tez.TezTask.execute(TezTask.java:169) [hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:203) [hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:100) [hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:2183) [hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1839) [hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1526) [hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1237) [hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1232) [hive-exec-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:252) [hive-service-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hive.service.cli.operation.SQLOperation.access$800(SQLOperation.java:88) [hive-service-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:345) [hive-service-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_332]
at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_332]
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1926) [hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:360) [hive-service-2.3.9-amzn-2.jar:2.3.9-amzn-2]
at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_332]
at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_332]
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_332]
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_332]
at java.lang.Thread.run(Thread.java:750) [?:1.8.0_332]
Caused by: org.apache.hadoop.ipc.RemoteException: Permission denied: user=hadoopbeeline, access=WRITE, inode="/user":hdfs:hdfsadmingroup:drwxr-xr-x
at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:351)
at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:251)
at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:189)
at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1756)
at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1740)
at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1699)
at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:60)
at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3017)
at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:1132)
at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:662)
at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:507)
at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1034)
at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1003)
at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:931)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:422)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1926)
at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2854)

at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.ipc.Client.call(Client.java:1495) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.ipc.Client.call(Client.java:1394) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at com.sun.proxy.$Proxy30.mkdirs(Unknown Source) ~[?:?]
at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:589) ~[hadoop-hdfs-client-2.10.1-amzn-4.jar:?]
at sun.reflect.GeneratedMethodAccessor11.invoke(Unknown Source) ~[?:?]
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_332]
at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_332]
at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359) ~[hadoop-common-2.10.1-amzn-4.jar:?]
at com.sun.proxy.$Proxy31.mkdirs(Unknown Source) ~[?:?]
at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2505) ~[hadoop-hdfs-client-2.10.1-amzn-4.jar:?]
... 34 more
ERROR : FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.tez.TezTask
INFO  : Completed executing command(queryId=hive_20220717082634_74d6451a-aeeb-416d-8095-47790d242885); Time taken: 0.319 seconds
Error: org.apache.hive.service.cli.HiveSQLException: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.tez.TezTask
at org.apache.hive.service.cli.operation.Operation.toSQLException(Operation.java:380)
at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:254)
at org.apache.hive.service.cli.operation.SQLOperation.access$800(SQLOperation.java:88)
at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:345)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:422)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1926)
at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:360)
at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
at java.util.concurrent.FutureTask.run(FutureTask.java:266)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
at java.lang.Thread.run(Thread.java:750) (state=08S01,code=1)
0: jdbc:hive2://localhost:10000/default> Closing: 0: jdbc:hive2://localhost:10000/default
[hadoop@ip-172-31-42-254 hive_cs]$ beeline -u jdbc:hive2://localhost:10000/default  -n hadoopbeeline -u jdbc:hive2://llocalhost:10000/default  -n hadoop
select month(event_time) as Month, sum(price) as Price from part_mnth_buck_type_tbll where event_type = 'purchase' group by month(event_time);beeline -u jdbc:hive2://localhost:10000/default  -n hadoop
cat 2019-Nov.csv | headbeeline -u jdbc:hive2://localhost:10000/default  -n hadoop
Connecting to jdbc:hive2://localhost:10000/default
Connected to: Apache Hive (version 2.3.9-amzn-2)
Driver: Hive JDBC (version 2.3.9-amzn-2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
Beeline version 2.3.9-amzn-2 by Apache Hive
0: jdbc:hive2://localhost:10000/default> use clickstream;
INFO  : Compiling command(queryId=hive_20220717082724_f742cb9a-e96a-4cb0-8047-43865929a5fa): use clickstream
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : EXPLAIN output for queryid hive_20220717082724_f742cb9a-e96a-4cb0-8047-43865929a5fa : STAGE DEPENDENCIES:
  Stage-0 is a root stage [DDL]

STAGE PLANS:
  Stage: Stage-0


INFO  : Completed compiling command(queryId=hive_20220717082724_f742cb9a-e96a-4cb0-8047-43865929a5fa); Time taken: 0.03 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717082724_f742cb9a-e96a-4cb0-8047-43865929a5fa): use clickstream
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20220717082724_f742cb9a-e96a-4cb0-8047-43865929a5fa); Time taken: 0.011 seconds
INFO  : OK
No rows affected (0.16 seconds)
0: jdbc:hive2://localhost:10000/default> use clickstream;select distinct(category_code) from clickstream_tbl where category_code!="" and category_code is not null ;how tables;elect distinct(category_code) from clickstream_tbl where category_code is not Null or category_code != ""; category_code != "";and category_code != "";use clickstream;select distinct(category_code) from clickstream_tbl where category_code is not Null and category_code != "";or  category_code != "";category_code != "";
0: jdbc:hive2://localhost:10000/default>         at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExec utor.java:624)
. . . . . . . . . . . . . . . . . . . .>         at java.lang.Thread.run(Thread.ja
. . . . . . . . . . . . . . . . . . . .> 
. . . . . . . . . . . . . . . . . . . .> 
. . . . . . . . . . . . . . . . . . . .> 
. . . . . . . . . . . . . . . . . . . .> 
. . . . . . . . . . . . . . . . . . . .> 
. . . . . . . . . . . . . . . . . . . .> 
[1]+  Stopped                 beeline -u jdbc:hive2://localhost:10000/default -n hadoop
[hadoop@ip-172-31-42-254 hive_cs]$ beeline -u jdbc:hive2://localhost:10000/default  -n hadoopbeeline -u jdbc:hive2://llocalhost:10000/default  -n hadoop

Connecting to jdbc:hive2://localhost:10000/default
Connected to: Apache Hive (version 2.3.9-amzn-2)
Driver: Hive JDBC (version 2.3.9-amzn-2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
Beeline version 2.3.9-amzn-2 by Apache Hive
0: jdbc:hive2://localhost:10000/default> select distinct(category_code) from clickstream_tbl where category_code!=""  and category_code is not null;
Error: Error while compiling statement: FAILED: SemanticException [Error 10001]: Line 1:36 Table not found 'clickstream_tbl' (state=42S02,code=10001)
0: jdbc:hive2://localhost:10000/default> use clickstream;
INFO  : Compiling command(queryId=hive_20220717082824_b6671162-0679-4f23-bf19-122be0dd6375): use clickstream
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : EXPLAIN output for queryid hive_20220717082824_b6671162-0679-4f23-bf19-122be0dd6375 : STAGE DEPENDENCIES:
  Stage-0 is a root stage [DDL]

STAGE PLANS:
  Stage: Stage-0


INFO  : Completed compiling command(queryId=hive_20220717082824_b6671162-0679-4f23-bf19-122be0dd6375); Time taken: 0.023 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717082824_b6671162-0679-4f23-bf19-122be0dd6375): use clickstream
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20220717082824_b6671162-0679-4f23-bf19-122be0dd6375); Time taken: 0.014 seconds
INFO  : OK
No rows affected (0.093 seconds)
0: jdbc:hive2://localhost:10000/default> show tables;
INFO  : Compiling command(queryId=hive_20220717082827_8420e983-d395-4d58-aa68-d6331dc01666): show tables
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:tab_name, type:string, comment:from deserializer)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717082827_8420e983-d395-4d58-aa68-d6331dc01666 : STAGE DEPENDENCIES:
  Stage-0 is a root stage [DDL]
  Stage-1 depends on stages: Stage-0 [FETCH]

STAGE PLANS:
  Stage: Stage-0
      Show Table Operator:
        Show Tables
          database name: clickstream
          result file: file:/mnt/tmp/hive/847661e0-bd72-4929-99e8-1e30c15b680b/hive_2022-07-17_08-28-27_020_7471602293392931353-16/-local-10000

  Stage: Stage-1
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717082827_8420e983-d395-4d58-aa68-d6331dc01666); Time taken: 0.02 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717082827_8420e983-d395-4d58-aa68-d6331dc01666): show tables
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20220717082827_8420e983-d395-4d58-aa68-d6331dc01666); Time taken: 0.011 seconds
INFO  : OK
+--------------------------+
|         tab_name         |
+--------------------------+
| clickstream_stats        |
| clickstream_tbl          |
| part_mnth_buck_type_tbl  |
+--------------------------+
3 rows selected (0.08 seconds)
0: jdbc:hive2://localhost:10000/default> show tables;select distinct(category_code) from clickstream_tbl where category_code!=""  and category_code is not null;
INFO  : Compiling command(queryId=hive_20220717082836_2199726b-4f1e-42da-b736-0858df34f98b): select distinct(category_code) from clickstream_tbl where category_code!="" and category_code is not null
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:category_code, type:string, comment:null)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717082836_2199726b-4f1e-42da-b736-0858df34f98b : STAGE DEPENDENCIES:
  Stage-1 is a root stage [MAPRED]
  Stage-0 depends on stages: Stage-1 [FETCH]

STAGE PLANS:
  Stage: Stage-1
    Tez
      DagId: hive_20220717082836_2199726b-4f1e-42da-b736-0858df34f98b:21
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
      DagName: 
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: clickstream_tbl
                  Statistics: Num rows: 10283816 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: (category_code <> '') (type: boolean)
                    Statistics: Num rows: 10283816 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      keys: category_code (type: string)
                      mode: hash
                      outputColumnNames: _col0
                      Statistics: Num rows: 10283816 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: string)
                        null sort order: a
                        sort order: +
                        Map-reduce partition columns: _col0 (type: string)
                        Statistics: Num rows: 10283816 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                        tag: -1
                        auto parallelism: true
            Path -> Alias:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl [clickstream_tbl]
            Path -> Partition:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl 
                Partition
                  base file name: clickstream_tbl
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    column.name.delimiter ,
                    columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                    columns.comments 
                    columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                    escapeChar \
                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                    name clickstream.clickstream_tbl
                    numFiles 2
                    numRows 0
                    quoteChar "
                    rawDataSize 0
                    separatorChar ,
                    serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                    skip.header.line.count 1
                    totalSize 1028381690
                    transient_lastDdlTime 1658039808
                  serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      column.name.delimiter ,
                      columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                      columns.comments 
                      columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                      escapeChar \
                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                      name clickstream.clickstream_tbl
                      numFiles 2
                      numRows 0
                      quoteChar "
                      rawDataSize 0
                      separatorChar ,
                      serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                      skip.header.line.count 1
                      totalSize 1028381690
                      transient_lastDdlTime 1658039808
                    serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                    name: clickstream.clickstream_tbl
                  name: clickstream.clickstream_tbl
            Truncated Path -> Alias:
              /clickstream.db/clickstream_tbl [clickstream_tbl]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Group By Operator
                keys: KEY._col0 (type: string)
                mode: mergepartial
                outputColumnNames: _col0
                Statistics: Num rows: 5141908 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
                  directory: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/847661e0-bd72-4929-99e8-1e30c15b680b/hive_2022-07-17_08-28-36_371_1751028585743064671-16/-mr-10001/.hive-staging_hive_2022-07-17_08-28-36_371_1751028585743064671-16/-ext-10002
                  NumFilesPerFileSink: 1
                  Statistics: Num rows: 5141908 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                  Stats Publishing Key Prefix: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/847661e0-bd72-4929-99e8-1e30c15b680b/hive_2022-07-17_08-28-36_371_1751028585743064671-16/-mr-10001/.hive-staging_hive_2022-07-17_08-28-36_371_1751028585743064671-16/-ext-10002/
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      properties:
                        columns _col0
                        columns.types string
                        escape.delim \
                        hive.serialization.extend.additional.nesting.levels true
                        serialization.escape.crlf true
                        serialization.format 1
                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  TotalFiles: 1
                  GatherStats: false
                  MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717082836_2199726b-4f1e-42da-b736-0858df34f98b); Time taken: 0.281 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717082836_2199726b-4f1e-42da-b736-0858df34f98b): select distinct(category_code) from clickstream_tbl where category_code!="" and category_code is not null
INFO  : Query ID = hive_20220717082836_2199726b-4f1e-42da-b736-0858df34f98b
INFO  : Total jobs = 1
INFO  : Launching Job 1 out of 1
INFO  : Starting task [Stage-1:MAPRED] in serial mode
INFO  : Tez session hasn't been created yet. Opening session
INFO  : Dag name: select distinct(category_code) from c...null(Stage-1)
INFO  : Status: Running (Executing on YARN cluster with App id application_1658032091232_0009)

INFO  : Map 1: 0/2Reducer 2: 0/10
INFO  : Map 1: 0/2Reducer 2: 0/10
INFO  : Map 1: 0(+1)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 1(+1)/2Reducer 2: 0/10
INFO  : Map 1: 1(+1)/2Reducer 2: 0/10
INFO  : Map 1: 2/2Reducer 2: 0/10
INFO  : Map 1: 2/2Reducer 2: 0(+1)/1
INFO  : Map 1: 2/2Reducer 2: 1/1
INFO  : Completed executing command(queryId=hive_20220717082836_2199726b-4f1e-42da-b736-0858df34f98b); Time taken: 63.89 seconds
INFO  : OK
+-----------------------------------------+
|              category_code              |
+-----------------------------------------+
| accessories.bag                         |
| accessories.cosmetic_bag                |
| apparel.glove                           |
| appliances.environment.air_conditioner  |
| appliances.environment.vacuum           |
| appliances.personal.hair_cutter         |
| furniture.bathroom.bath                 |
| furniture.living_room.cabinet           |
| furniture.living_room.chair             |
| sport.diving                            |
| stationery.cartrige                     |
+-----------------------------------------+
11 rows selected (64.239 seconds)
0: jdbc:hive2://localhost:10000/default> Closing: 0: jdbc:hive2://localhost:10000/default
[hadoop@ip-172-31-42-254 hive_cs]$ ^C
[hadoop@ip-172-31-42-254 hive_cs]$ beeline -u jdbc:hive2://localhost:10000/default  -n hadoop
Connecting to jdbc:hive2://localhost:10000/default
Connected to: Apache Hive (version 2.3.9-amzn-2)
Driver: Hive JDBC (version 2.3.9-amzn-2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
Beeline version 2.3.9-amzn-2 by Apache Hive
0: jdbc:hive2://localhost:10000/default> use clickstream;
INFO  : Compiling command(queryId=hive_20220717083025_5b02ed2e-d93b-4ebb-be60-df9027ed5a7d): use clickstream
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : EXPLAIN output for queryid hive_20220717083025_5b02ed2e-d93b-4ebb-be60-df9027ed5a7d : STAGE DEPENDENCIES:
  Stage-0 is a root stage [DDL]

STAGE PLANS:
  Stage: Stage-0


INFO  : Completed compiling command(queryId=hive_20220717083025_5b02ed2e-d93b-4ebb-be60-df9027ed5a7d); Time taken: 0.067 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717083025_5b02ed2e-d93b-4ebb-be60-df9027ed5a7d): use clickstream
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20220717083025_5b02ed2e-d93b-4ebb-be60-df9027ed5a7d); Time taken: 0.022 seconds
INFO  : OK
No rows affected (0.273 seconds)
0: jdbc:hive2://localhost:10000/default> select distinct(category_code) from part_mnth_buck_type_tbl where category_c ode!="" and category_code is not null;
INFO  : Compiling command(queryId=hive_20220717083105_02a756e0-a9be-4b5a-a2a1-ac4b938c5fa4): select distinct(category_code) from part_mnth_buck_type_tbl where category_code!="" and category_code is not null
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:category_code, type:string, comment:null)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717083105_02a756e0-a9be-4b5a-a2a1-ac4b938c5fa4 : STAGE DEPENDENCIES:
  Stage-1 is a root stage [MAPRED]
  Stage-0 depends on stages: Stage-1 [FETCH]

STAGE PLANS:
  Stage: Stage-1
    Tez
      DagId: hive_20220717083105_02a756e0-a9be-4b5a-a2a1-ac4b938c5fa4:22
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
      DagName: 
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: part_mnth_buck_type_tbl
                  Statistics: Num rows: 8738120 Data size: 1255572626 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: (category_code <> '') (type: boolean)
                    Statistics: Num rows: 8738120 Data size: 1255572626 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      keys: category_code (type: string)
                      mode: hash
                      outputColumnNames: _col0
                      Statistics: Num rows: 8738120 Data size: 1255572626 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: string)
                        null sort order: a
                        sort order: +
                        Map-reduce partition columns: _col0 (type: string)
                        Statistics: Num rows: 8738120 Data size: 1255572626 Basic stats: COMPLETE Column stats: NONE
                        tag: -1
                        auto parallelism: true
            Path -> Alias:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl/mnth=10 [part_mnth_buck_type_tbl]
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl/mnth=11 [part_mnth_buck_type_tbl]
            Path -> Partition:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl/mnth=10 
                Partition
                  base file name: mnth=10
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    mnth 10
                  properties:
                    COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
                    bucket_count 4
                    bucket_field_name event_type
                    column.name.delimiter ,
                    columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                    columns.comments 
                    columns.types string:string:string:string:string:string:decimal(10,3):bigint:string
                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl/mnth=10
                    name clickstream.part_mnth_buck_type_tbl
                    numFiles 3
                    numRows 4102283
                    partition_columns mnth
                    partition_columns.types int
                    rawDataSize 0
                    serialization.ddl struct part_mnth_buck_type_tbl { string event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                    totalSize 556383280
                    transient_lastDdlTime 1658042010
                  serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count 4
                      bucket_field_name event_type
                      column.name.delimiter ,
                      columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                      columns.comments 
                      columns.types string:string:string:string:string:string:decimal(10,3):bigint:string
                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl
                      name clickstream.part_mnth_buck_type_tbl
                      partition_columns mnth
                      partition_columns.types int
                      serialization.ddl struct part_mnth_buck_type_tbl { string event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                      transient_lastDdlTime 1658041789
                    serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                    name: clickstream.part_mnth_buck_type_tbl
                  name: clickstream.part_mnth_buck_type_tbl
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl/mnth=11 
                Partition
                  base file name: mnth=11
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  partition values:
                    mnth 11
                  properties:
                    COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
                    bucket_count 4
                    bucket_field_name event_type
                    column.name.delimiter ,
                    columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                    columns.comments 
                    columns.types string:string:string:string:string:string:decimal(10,3):bigint:string
                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl/mnth=11
                    name clickstream.part_mnth_buck_type_tbl
                    numFiles 3
                    numRows 4635837
                    partition_columns mnth
                    partition_columns.types int
                    rawDataSize 0
                    serialization.ddl struct part_mnth_buck_type_tbl { string event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                    totalSize 629284386
                    transient_lastDdlTime 1658042011
                  serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count 4
                      bucket_field_name event_type
                      column.name.delimiter ,
                      columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                      columns.comments 
                      columns.types string:string:string:string:string:string:decimal(10,3):bigint:string
                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/part_mnth_buck_type_tbl
                      name clickstream.part_mnth_buck_type_tbl
                      partition_columns mnth
                      partition_columns.types int
                      serialization.ddl struct part_mnth_buck_type_tbl { string event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                      transient_lastDdlTime 1658041789
                    serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                    name: clickstream.part_mnth_buck_type_tbl
                  name: clickstream.part_mnth_buck_type_tbl
            Truncated Path -> Alias:
              /clickstream.db/part_mnth_buck_type_tbl/mnth=10 [part_mnth_buck_type_tbl]
              /clickstream.db/part_mnth_buck_type_tbl/mnth=11 [part_mnth_buck_type_tbl]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Group By Operator
                keys: KEY._col0 (type: string)
                mode: mergepartial
                outputColumnNames: _col0
                Statistics: Num rows: 4369060 Data size: 627786313 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
                  directory: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/6d06f1f1-d96b-4e15-a557-93756f1f3ebc/hive_2022-07-17_08-31-05_204_4209260099842987097-16/-mr-10001/.hive-staging_hive_2022-07-17_08-31-05_204_4209260099842987097-16/-ext-10002
                  NumFilesPerFileSink: 1
                  Statistics: Num rows: 4369060 Data size: 627786313 Basic stats: COMPLETE Column stats: NONE
                  Stats Publishing Key Prefix: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/6d06f1f1-d96b-4e15-a557-93756f1f3ebc/hive_2022-07-17_08-31-05_204_4209260099842987097-16/-mr-10001/.hive-staging_hive_2022-07-17_08-31-05_204_4209260099842987097-16/-ext-10002/
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      properties:
                        columns _col0
                        columns.types string
                        escape.delim \
                        hive.serialization.extend.additional.nesting.levels true
                        serialization.escape.crlf true
                        serialization.format 1
                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  TotalFiles: 1
                  GatherStats: false
                  MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717083105_02a756e0-a9be-4b5a-a2a1-ac4b938c5fa4); Time taken: 0.368 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717083105_02a756e0-a9be-4b5a-a2a1-ac4b938c5fa4): select distinct(category_code) from part_mnth_buck_type_tbl where category_code!="" and category_code is not null
INFO  : Query ID = hive_20220717083105_02a756e0-a9be-4b5a-a2a1-ac4b938c5fa4
INFO  : Total jobs = 1
INFO  : Launching Job 1 out of 1
INFO  : Starting task [Stage-1:MAPRED] in serial mode
INFO  : Tez session hasn't been created yet. Opening session
INFO  : Dag name: select distinct(category_code) from p...null(Stage-1)
INFO  : Status: Running (Executing on YARN cluster with App id application_1658032091232_0010)

INFO  : Map 1: -/-Reducer 2: 0/10
INFO  : Map 1: 0/9Reducer 2: 0/10
INFO  : Map 1: 0/9Reducer 2: 0/10
INFO  : Map 1: 0/9Reducer 2: 0/10
INFO  : Map 1: 0(+2)/9Reducer 2: 0/10
INFO  : Map 1: 0(+3)/9Reducer 2: 0/10
INFO  : Map 1: 0(+3)/9Reducer 2: 0/10
INFO  : Map 1: 0(+3)/9Reducer 2: 0/10
INFO  : Map 1: 0(+3)/9Reducer 2: 0/10
INFO  : Map 1: 0(+3)/9Reducer 2: 0/10
INFO  : Map 1: 0(+3)/9Reducer 2: 0/10
INFO  : Map 1: 0(+3)/9Reducer 2: 0/10
INFO  : Map 1: 0(+3)/9Reducer 2: 0/10
INFO  : Map 1: 0(+3)/9Reducer 2: 0/10
INFO  : Map 1: 1(+3)/9Reducer 2: 0/10
INFO  : Map 1: 2(+3)/9Reducer 2: 0/10
INFO  : Map 1: 3(+3)/9Reducer 2: 0/10
INFO  : Map 1: 3(+3)/9Reducer 2: 0/10
INFO  : Map 1: 3(+3)/9Reducer 2: 0/10
INFO  : Map 1: 3(+3)/9Reducer 2: 0/10
INFO  : Map 1: 3(+3)/9Reducer 2: 0/10
INFO  : Map 1: 3(+3)/9Reducer 2: 0/10
INFO  : Map 1: 4(+3)/9Reducer 2: 0/10
INFO  : Map 1: 5(+2)/9Reducer 2: 0/10
INFO  : Map 1: 5(+3)/9Reducer 2: 0/10
INFO  : Map 1: 6(+2)/9Reducer 2: 0/10
INFO  : Map 1: 6(+3)/9Reducer 2: 0/10
INFO  : Map 1: 7(+2)/9Reducer 2: 0/1
INFO  : Map 1: 7(+2)/9Reducer 2: 0(+1)/1
INFO  : Map 1: 7(+2)/9Reducer 2: 0(+1)/1
INFO  : Map 1: 7(+2)/9Reducer 2: 0(+1)/1
INFO  : Map 1: 8(+1)/9Reducer 2: 0(+1)/1
INFO  : Map 1: 8(+1)/9Reducer 2: 0(+1)/1
INFO  : Map 1: 9/9Reducer 2: 0(+1)/1
INFO  : Map 1: 9/9Reducer 2: 1/1
INFO  : Completed executing command(queryId=hive_20220717083105_02a756e0-a9be-4b5a-a2a1-ac4b938c5fa4); Time taken: 79.942 seconds
INFO  : OK
+-----------------------------------------+
|              category_code              |
+-----------------------------------------+
| accessories.bag                         |
| accessories.cosmetic_bag                |
| apparel.glove                           |
| appliances.environment.air_conditioner  |
| appliances.environment.vacuum           |
| appliances.personal.hair_cutter         |
| furniture.bathroom.bath                 |
| furniture.living_room.cabinet           |
| furniture.living_room.chair             |
| sport.diving                            |
| stationery.cartrige                     |
+-----------------------------------------+
11 rows selected (80.517 seconds)
0: jdbc:hive2://localhost:10000/default> select count(product_id) as Product_Count, category_code from clickstream_tb l 
. . . . . . . . . . . . . . . . . . . .> group by category_code order by 1;
Error: Error while compiling statement: FAILED: SemanticException [Error 10004]: Line 1:13 Invalid table alias or column reference 'product_id': (possible column names are: product_count, category_code) (state=42000,code=10004)
0: jdbc:hive2://localhost:10000/default> select count(product_id) as Product_Count, category_code from clickstream_tb l group by category_code order by 1;
Error: Error while compiling statement: FAILED: SemanticException [Error 10004]: Line 1:13 Invalid table alias or column reference 'product_id': (possible column names are: product_count, category_code) (state=42000,code=10004)
0: jdbc:hive2://localhost:10000/default> use clickstream;
INFO  : Compiling command(queryId=hive_20220717083615_d7d932eb-7a1c-4fa9-8d90-f22f6104c335): use clickstream
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : EXPLAIN output for queryid hive_20220717083615_d7d932eb-7a1c-4fa9-8d90-f22f6104c335 : STAGE DEPENDENCIES:
  Stage-0 is a root stage [DDL]

STAGE PLANS:
  Stage: Stage-0


INFO  : Completed compiling command(queryId=hive_20220717083615_d7d932eb-7a1c-4fa9-8d90-f22f6104c335); Time taken: 0.017 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717083615_d7d932eb-7a1c-4fa9-8d90-f22f6104c335): use clickstream
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20220717083615_d7d932eb-7a1c-4fa9-8d90-f22f6104c335); Time taken: 0.007 seconds
INFO  : OK
No rows affected (0.036 seconds)
0: jdbc:hive2://localhost:10000/default> use clickstream;select count(product_id) as Product_Count, category_code from clickstream_tbl group by category_code order by 1;
Error: Error while compiling statement: FAILED: SemanticException [Error 10004]: Line 1:13 Invalid table alias or column reference 'product_id': (possible column names are: product_count, category_code) (state=42000,code=10004)
0: jdbc:hive2://localhost:10000/default> select count(product_id) as Product_Count, category_code from clickstream_tbl group by category_code order by 1;use clickstream;select count(product_id) as Product_Count, category_code from clickstream_tbl group by category_code order by 1;group by category_code order by 1;select count(product_id) as Product_Count, category_code from clickstream_tbl distinct(category_code) from part_mnth_buck_type_tbl where category_code!="" and category_code is not null;use clickstream;select distinct(category_code) from clickstream_tbl where category_code!="" and category_code is not null;how tables;use clickstream;select distinct(category_code) from clickstream_tbl where category_code!="" and category_code is not null;use clickstream;show tables;use clickstream;shdescribe clickstremaam_tbl;
INFO  : Compiling command(queryId=hive_20220717083647_26f1d958-bc76-4ea8-a429-9f12297e4c87): describe clickstream_tbl
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:col_name, type:string, comment:from deserializer), FieldSchema(name:data_type, type:string, comment:from deserializer), FieldSchema(name:comment, type:string, comment:from deserializer)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717083647_26f1d958-bc76-4ea8-a429-9f12297e4c87 : STAGE DEPENDENCIES:
  Stage-0 is a root stage [DDL]
  Stage-1 depends on stages: Stage-0 [FETCH]

STAGE PLANS:
  Stage: Stage-0
      Describe Table Operator:
        Describe Table
          result file: file:/mnt/tmp/hive/6d06f1f1-d96b-4e15-a557-93756f1f3ebc/hive_2022-07-17_08-36-47_254_7258217349906395838-16/-local-10000
          table: clickstream_tbl

  Stage: Stage-1
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717083647_26f1d958-bc76-4ea8-a429-9f12297e4c87); Time taken: 0.03 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717083647_26f1d958-bc76-4ea8-a429-9f12297e4c87): describe clickstream_tbl
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20220717083647_26f1d958-bc76-4ea8-a429-9f12297e4c87); Time taken: 0.014 seconds
INFO  : OK
+----------------+------------+--------------------+
|    col_name    | data_type  |      comment       |
+----------------+------------+--------------------+
| event_time     | string     | from deserializer  |
| event_type     | string     | from deserializer  |
| product_id     | string     | from deserializer  |
| category_id    | string     | from deserializer  |
| category_code  | string     | from deserializer  |
| brand          | string     | from deserializer  |
| price          | string     | from deserializer  |
| user_id        | string     | from deserializer  |
| user_session   | string     | from deserializer  |
+----------------+------------+--------------------+
9 rows selected (0.081 seconds)
0: jdbc:hive2://localhost:10000/default> describe clickstream_tbl;select count(product_id) as Product_Count, category_code from clickstream_tbl group by category_code order by 1;
Error: Error while compiling statement: FAILED: SemanticException [Error 10004]: Line 1:13 Invalid table alias or column reference 'product_id': (possible column names are: product_count, category_code) (state=42000,code=10004)
0: jdbc:hive2://localhost:10000/default> select count(product_id) as Product_Count, category_code from clickstream_tbl group by category_code order by 1;;p;r;o;d;u;c;;;;;;;P;r;o;d;u;c;t;_;C;o;u;n;t;;;;;;;;;;;;;;;;;;;;;;;;;e;
INFO  : Compiling command(queryId=hive_20220717083736_bd28c353-2e76-456b-99b3-48ad98b3232b): select count(product_id) as Product_Count, category_code from clickstream_tbl group by category_code
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:product_count, type:bigint, comment:null), FieldSchema(name:category_code, type:string, comment:null)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717083736_bd28c353-2e76-456b-99b3-48ad98b3232b : STAGE DEPENDENCIES:
  Stage-1 is a root stage [MAPRED]
  Stage-0 depends on stages: Stage-1 [FETCH]

STAGE PLANS:
  Stage: Stage-1
    Tez
      DagId: hive_20220717083736_bd28c353-2e76-456b-99b3-48ad98b3232b:23
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
      DagName: 
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: clickstream_tbl
                  Statistics: Num rows: 5141908 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Select Operator
                    expressions: category_code (type: string), product_id (type: string)
                    outputColumnNames: category_code, product_id
                    Statistics: Num rows: 5141908 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      aggregations: count(product_id)
                      keys: category_code (type: string)
                      mode: hash
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 5141908 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: string)
                        null sort order: a
                        sort order: +
                        Map-reduce partition columns: _col0 (type: string)
                        Statistics: Num rows: 5141908 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                        tag: -1
                        value expressions: _col1 (type: bigint)
                        auto parallelism: true
            Path -> Alias:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl [clickstream_tbl]
            Path -> Partition:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl 
                Partition
                  base file name: clickstream_tbl
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    column.name.delimiter ,
                    columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                    columns.comments 
                    columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                    escapeChar \
                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                    name clickstream.clickstream_tbl
                    numFiles 2
                    numRows 0
                    quoteChar "
                    rawDataSize 0
                    separatorChar ,
                    serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                    skip.header.line.count 1
                    totalSize 1028381690
                    transient_lastDdlTime 1658039808
                  serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      column.name.delimiter ,
                      columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                      columns.comments 
                      columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                      escapeChar \
                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                      name clickstream.clickstream_tbl
                      numFiles 2
                      numRows 0
                      quoteChar "
                      rawDataSize 0
                      separatorChar ,
                      serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                      skip.header.line.count 1
                      totalSize 1028381690
                      transient_lastDdlTime 1658039808
                    serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                    name: clickstream.clickstream_tbl
                  name: clickstream.clickstream_tbl
            Truncated Path -> Alias:
              /clickstream.db/clickstream_tbl [clickstream_tbl]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(VALUE._col0)
                keys: KEY._col0 (type: string)
                mode: mergepartial
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 2570954 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: _col1 (type: bigint), _col0 (type: string)
                  outputColumnNames: _col0, _col1
                  Statistics: Num rows: 2570954 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    GlobalTableId: 0
                    directory: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/6d06f1f1-d96b-4e15-a557-93756f1f3ebc/hive_2022-07-17_08-37-36_703_8256346976074040899-16/-mr-10001/.hive-staging_hive_2022-07-17_08-37-36_703_8256346976074040899-16/-ext-10002
                    NumFilesPerFileSink: 1
                    Statistics: Num rows: 2570954 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                    Stats Publishing Key Prefix: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/6d06f1f1-d96b-4e15-a557-93756f1f3ebc/hive_2022-07-17_08-37-36_703_8256346976074040899-16/-mr-10001/.hive-staging_hive_2022-07-17_08-37-36_703_8256346976074040899-16/-ext-10002/
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        properties:
                          columns _col0,_col1
                          columns.types bigint:string
                          escape.delim \
                          hive.serialization.extend.additional.nesting.levels true
                          serialization.escape.crlf true
                          serialization.format 1
                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    TotalFiles: 1
                    GatherStats: false
                    MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717083736_bd28c353-2e76-456b-99b3-48ad98b3232b); Time taken: 0.145 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717083736_bd28c353-2e76-456b-99b3-48ad98b3232b): select count(product_id) as Product_Count, category_code from clickstream_tbl group by category_code
INFO  : Query ID = hive_20220717083736_bd28c353-2e76-456b-99b3-48ad98b3232b
INFO  : Total jobs = 1
INFO  : Launching Job 1 out of 1
INFO  : Starting task [Stage-1:MAPRED] in serial mode
INFO  : Session is already open
INFO  : Dag name: select count(product_id) as ...category_code(Stage-1)
INFO  : Status: Running (Executing on YARN cluster with App id application_1658032091232_0010)

INFO  : Map 1: 0/2Reducer 2: 0/10
INFO  : Map 1: 0/2Reducer 2: 0/10
INFO  : Map 1: 0(+1)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 1(+1)/2Reducer 2: 0/10
INFO  : Map 1: 2/2Reducer 2: 0/1
INFO  : Map 1: 2/2Reducer 2: 0(+1)/1
INFO  : Map 1: 2/2Reducer 2: 1/1
INFO  : Completed executing command(queryId=hive_20220717083736_bd28c353-2e76-456b-99b3-48ad98b3232b); Time taken: 55.632 seconds
INFO  : OK
+----------------+-----------------------------------------+
| product_count  |              category_code              |
+----------------+-----------------------------------------+
| 8594895        |                                         |
| 11681          | accessories.bag                         |
| 1248           | accessories.cosmetic_bag                |
| 18232          | apparel.glove                           |
| 332            | appliances.environment.air_conditioner  |
| 59761          | appliances.environment.vacuum           |
| 1643           | appliances.personal.hair_cutter         |
| 9857           | furniture.bathroom.bath                 |
| 13439          | furniture.living_room.cabinet           |
| 308            | furniture.living_room.chair             |
| 2              | sport.diving                            |
| 26722          | stationery.cartrige                     |
+----------------+-----------------------------------------+
12 rows selected (55.832 seconds)
0: jdbc:hive2://localhost:10000/default> select brand,sum(price) as Brand_Price from clickstream_tbl group by brand o rder by Brand_Price desc limit 5;
INFO  : Compiling command(queryId=hive_20220717084233_7a8bae43-169c-43e9-84b2-f257aef57592): select brand,sum(price) as Brand_Price from clickstream_tbl group by brand order by Brand_Price desc limit 5
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:brand, type:string, comment:null), FieldSchema(name:brand_price, type:double, comment:null)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717084233_7a8bae43-169c-43e9-84b2-f257aef57592 : STAGE DEPENDENCIES:
  Stage-1 is a root stage [MAPRED]
  Stage-0 depends on stages: Stage-1 [FETCH]

STAGE PLANS:
  Stage: Stage-1
    Tez
      DagId: hive_20220717084233_7a8bae43-169c-43e9-84b2-f257aef57592:24
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
      DagName: 
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: clickstream_tbl
                  Statistics: Num rows: 5141908 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Select Operator
                    expressions: brand (type: string), price (type: string)
                    outputColumnNames: brand, price
                    Statistics: Num rows: 5141908 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      aggregations: sum(price)
                      keys: brand (type: string)
                      mode: hash
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 5141908 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: string)
                        null sort order: a
                        sort order: +
                        Map-reduce partition columns: _col0 (type: string)
                        Statistics: Num rows: 5141908 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                        tag: -1
                        value expressions: _col1 (type: double)
                        auto parallelism: true
            Path -> Alias:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl [clickstream_tbl]
            Path -> Partition:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl 
                Partition
                  base file name: clickstream_tbl
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    column.name.delimiter ,
                    columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                    columns.comments 
                    columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                    escapeChar \
                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                    name clickstream.clickstream_tbl
                    numFiles 2
                    numRows 0
                    quoteChar "
                    rawDataSize 0
                    separatorChar ,
                    serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                    skip.header.line.count 1
                    totalSize 1028381690
                    transient_lastDdlTime 1658039808
                  serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      column.name.delimiter ,
                      columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                      columns.comments 
                      columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                      escapeChar \
                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                      name clickstream.clickstream_tbl
                      numFiles 2
                      numRows 0
                      quoteChar "
                      rawDataSize 0
                      separatorChar ,
                      serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                      skip.header.line.count 1
                      totalSize 1028381690
                      transient_lastDdlTime 1658039808
                    serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                    name: clickstream.clickstream_tbl
                  name: clickstream.clickstream_tbl
            Truncated Path -> Alias:
              /clickstream.db/clickstream_tbl [clickstream_tbl]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0)
                keys: KEY._col0 (type: string)
                mode: mergepartial
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 2570954 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col1 (type: double)
                  null sort order: z
                  sort order: -
                  Statistics: Num rows: 2570954 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                  tag: -1
                  TopN: 5
                  TopN Hash Memory Usage: 0.1
                  value expressions: _col0 (type: string)
                  auto parallelism: false
        Reducer 3 
            Needs Tagging: false
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: string), KEY.reducesinkkey0 (type: double)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 2570954 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                Limit
                  Number of rows: 5
                  Statistics: Num rows: 5 Data size: 1000 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    GlobalTableId: 0
                    directory: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/6d06f1f1-d96b-4e15-a557-93756f1f3ebc/hive_2022-07-17_08-42-33_453_2643317203488844213-16/-mr-10001/.hive-staging_hive_2022-07-17_08-42-33_453_2643317203488844213-16/-ext-10002
                    NumFilesPerFileSink: 1
                    Statistics: Num rows: 5 Data size: 1000 Basic stats: COMPLETE Column stats: NONE
                    Stats Publishing Key Prefix: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/6d06f1f1-d96b-4e15-a557-93756f1f3ebc/hive_2022-07-17_08-42-33_453_2643317203488844213-16/-mr-10001/.hive-staging_hive_2022-07-17_08-42-33_453_2643317203488844213-16/-ext-10002/
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        properties:
                          columns _col0,_col1
                          columns.types string:double
                          escape.delim \
                          hive.serialization.extend.additional.nesting.levels true
                          serialization.escape.crlf true
                          serialization.format 1
                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    TotalFiles: 1
                    GatherStats: false
                    MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: 5
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717084233_7a8bae43-169c-43e9-84b2-f257aef57592); Time taken: 0.167 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717084233_7a8bae43-169c-43e9-84b2-f257aef57592): select brand,sum(price) as Brand_Price from clickstream_tbl group by brand order by Brand_Price desc limit 5
INFO  : Query ID = hive_20220717084233_7a8bae43-169c-43e9-84b2-f257aef57592
INFO  : Total jobs = 1
INFO  : Launching Job 1 out of 1
INFO  : Starting task [Stage-1:MAPRED] in serial mode
INFO  : Session is already open
INFO  : Dag name: select brand,sum(price) as Brand_Price f...5(Stage-1)
INFO  : Status: Running (Executing on YARN cluster with App id application_1658032091232_0010)

INFO  : Map 1: 0/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+1)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 1(+1)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 2/2Reducer 2: 0/1Reducer 3: 0/1
INFO  : Map 1: 2/2Reducer 2: 0(+1)/1Reducer 3: 0/1
INFO  : Map 1: 2/2Reducer 2: 1/1Reducer 3: 0(+1)/1
INFO  : Map 1: 2/2Reducer 2: 1/1Reducer 3: 1/1
INFO  : Completed executing command(queryId=hive_20220717084233_7a8bae43-169c-43e9-84b2-f257aef57592); Time taken: 57.497 seconds
INFO  : OK
+-----------+-----------------------+
|   brand   |      brand_price      |
+-----------+-----------------------+
|           | 2.6194508599959712E7  |
| strong    | 4927445.599999621     |
| jessnail  | 3905094.109999678     |
| runail    | 3838847.3300006418    |
| irisk     | 2660064.559998853     |
+-----------+-----------------------+
5 rows selected (57.694 seconds)
0: jdbc:hive2://localhost:10000/default> select user_id,sum(price) as Purchase_Amt from clickstream_tbl where event_t ype = 'puchase' group by user_id order by Purchase_Amt desc limit 10;
INFO  : Compiling command(queryId=hive_20220717084951_38336616-5c61-4c32-8f49-0b5892c492e9): select user_id,sum(price) as Purchase_Amt from clickstream_tbl where event_type = 'puchase' group by user_id order by Purchase_Amt desc limit 10
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:user_id, type:string, comment:null), FieldSchema(name:purchase_amt, type:double, comment:null)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717084951_38336616-5c61-4c32-8f49-0b5892c492e9 : STAGE DEPENDENCIES:
  Stage-1 is a root stage [MAPRED]
  Stage-0 depends on stages: Stage-1 [FETCH]

STAGE PLANS:
  Stage: Stage-1
    Tez
      DagId: hive_20220717084951_38336616-5c61-4c32-8f49-0b5892c492e9:25
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
      DagName: 
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: clickstream_tbl
                  Statistics: Num rows: 3427938 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: (event_type = 'puchase') (type: boolean)
                    Statistics: Num rows: 1713969 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: user_id (type: string), price (type: string)
                      outputColumnNames: user_id, price
                      Statistics: Num rows: 1713969 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        aggregations: sum(price)
                        keys: user_id (type: string)
                        mode: hash
                        outputColumnNames: _col0, _col1
                        Statistics: Num rows: 1713969 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: string)
                          null sort order: a
                          sort order: +
                          Map-reduce partition columns: _col0 (type: string)
                          Statistics: Num rows: 1713969 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                          tag: -1
                          value expressions: _col1 (type: double)
                          auto parallelism: true
            Path -> Alias:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl [clickstream_tbl]
            Path -> Partition:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl 
                Partition
                  base file name: clickstream_tbl
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    column.name.delimiter ,
                    columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                    columns.comments 
                    columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                    escapeChar \
                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                    name clickstream.clickstream_tbl
                    numFiles 2
                    numRows 0
                    quoteChar "
                    rawDataSize 0
                    separatorChar ,
                    serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                    skip.header.line.count 1
                    totalSize 1028381690
                    transient_lastDdlTime 1658039808
                  serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      column.name.delimiter ,
                      columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                      columns.comments 
                      columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                      escapeChar \
                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                      name clickstream.clickstream_tbl
                      numFiles 2
                      numRows 0
                      quoteChar "
                      rawDataSize 0
                      separatorChar ,
                      serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                      skip.header.line.count 1
                      totalSize 1028381690
                      transient_lastDdlTime 1658039808
                    serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                    name: clickstream.clickstream_tbl
                  name: clickstream.clickstream_tbl
            Truncated Path -> Alias:
              /clickstream.db/clickstream_tbl [clickstream_tbl]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0)
                keys: KEY._col0 (type: string)
                mode: mergepartial
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 856984 Data size: 257095273 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col1 (type: double)
                  null sort order: z
                  sort order: -
                  Statistics: Num rows: 856984 Data size: 257095273 Basic stats: COMPLETE Column stats: NONE
                  tag: -1
                  TopN: 10
                  TopN Hash Memory Usage: 0.1
                  value expressions: _col0 (type: string)
                  auto parallelism: false
        Reducer 3 
            Needs Tagging: false
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: string), KEY.reducesinkkey0 (type: double)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 856984 Data size: 257095273 Basic stats: COMPLETE Column stats: NONE
                Limit
                  Number of rows: 10
                  Statistics: Num rows: 10 Data size: 3000 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    GlobalTableId: 0
                    directory: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/6d06f1f1-d96b-4e15-a557-93756f1f3ebc/hive_2022-07-17_08-49-51_099_6221730846562506313-16/-mr-10001/.hive-staging_hive_2022-07-17_08-49-51_099_6221730846562506313-16/-ext-10002
                    NumFilesPerFileSink: 1
                    Statistics: Num rows: 10 Data size: 3000 Basic stats: COMPLETE Column stats: NONE
                    Stats Publishing Key Prefix: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/6d06f1f1-d96b-4e15-a557-93756f1f3ebc/hive_2022-07-17_08-49-51_099_6221730846562506313-16/-mr-10001/.hive-staging_hive_2022-07-17_08-49-51_099_6221730846562506313-16/-ext-10002/
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        properties:
                          columns _col0,_col1
                          columns.types string:double
                          escape.delim \
                          hive.serialization.extend.additional.nesting.levels true
                          serialization.escape.crlf true
                          serialization.format 1
                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    TotalFiles: 1
                    GatherStats: false
                    MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: 10
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717084951_38336616-5c61-4c32-8f49-0b5892c492e9); Time taken: 0.185 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717084951_38336616-5c61-4c32-8f49-0b5892c492e9): select user_id,sum(price) as Purchase_Amt from clickstream_tbl where event_type = 'puchase' group by user_id order by Purchase_Amt desc limit 10
INFO  : Query ID = hive_20220717084951_38336616-5c61-4c32-8f49-0b5892c492e9
INFO  : Total jobs = 1
INFO  : Launching Job 1 out of 1
INFO  : Starting task [Stage-1:MAPRED] in serial mode
INFO  : Session is already open
INFO  : Dag name: select user_id,sum(price) as Purchase_A...10(Stage-1)
INFO  : Tez session was closed. Reopening...
INFO  : Session re-established.
INFO  : Status: Running (Executing on YARN cluster with App id application_1658032091232_0011)

INFO  : Map 1: 0/2Reducer 2: 0/6Reducer 3: 0/1
INFO  : Map 1: 0/2Reducer 2: 0/6Reducer 3: 0/1
INFO  : Map 1: 0(+1)/2Reducer 2: 0/6Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6Reducer 3: 0/1
INFO  : Map 1: 1(+1)/2Reducer 2: 0/6Reducer 3: 0/1
INFO  : Map 1: 1(+1)/2Reducer 2: 0(+1)/6Reducer 3: 0/1
INFO  : Map 1: 1(+1)/2Reducer 2: 0(+1)/6Reducer 3: 0/1
INFO  : Map 1: 1(+1)/2Reducer 2: 0(+2)/6Reducer 3: 0/1
INFO  : Map 1: 2/2Reducer 2: 0(+3)/6Reducer 3: 0/1
INFO  : Map 1: 2/2Reducer 2: 1(+3)/6Reducer 3: 0/1
INFO  : Map 1: 2/2Reducer 2: 3(+3)/6Reducer 3: 0/1
INFO  : Map 1: 2/2Reducer 2: 4(+1)/6Reducer 3: 0(+1)/1
INFO  : Map 1: 2/2Reducer 2: 5(+1)/6Reducer 3: 0(+1)/1
INFO  : Map 1: 2/2Reducer 2: 6/6Reducer 3: 0(+1)/1
INFO  : Map 1: 2/2Reducer 2: 6/6Reducer 3: 1/1
INFO  : Completed executing command(queryId=hive_20220717084951_38336616-5c61-4c32-8f49-0b5892c492e9); Time taken: 67.014 seconds
INFO  : OK
+----------+---------------+
| user_id  | purchase_amt  |
+----------+---------------+
+----------+---------------+
No rows selected (67.213 seconds)
0: jdbc:hive2://localhost:10000/default> select user_id,sum(price) as Purchase_Amt from clickstream_tbl where event_t ype = 'purchase' group by user_id order by Purchase_Amt desc limit 10;
INFO  : Compiling command(queryId=hive_20220717085120_13b243a7-9e59-40a3-9b2d-453ca9a26625): select user_id,sum(price) as Purchase_Amt from clickstream_tbl where event_type = 'purchase' group by user_id order by Purchase_Amt desc limit 10
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:user_id, type:string, comment:null), FieldSchema(name:purchase_amt, type:double, comment:null)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717085120_13b243a7-9e59-40a3-9b2d-453ca9a26625 : STAGE DEPENDENCIES:
  Stage-1 is a root stage [MAPRED]
  Stage-0 depends on stages: Stage-1 [FETCH]

STAGE PLANS:
  Stage: Stage-1
    Tez
      DagId: hive_20220717085120_13b243a7-9e59-40a3-9b2d-453ca9a26625:26
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
      DagName: 
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: clickstream_tbl
                  Statistics: Num rows: 3427938 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: (event_type = 'purchase') (type: boolean)
                    Statistics: Num rows: 1713969 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: user_id (type: string), price (type: string)
                      outputColumnNames: user_id, price
                      Statistics: Num rows: 1713969 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        aggregations: sum(price)
                        keys: user_id (type: string)
                        mode: hash
                        outputColumnNames: _col0, _col1
                        Statistics: Num rows: 1713969 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: string)
                          null sort order: a
                          sort order: +
                          Map-reduce partition columns: _col0 (type: string)
                          Statistics: Num rows: 1713969 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                          tag: -1
                          value expressions: _col1 (type: double)
                          auto parallelism: true
            Path -> Alias:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl [clickstream_tbl]
            Path -> Partition:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl 
                Partition
                  base file name: clickstream_tbl
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    column.name.delimiter ,
                    columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                    columns.comments 
                    columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                    escapeChar \
                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                    name clickstream.clickstream_tbl
                    numFiles 2
                    numRows 0
                    quoteChar "
                    rawDataSize 0
                    separatorChar ,
                    serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                    skip.header.line.count 1
                    totalSize 1028381690
                    transient_lastDdlTime 1658039808
                  serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      column.name.delimiter ,
                      columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                      columns.comments 
                      columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                      escapeChar \
                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                      name clickstream.clickstream_tbl
                      numFiles 2
                      numRows 0
                      quoteChar "
                      rawDataSize 0
                      separatorChar ,
                      serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                      skip.header.line.count 1
                      totalSize 1028381690
                      transient_lastDdlTime 1658039808
                    serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                    name: clickstream.clickstream_tbl
                  name: clickstream.clickstream_tbl
            Truncated Path -> Alias:
              /clickstream.db/clickstream_tbl [clickstream_tbl]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0)
                keys: KEY._col0 (type: string)
                mode: mergepartial
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 856984 Data size: 257095273 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col1 (type: double)
                  null sort order: z
                  sort order: -
                  Statistics: Num rows: 856984 Data size: 257095273 Basic stats: COMPLETE Column stats: NONE
                  tag: -1
                  TopN: 10
                  TopN Hash Memory Usage: 0.1
                  value expressions: _col0 (type: string)
                  auto parallelism: false
        Reducer 3 
            Needs Tagging: false
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: string), KEY.reducesinkkey0 (type: double)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 856984 Data size: 257095273 Basic stats: COMPLETE Column stats: NONE
                Limit
                  Number of rows: 10
                  Statistics: Num rows: 10 Data size: 3000 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    GlobalTableId: 0
                    directory: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/6d06f1f1-d96b-4e15-a557-93756f1f3ebc/hive_2022-07-17_08-51-20_067_8141296481582493960-16/-mr-10001/.hive-staging_hive_2022-07-17_08-51-20_067_8141296481582493960-16/-ext-10002
                    NumFilesPerFileSink: 1
                    Statistics: Num rows: 10 Data size: 3000 Basic stats: COMPLETE Column stats: NONE
                    Stats Publishing Key Prefix: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/6d06f1f1-d96b-4e15-a557-93756f1f3ebc/hive_2022-07-17_08-51-20_067_8141296481582493960-16/-mr-10001/.hive-staging_hive_2022-07-17_08-51-20_067_8141296481582493960-16/-ext-10002/
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        properties:
                          columns _col0,_col1
                          columns.types string:double
                          escape.delim \
                          hive.serialization.extend.additional.nesting.levels true
                          serialization.escape.crlf true
                          serialization.format 1
                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    TotalFiles: 1
                    GatherStats: false
                    MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: 10
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717085120_13b243a7-9e59-40a3-9b2d-453ca9a26625); Time taken: 0.16 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717085120_13b243a7-9e59-40a3-9b2d-453ca9a26625): select user_id,sum(price) as Purchase_Amt from clickstream_tbl where event_type = 'purchase' group by user_id order by Purchase_Amt desc limit 10
INFO  : Query ID = hive_20220717085120_13b243a7-9e59-40a3-9b2d-453ca9a26625
INFO  : Total jobs = 1
INFO  : Launching Job 1 out of 1
INFO  : Starting task [Stage-1:MAPRED] in serial mode
INFO  : Session is already open
INFO  : Dag name: select user_id,sum(price) as Purchase_A...10(Stage-1)
INFO  : Status: Running (Executing on YARN cluster with App id application_1658032091232_0011)

INFO  : Map 1: 0/2Reducer 2: 0/6Reducer 3: 0/1
INFO  : Map 1: 0/2Reducer 2: 0/6Reducer 3: 0/1
INFO  : Map 1: 0(+1)/2Reducer 2: 0/6Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/6Reducer 3: 0/1
INFO  : Map 1: 1(+1)/2Reducer 2: 0(+1)/6Reducer 3: 0/1
INFO  : Map 1: 1(+1)/2Reducer 2: 0(+1)/6Reducer 3: 0/1
INFO  : Map 1: 1(+1)/2Reducer 2: 0(+2)/6Reducer 3: 0/1
INFO  : Map 1: 2/2Reducer 2: 0(+3)/6Reducer 3: 0/1
INFO  : Map 1: 2/2Reducer 2: 1(+3)/6Reducer 3: 0/1
INFO  : Map 1: 2/2Reducer 2: 3(+2)/6Reducer 3: 0/1
INFO  : Map 1: 2/2Reducer 2: 3(+3)/6Reducer 3: 0/1
INFO  : Map 1: 2/2Reducer 2: 4(+2)/6Reducer 3: 0(+1)/1
INFO  : Map 1: 2/2Reducer 2: 5(+1)/6Reducer 3: 0(+1)/1
INFO  : Map 1: 2/2Reducer 2: 6/6Reducer 3: 0(+1)/1
INFO  : Map 1: 2/2Reducer 2: 6/6Reducer 3: 1/1
INFO  : Completed executing command(queryId=hive_20220717085120_13b243a7-9e59-40a3-9b2d-453ca9a26625); Time taken: 64.588 seconds
INFO  : OK
+------------+---------------------+
|  user_id   |    purchase_amt     |
+------------+---------------------+
| 557790271  | 2715.869999999991   |
| 150318419  | 1645.97             |
| 562167663  | 1352.8500000000004  |
| 531900924  | 1329.4500000000003  |
| 557850743  | 1295.4800000000002  |
| 522130011  | 1185.3899999999994  |
| 561592095  | 1109.6999999999996  |
| 431950134  | 1097.5899999999995  |
| 566576008  | 1056.3600000000017  |
| 521347209  | 1040.9099999999999  |
+------------+---------------------+
10 rows selected (64.799 seconds)
0: jdbc:hive2://localhost:10000/default> create view monthly_brand_price as (select month(event_time) as Month, brand , sum(price) as Monthly_Price from clickstream_tbl group by Month,brand;
Error: Error while compiling statement: FAILED: ParseException line 1:147 mismatched input '<EOF>' expecting ) near 'brand' in create view statement (state=42000,code=40000)
0: jdbc:hive2://localhost:10000/default> create view monthly_brand_price as (select month(event_time) as Month, brand , sum(price) as Monthly_Price from clickstream_tbl group by Month,brand);
Error: Error while compiling statement: FAILED: SemanticException [Error 10004]: Line 1:136 Invalid table alias or column reference 'Month': (possible column names are: event_time, event_type, product_id, category_id, category_code, brand, price, user_id, user_session) (state=42000,code=10004)
0: jdbc:hive2://localhost:10000/default> create view monthly_brand_price as (select month(event_time) as Month, brand , sum(price) as Monthly_Price from clickstream_tbl group by month(event_time),brand);
INFO  : Compiling command(queryId=hive_20220717090505_10621b44-7cad-431d-a0b7-0e1f65a2fe86): create view monthly_brand_price as (select month(event_time) as Month, brand, sum(price) as Monthly_Price from clickstream_tbl group by month(event_time),brand)
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:month, type:int, comment:null), FieldSchema(name:brand, type:string, comment:null), FieldSchema(name:monthly_price, type:double, comment:null)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717090505_10621b44-7cad-431d-a0b7-0e1f65a2fe86 : STAGE DEPENDENCIES:
  Stage-1 is a root stage [DDL]

STAGE PLANS:
  Stage: Stage-1
      Create View Operator:
        Create View
          or replace: false
          columns: month int, brand string, monthly_price double
          expanded text: (select month(`clickstream_tbl`.`event_time`) as `Month`, `clickstream_tbl`.`brand`, sum(`clickstream_tbl`.`price`) as `Monthly_Price` from `clickstream`.`clickstream_tbl` group by month(`clickstream_tbl`.`event_time`),`clickstream_tbl`.`brand`)
          name: clickstream.monthly_brand_price
          original text: (select month(event_time) as Month, brand, sum(price) as Monthly_Price from clickstream_tbl group by month(event_time),brand)
          rewrite enabled: false


INFO  : Completed compiling command(queryId=hive_20220717090505_10621b44-7cad-431d-a0b7-0e1f65a2fe86); Time taken: 0.318 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717090505_10621b44-7cad-431d-a0b7-0e1f65a2fe86): create view monthly_brand_price as (select month(event_time) as Month, brand, sum(price) as Monthly_Price from clickstream_tbl group by month(event_time),brand)
INFO  : Starting task [Stage-1:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20220717090505_10621b44-7cad-431d-a0b7-0e1f65a2fe86); Time taken: 0.057 seconds
INFO  : OK
No rows affected (0.402 seconds)
0: jdbc:hive2://localhost:10000/default> select * from monthly_brand_price limit 5;
INFO  : Compiling command(queryId=hive_20220717090521_d2d5fe79-58b4-4923-ace4-cadbc5f8057d): select * from monthly_brand_price limit 5
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:monthly_brand_price.month, type:int, comment:null), FieldSchema(name:monthly_brand_price.brand, type:string, comment:null), FieldSchema(name:monthly_brand_price.monthly_price, type:double, comment:null)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717090521_d2d5fe79-58b4-4923-ace4-cadbc5f8057d : STAGE DEPENDENCIES:
  Stage-1 is a root stage [MAPRED]
  Stage-0 depends on stages: Stage-1 [FETCH]

STAGE PLANS:
  Stage: Stage-1
    Tez
      DagId: hive_20220717090521_d2d5fe79-58b4-4923-ace4-cadbc5f8057d:27
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
      DagName: 
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: clickstream_tbl
                  properties:
                    insideView TRUE
                  Statistics: Num rows: 3427938 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Select Operator
                    expressions: month(event_time) (type: int), brand (type: string), price (type: string)
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 3427938 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      aggregations: sum(_col2)
                      keys: _col0 (type: int), _col1 (type: string)
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 3427938 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: string)
                        null sort order: aa
                        sort order: ++
                        Map-reduce partition columns: _col0 (type: int), _col1 (type: string)
                        Statistics: Num rows: 3427938 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                        tag: -1
                        TopN: 5
                        TopN Hash Memory Usage: 0.1
                        value expressions: _col2 (type: double)
                        auto parallelism: true
            Path -> Alias:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl [clickstream_tbl]
            Path -> Partition:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl 
                Partition
                  base file name: clickstream_tbl
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    column.name.delimiter ,
                    columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                    columns.comments 
                    columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                    escapeChar \
                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    insideView TRUE
                    location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                    name clickstream.clickstream_tbl
                    numFiles 2
                    numRows 0
                    quoteChar "
                    rawDataSize 0
                    separatorChar ,
                    serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                    skip.header.line.count 1
                    totalSize 1028381690
                    transient_lastDdlTime 1658039808
                  serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      column.name.delimiter ,
                      columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                      columns.comments 
                      columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                      escapeChar \
                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      insideView TRUE
                      location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                      name clickstream.clickstream_tbl
                      numFiles 2
                      numRows 0
                      quoteChar "
                      rawDataSize 0
                      separatorChar ,
                      serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                      skip.header.line.count 1
                      totalSize 1028381690
                      transient_lastDdlTime 1658039808
                    serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                    name: clickstream.clickstream_tbl
                  name: clickstream.clickstream_tbl
            Truncated Path -> Alias:
              /clickstream.db/clickstream_tbl [clickstream_tbl]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0)
                keys: KEY._col0 (type: int), KEY._col1 (type: string)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1713969 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                Limit
                  Number of rows: 5
                  Statistics: Num rows: 5 Data size: 1500 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    GlobalTableId: 0
                    directory: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/6d06f1f1-d96b-4e15-a557-93756f1f3ebc/hive_2022-07-17_09-05-21_827_892162223508004822-16/-mr-10001/.hive-staging_hive_2022-07-17_09-05-21_827_892162223508004822-16/-ext-10002
                    NumFilesPerFileSink: 1
                    Statistics: Num rows: 5 Data size: 1500 Basic stats: COMPLETE Column stats: NONE
                    Stats Publishing Key Prefix: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/6d06f1f1-d96b-4e15-a557-93756f1f3ebc/hive_2022-07-17_09-05-21_827_892162223508004822-16/-mr-10001/.hive-staging_hive_2022-07-17_09-05-21_827_892162223508004822-16/-ext-10002/
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        properties:
                          columns _col0,_col1,_col2
                          columns.types int:string:double
                          escape.delim \
                          hive.serialization.extend.additional.nesting.levels true
                          serialization.escape.crlf true
                          serialization.format 1
                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    TotalFiles: 1
                    GatherStats: false
                    MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: 5
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717090521_d2d5fe79-58b4-4923-ace4-cadbc5f8057d); Time taken: 0.225 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717090521_d2d5fe79-58b4-4923-ace4-cadbc5f8057d): select * from monthly_brand_price limit 5
INFO  : Query ID = hive_20220717090521_d2d5fe79-58b4-4923-ace4-cadbc5f8057d
INFO  : Total jobs = 1
INFO  : Launching Job 1 out of 1
INFO  : Starting task [Stage-1:MAPRED] in serial mode
INFO  : Session is already open
INFO  : Dag name: select * from monthly_brand_price limit 5(Stage-1)
INFO  : Tez session was closed. Reopening...
INFO  : Session re-established.
INFO  : Status: Running (Executing on YARN cluster with App id application_1658032091232_0012)

INFO  : Map 1: 0/2Reducer 2: 0/10
INFO  : Map 1: 0/2Reducer 2: 0/10
INFO  : Map 1: 0(+1)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10
INFO  : Map 1: 1(+1)/2Reducer 2: 0/10
INFO  : Map 1: 1(+1)/2Reducer 2: 0/10
INFO  : Map 1: 2/2Reducer 2: 0/1
INFO  : Map 1: 2/2Reducer 2: 0(+1)/1
INFO  : Map 1: 2/2Reducer 2: 1/1
INFO  : Completed executing command(queryId=hive_20220717090521_d2d5fe79-58b4-4923-ace4-cadbc5f8057d); Time taken: 83.764 seconds
INFO  : OK
+----------------------------+----------------------------+------------------------------------+
| monthly_brand_price.month  | monthly_brand_price.brand  | monthly_brand_price.monthly_price  |
+----------------------------+----------------------------+------------------------------------+
| 10                         |                            | 1.2475523980005352E7               |
| 10                         | airnails                   | 202151.00999996433                 |
| 10                         | almea                      | 32792.11999999966                  |
| 10                         | andrea                     | 997.1999999999977                  |
| 10                         | ardell                     | 30837.820000000258                 |
+----------------------------+----------------------------+------------------------------------+
5 rows selected (84.027 seconds)
0: jdbc:hive2://localhost:10000/default> create view monthly_brand_price as (select month(event_time) as Month, brand , sum(price) as Monthly_Price from clickstream_tbl group by month(event_time),brand order by month(event_time),brand) ;
Error: Error while compiling statement: FAILED: SemanticException [Error 10004]: Line 1:175 Invalid table alias or column reference 'event_time': (possible column names are: month, brand, monthly_price) (state=42000,code=10004)
0: jdbc:hive2://localhost:10000/default> create view monthly_brand_price as (select month(event_time) as Month, brand , sum(price) as Monthly_Price from clickstream_tbl group by month(event_time),brand order by Month,brand);
INFO  : Compiling command(queryId=hive_20220717090800_5b12d61e-78c3-4799-a908-2addfadb06f7): create view monthly_brand_price as (select month(event_time) as Month, brand, sum(price) as Monthly_Price from clickstream_tbl group by month(event_time),brand order by Month,brand)
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:month, type:int, comment:null), FieldSchema(name:brand, type:string, comment:null), FieldSchema(name:monthly_price, type:double, comment:null)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717090800_5b12d61e-78c3-4799-a908-2addfadb06f7 : STAGE DEPENDENCIES:
  Stage-1 is a root stage [DDL]

STAGE PLANS:
  Stage: Stage-1
      Create View Operator:
        Create View
          or replace: false
          columns: month int, brand string, monthly_price double
          expanded text: (select month(`clickstream_tbl`.`event_time`) as `Month`, `clickstream_tbl`.`brand`, sum(`clickstream_tbl`.`price`) as `Monthly_Price` from `clickstream`.`clickstream_tbl` group by month(`clickstream_tbl`.`event_time`),`clickstream_tbl`.`brand` order by Month,brand)
          name: clickstream.monthly_brand_price
          original text: (select month(event_time) as Month, brand, sum(price) as Monthly_Price from clickstream_tbl group by month(event_time),brand order by Month,brand)
          rewrite enabled: false


INFO  : Completed compiling command(queryId=hive_20220717090800_5b12d61e-78c3-4799-a908-2addfadb06f7); Time taken: 0.144 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717090800_5b12d61e-78c3-4799-a908-2addfadb06f7): create view monthly_brand_price as (select month(event_time) as Month, brand, sum(price) as Monthly_Price from clickstream_tbl group by month(event_time),brand order by Month,brand)
INFO  : Starting task [Stage-1:DDL] in serial mode
ERROR : FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. AlreadyExistsException(message:Table monthly_brand_price already exists)
INFO  : Completed executing command(queryId=hive_20220717090800_5b12d61e-78c3-4799-a908-2addfadb06f7); Time taken: 0.035 seconds
Error: org.apache.hive.service.cli.HiveSQLException: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. AlreadyExistsException(message:Table monthly_brand_price already exists)
at org.apache.hive.service.cli.operation.Operation.toSQLException(Operation.java:380)
at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:254)
at org.apache.hive.service.cli.operation.SQLOperation.access$800(SQLOperation.java:88)
at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:345)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:422)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1926)
at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:360)
at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
at java.util.concurrent.FutureTask.run(FutureTask.java:266)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: AlreadyExistsException(message:Table monthly_brand_price already exists)
at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:884)
at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:892)
at org.apache.hadoop.hive.ql.exec.DDLTask.createView(DDLTask.java:4607)
at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:396)
at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:203)
at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:100)
at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:2183)
at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1839)
at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1526)
at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1237)
at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1232)
at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:252)
... 11 more
Caused by: AlreadyExistsException(message:Table monthly_brand_price already exists)
at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$create_table_with_environment_context_result$create_table_with_environment_context_resultStandardScheme.read(ThriftHiveMetastore.java:42362)
at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$create_table_with_environment_context_result$create_table_with_environment_context_resultStandardScheme.read(ThriftHiveMetastore.java:42348)
at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$create_table_with_environment_context_result.read(ThriftHiveMetastore.java:42274)
at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:86)
at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_create_table_with_environment_context(ThriftHiveMetastore.java:1207)
at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.create_table_with_environment_context(ThriftHiveMetastore.java:1193)
at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.create_table_with_environment_context(HiveMetaStoreClient.java:2419)
at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.create_table_with_environment_context(SessionHiveMetaStoreClient.java:93)
at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:755)
at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:743)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:498)
at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:177)
at com.sun.proxy.$Proxy32.createTable(Unknown Source)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:498)
at org.apache.hadoop.hive.metastore.HiveMetaStoreClient$SynchronizedHandler.invoke(HiveMetaStoreClient.java:2350)
at com.sun.proxy.$Proxy32.createTable(Unknown Source)
at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:877)
... 22 more (state=08S01,code=1)
0: jdbc:hive2://localhost:10000/default> shwootw tables;
INFO  : Compiling command(queryId=hive_20220717090814_3d2593cc-e3e2-4ab1-a172-b877d3b4de25): show tables
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:tab_name, type:string, comment:from deserializer)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717090814_3d2593cc-e3e2-4ab1-a172-b877d3b4de25 : STAGE DEPENDENCIES:
  Stage-0 is a root stage [DDL]
  Stage-1 depends on stages: Stage-0 [FETCH]

STAGE PLANS:
  Stage: Stage-0
      Show Table Operator:
        Show Tables
          database name: clickstream
          result file: file:/mnt/tmp/hive/6d06f1f1-d96b-4e15-a557-93756f1f3ebc/hive_2022-07-17_09-08-14_447_6892323022275652825-16/-local-10000

  Stage: Stage-1
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717090814_3d2593cc-e3e2-4ab1-a172-b877d3b4de25); Time taken: 0.019 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717090814_3d2593cc-e3e2-4ab1-a172-b877d3b4de25): show tables
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20220717090814_3d2593cc-e3e2-4ab1-a172-b877d3b4de25); Time taken: 0.01 seconds
INFO  : OK
+--------------------------+
|         tab_name         |
+--------------------------+
| clickstream_stats        |
| clickstream_tbl          |
| monthly_brand_price      |
| part_mnth_buck_type_tbl  |
+--------------------------+
4 rows selected (0.046 seconds)
0: jdbc:hive2://localhost:10000/default> drop table monthly_brand_price
. . . . . . . . . . . . . . . . . . . .> l;
INFO  : Compiling command(queryId=hive_20220717090830_80c14820-3dc7-4ab4-912d-4710c1b0aeb9): drop table monthly_brand_price
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : EXPLAIN output for queryid hive_20220717090830_80c14820-3dc7-4ab4-912d-4710c1b0aeb9 : STAGE DEPENDENCIES:
  Stage-0 is a root stage [DDL]

STAGE PLANS:
  Stage: Stage-0
      Drop Table Operator:
        Drop Table
          table: monthly_brand_price


INFO  : Completed compiling command(queryId=hive_20220717090830_80c14820-3dc7-4ab4-912d-4710c1b0aeb9); Time taken: 0.024 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717090830_80c14820-3dc7-4ab4-912d-4710c1b0aeb9): drop table monthly_brand_price
INFO  : Starting task [Stage-0:DDL] in serial mode
ERROR : FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. Cannot drop a view with DROP TABLE
INFO  : Completed executing command(queryId=hive_20220717090830_80c14820-3dc7-4ab4-912d-4710c1b0aeb9); Time taken: 0.011 seconds
Error: org.apache.hive.service.cli.HiveSQLException: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. Cannot drop a view with DROP TABLE
at org.apache.hive.service.cli.operation.Operation.toSQLException(Operation.java:380)
at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:254)
at org.apache.hive.service.cli.operation.SQLOperation.access$800(SQLOperation.java:88)
at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:345)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:422)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1926)
at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:360)
at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
at java.util.concurrent.FutureTask.run(FutureTask.java:266)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Cannot drop a view with DROP TABLE
at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:4104)
at org.apache.hadoop.hive.ql.exec.DDLTask.dropTableOrPartitions(DDLTask.java:4038)
at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:379)
at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:203)
at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:100)
at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:2183)
at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1839)
at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1526)
at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1237)
at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1232)
at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:252)
... 11 more (state=08S01,code=1)
0: jdbc:hive2://localhost:10000/default> ;drop table monthly_brand_price;
INFO  : Compiling command(queryId=hive_20220717090836_e8e1b394-207b-4d3a-a135-8d240b39ea81): drop table monthly_brand_price
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : EXPLAIN output for queryid hive_20220717090836_e8e1b394-207b-4d3a-a135-8d240b39ea81 : STAGE DEPENDENCIES:
  Stage-0 is a root stage [DDL]

STAGE PLANS:
  Stage: Stage-0
      Drop Table Operator:
        Drop Table
          table: monthly_brand_price


INFO  : Completed compiling command(queryId=hive_20220717090836_e8e1b394-207b-4d3a-a135-8d240b39ea81); Time taken: 0.021 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717090836_e8e1b394-207b-4d3a-a135-8d240b39ea81): drop table monthly_brand_price
INFO  : Starting task [Stage-0:DDL] in serial mode
ERROR : FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. Cannot drop a view with DROP TABLE
INFO  : Completed executing command(queryId=hive_20220717090836_e8e1b394-207b-4d3a-a135-8d240b39ea81); Time taken: 0.01 seconds
Error: org.apache.hive.service.cli.HiveSQLException: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. Cannot drop a view with DROP TABLE
at org.apache.hive.service.cli.operation.Operation.toSQLException(Operation.java:380)
at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:254)
at org.apache.hive.service.cli.operation.SQLOperation.access$800(SQLOperation.java:88)
at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:345)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:422)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1926)
at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:360)
at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
at java.util.concurrent.FutureTask.run(FutureTask.java:266)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Cannot drop a view with DROP TABLE
at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:4104)
at org.apache.hadoop.hive.ql.exec.DDLTask.dropTableOrPartitions(DDLTask.java:4038)
at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:379)
at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:203)
at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:100)
at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:2183)
at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1839)
at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1526)
at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1237)
at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1232)
at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:252)
... 11 more (state=08S01,code=1)
0: jdbc:hive2://localhost:10000/default> drop table monthly_brand_price; monthly_brand_price; monthly_brand_price; monthly_brand_price; monthly_brand_price; monthly_brand_price;v monthly_brand_price;i monthly_brand_price;e monthly_brand_price;w monthly_brand_price;
INFO  : Compiling command(queryId=hive_20220717090842_424c5d52-a8fd-4ebb-a692-89aa3857dc39): drop view monthly_brand_price
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : EXPLAIN output for queryid hive_20220717090842_424c5d52-a8fd-4ebb-a692-89aa3857dc39 : STAGE DEPENDENCIES:
  Stage-0 is a root stage [DDL]

STAGE PLANS:
  Stage: Stage-0
      Drop Table Operator:
        Drop Table
          table: monthly_brand_price


INFO  : Completed compiling command(queryId=hive_20220717090842_424c5d52-a8fd-4ebb-a692-89aa3857dc39); Time taken: 0.033 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717090842_424c5d52-a8fd-4ebb-a692-89aa3857dc39): drop view monthly_brand_price
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20220717090842_424c5d52-a8fd-4ebb-a692-89aa3857dc39); Time taken: 0.071 seconds
INFO  : OK
No rows affected (0.111 seconds)
0: jdbc:hive2://localhost:10000/default> drop view monthly_brand_price;table monthly_brand_price;;drop table monthly_brand_priceshow tables;
INFO  : Compiling command(queryId=hive_20220717090848_362a043d-851a-4d20-ad50-7d945383cc46): show tables
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:tab_name, type:string, comment:from deserializer)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717090848_362a043d-851a-4d20-ad50-7d945383cc46 : STAGE DEPENDENCIES:
  Stage-0 is a root stage [DDL]
  Stage-1 depends on stages: Stage-0 [FETCH]

STAGE PLANS:
  Stage: Stage-0
      Show Table Operator:
        Show Tables
          database name: clickstream
          result file: file:/mnt/tmp/hive/6d06f1f1-d96b-4e15-a557-93756f1f3ebc/hive_2022-07-17_09-08-48_904_8465123844490288472-16/-local-10000

  Stage: Stage-1
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717090848_362a043d-851a-4d20-ad50-7d945383cc46); Time taken: 0.018 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717090848_362a043d-851a-4d20-ad50-7d945383cc46): show tables
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20220717090848_362a043d-851a-4d20-ad50-7d945383cc46); Time taken: 0.013 seconds
INFO  : OK
+--------------------------+
|         tab_name         |
+--------------------------+
| clickstream_stats        |
| clickstream_tbl          |
| part_mnth_buck_type_tbl  |
+--------------------------+
3 rows selected (0.045 seconds)
0: jdbc:hive2://localhost:10000/default> show tables;drop view monthly_brand_price;table monthly_brand_price;;drop table monthly_brand_priceshow tables;create view monthly_brand_price as (select month(event_time) as Month, brand, sum(price) as Monthly_Price from clickstream_tbl group by month(event_time),brand order by Month,brand);
INFO  : Compiling command(queryId=hive_20220717090946_d605f30d-b2e8-4505-814d-fcf18cb4c1b5): create view monthly_brand_price as (select month(event_time) as Month, brand, sum(price) as Monthly_Price from clickstream_tbl group by month(event_time),brand order by Month,brand)
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:month, type:int, comment:null), FieldSchema(name:brand, type:string, comment:null), FieldSchema(name:monthly_price, type:double, comment:null)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717090946_d605f30d-b2e8-4505-814d-fcf18cb4c1b5 : STAGE DEPENDENCIES:
  Stage-1 is a root stage [DDL]

STAGE PLANS:
  Stage: Stage-1
      Create View Operator:
        Create View
          or replace: false
          columns: month int, brand string, monthly_price double
          expanded text: (select month(`clickstream_tbl`.`event_time`) as `Month`, `clickstream_tbl`.`brand`, sum(`clickstream_tbl`.`price`) as `Monthly_Price` from `clickstream`.`clickstream_tbl` group by month(`clickstream_tbl`.`event_time`),`clickstream_tbl`.`brand` order by Month,brand)
          name: clickstream.monthly_brand_price
          original text: (select month(event_time) as Month, brand, sum(price) as Monthly_Price from clickstream_tbl group by month(event_time),brand order by Month,brand)
          rewrite enabled: false


INFO  : Completed compiling command(queryId=hive_20220717090946_d605f30d-b2e8-4505-814d-fcf18cb4c1b5); Time taken: 0.186 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717090946_d605f30d-b2e8-4505-814d-fcf18cb4c1b5): create view monthly_brand_price as (select month(event_time) as Month, brand, sum(price) as Monthly_Price from clickstream_tbl group by month(event_time),brand order by Month,brand)
INFO  : Starting task [Stage-1:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20220717090946_d605f30d-b2e8-4505-814d-fcf18cb4c1b5); Time taken: 0.036 seconds
INFO  : OK
No rows affected (0.229 seconds)
0: jdbc:hive2://localhost:10000/default> create view monthly_brand_price as (select month(event_time) as Month, brand, sum(price) as Monthly_Price from clickstream_tbl group by month(event_time),brand order by Month,brand);show tables;drop view monthly_brand_price;table monthly_brand_price;;drop table monthly_brand_priceshow tables;create view monthly_brand_price as (select month(event_time) as Month, brand, sum(price) as Monthly_Price from clickstream_tbl group by month(event_time),brand order by Month,brand);month(event_time),brand);select * from monthly_brand_price limit 5;;1;0;
INFO  : Compiling command(queryId=hive_20220717090959_c42c8d8d-14ce-4cac-8a9b-3e2c3bb9d8e2): select * from monthly_brand_price limit 10
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:monthly_brand_price.month, type:int, comment:null), FieldSchema(name:monthly_brand_price.brand, type:string, comment:null), FieldSchema(name:monthly_brand_price.monthly_price, type:double, comment:null)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717090959_c42c8d8d-14ce-4cac-8a9b-3e2c3bb9d8e2 : STAGE DEPENDENCIES:
  Stage-1 is a root stage [MAPRED]
  Stage-0 depends on stages: Stage-1 [FETCH]

STAGE PLANS:
  Stage: Stage-1
    Tez
      DagId: hive_20220717090959_c42c8d8d-14ce-4cac-8a9b-3e2c3bb9d8e2:28
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
      DagName: 
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: clickstream_tbl
                  properties:
                    insideView TRUE
                  Statistics: Num rows: 3427938 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Select Operator
                    expressions: month(event_time) (type: int), brand (type: string), price (type: string)
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 3427938 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      aggregations: sum(_col2)
                      keys: _col0 (type: int), _col1 (type: string)
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 3427938 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: string)
                        null sort order: aa
                        sort order: ++
                        Map-reduce partition columns: _col0 (type: int), _col1 (type: string)
                        Statistics: Num rows: 3427938 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                        tag: -1
                        TopN: 10
                        TopN Hash Memory Usage: 0.1
                        value expressions: _col2 (type: double)
                        auto parallelism: true
            Path -> Alias:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl [clickstream_tbl]
            Path -> Partition:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl 
                Partition
                  base file name: clickstream_tbl
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    column.name.delimiter ,
                    columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                    columns.comments 
                    columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                    escapeChar \
                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    insideView TRUE
                    location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                    name clickstream.clickstream_tbl
                    numFiles 2
                    numRows 0
                    quoteChar "
                    rawDataSize 0
                    separatorChar ,
                    serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                    skip.header.line.count 1
                    totalSize 1028381690
                    transient_lastDdlTime 1658039808
                  serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      column.name.delimiter ,
                      columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                      columns.comments 
                      columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                      escapeChar \
                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      insideView TRUE
                      location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                      name clickstream.clickstream_tbl
                      numFiles 2
                      numRows 0
                      quoteChar "
                      rawDataSize 0
                      separatorChar ,
                      serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                      skip.header.line.count 1
                      totalSize 1028381690
                      transient_lastDdlTime 1658039808
                    serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                    name: clickstream.clickstream_tbl
                  name: clickstream.clickstream_tbl
            Truncated Path -> Alias:
              /clickstream.db/clickstream_tbl [clickstream_tbl]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0)
                keys: KEY._col0 (type: int), KEY._col1 (type: string)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1713969 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: int), _col1 (type: string)
                  null sort order: aa
                  sort order: ++
                  Statistics: Num rows: 1713969 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                  tag: -1
                  TopN: 10
                  TopN Hash Memory Usage: 0.1
                  value expressions: _col2 (type: double)
                  auto parallelism: false
        Reducer 3 
            Needs Tagging: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string), VALUE._col0 (type: double)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1713969 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                Limit
                  Number of rows: 10
                  Statistics: Num rows: 10 Data size: 3000 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    GlobalTableId: 0
                    directory: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/6d06f1f1-d96b-4e15-a557-93756f1f3ebc/hive_2022-07-17_09-09-59_519_4418318677550114334-16/-mr-10001/.hive-staging_hive_2022-07-17_09-09-59_519_4418318677550114334-16/-ext-10002
                    NumFilesPerFileSink: 1
                    Statistics: Num rows: 10 Data size: 3000 Basic stats: COMPLETE Column stats: NONE
                    Stats Publishing Key Prefix: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/6d06f1f1-d96b-4e15-a557-93756f1f3ebc/hive_2022-07-17_09-09-59_519_4418318677550114334-16/-mr-10001/.hive-staging_hive_2022-07-17_09-09-59_519_4418318677550114334-16/-ext-10002/
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        properties:
                          columns _col0,_col1,_col2
                          columns.types int:string:double
                          escape.delim \
                          hive.serialization.extend.additional.nesting.levels true
                          serialization.escape.crlf true
                          serialization.format 1
                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    TotalFiles: 1
                    GatherStats: false
                    MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: 10
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717090959_c42c8d8d-14ce-4cac-8a9b-3e2c3bb9d8e2); Time taken: 0.157 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717090959_c42c8d8d-14ce-4cac-8a9b-3e2c3bb9d8e2): select * from monthly_brand_price limit 10
INFO  : Query ID = hive_20220717090959_c42c8d8d-14ce-4cac-8a9b-3e2c3bb9d8e2
INFO  : Total jobs = 1
INFO  : Launching Job 1 out of 1
INFO  : Starting task [Stage-1:MAPRED] in serial mode
INFO  : Session is already open
INFO  : Dag name: select * from monthly_brand_price limit 10(Stage-1)
INFO  : Status: Running (Executing on YARN cluster with App id application_1658032091232_0012)

INFO  : Map 1: 0/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+1)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 1(+1)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 2/2Reducer 2: 0/1Reducer 3: 0/1
INFO  : Map 1: 2/2Reducer 2: 0(+1)/1Reducer 3: 0/1
INFO  : Map 1: 2/2Reducer 2: 1/1Reducer 3: 0/1
INFO  : Map 1: 2/2Reducer 2: 1/1Reducer 3: 0(+1)/1
INFO  : Map 1: 2/2Reducer 2: 1/1Reducer 3: 1/1
INFO  : Completed executing command(queryId=hive_20220717090959_c42c8d8d-14ce-4cac-8a9b-3e2c3bb9d8e2); Time taken: 70.909 seconds
INFO  : OK
+----------------------------+----------------------------+------------------------------------+
| monthly_brand_price.month  | monthly_brand_price.brand  | monthly_brand_price.monthly_price  |
+----------------------------+----------------------------+------------------------------------+
| 10                         |                            | 1.2475523980005352E7               |
| 10                         | airnails                   | 202151.00999996433                 |
| 10                         | almea                      | 32792.11999999966                  |
| 10                         | andrea                     | 997.1999999999977                  |
| 10                         | ardell                     | 30837.820000000258                 |
| 10                         | art-visage                 | 39194.68000000109                  |
| 10                         | artex                      | 42072.87000000202                  |
| 10                         | aura                       | 1670.0499999999984                 |
| 10                         | australis                  | 663.9900000000001                  |
| 10                         | balbcare                   | 3265.1000000000454                 |
+----------------------------+----------------------------+------------------------------------+
10 rows selected (71.11 seconds)
0: jdbc:hive2://localhost:10000/default> select * from monthly_brand_price limit 10;glimit 10;rlimit 10;olimit 10;ulimit 10;plimit 10; limit 10;blimit 10;ylimit 10; limit 10;blimit 10;rlimit 10;alimit 10;nlimit 10;dlimit 10; limit 10;olimit 10;rlimit 10;dlimit 10;elimit 10;rlimit 10; limit 10;blimit 10;ylimit 10; limit 10;blimit 10;rlimit 10;alimit 10;nlimit 10;dlimit 10; limit 10;
Error: Error while compiling statement: FAILED: SemanticException [Error 10025]: Expression not in GROUP BY key month (state=42000,code=10025)
0: jdbc:hive2://localhost:10000/default> select * from monthly_brand_price group by brand order by brand limit 10;order by brand limit 10;order by brand limit 10;order by brand limit 10;order by brand limit 10;order by brand limit 10;order by brand limit 10;order by brand limit 10;order by brand limit 10;order by brand limit 10;order by brand limit 10;order by brand limit 10;order by brand limit 10;order by brand limit 10;order by brand limit 10;order by brand limit 10;
INFO  : Compiling command(queryId=hive_20220717091847_b1e78de7-ee18-4c40-89d4-b989e1d5f04f): select * from monthly_brand_price order by brand limit 10
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:monthly_brand_price.month, type:int, comment:null), FieldSchema(name:monthly_brand_price.brand, type:string, comment:null), FieldSchema(name:monthly_brand_price.monthly_price, type:double, comment:null)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717091847_b1e78de7-ee18-4c40-89d4-b989e1d5f04f : STAGE DEPENDENCIES:
  Stage-1 is a root stage [MAPRED]
  Stage-0 depends on stages: Stage-1 [FETCH]

STAGE PLANS:
  Stage: Stage-1
    Tez
      DagId: hive_20220717091847_b1e78de7-ee18-4c40-89d4-b989e1d5f04f:29
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
      DagName: 
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: clickstream_tbl
                  properties:
                    insideView TRUE
                  Statistics: Num rows: 3427938 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Select Operator
                    expressions: month(event_time) (type: int), brand (type: string), price (type: string)
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 3427938 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      aggregations: sum(_col2)
                      keys: _col0 (type: int), _col1 (type: string)
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 3427938 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: string)
                        null sort order: aa
                        sort order: ++
                        Map-reduce partition columns: _col0 (type: int), _col1 (type: string)
                        Statistics: Num rows: 3427938 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                        tag: -1
                        value expressions: _col2 (type: double)
                        auto parallelism: true
            Path -> Alias:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl [clickstream_tbl]
            Path -> Partition:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl 
                Partition
                  base file name: clickstream_tbl
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    column.name.delimiter ,
                    columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                    columns.comments 
                    columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                    escapeChar \
                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    insideView TRUE
                    location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                    name clickstream.clickstream_tbl
                    numFiles 2
                    numRows 0
                    quoteChar "
                    rawDataSize 0
                    separatorChar ,
                    serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                    skip.header.line.count 1
                    totalSize 1028381690
                    transient_lastDdlTime 1658039808
                  serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      column.name.delimiter ,
                      columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                      columns.comments 
                      columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                      escapeChar \
                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      insideView TRUE
                      location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                      name clickstream.clickstream_tbl
                      numFiles 2
                      numRows 0
                      quoteChar "
                      rawDataSize 0
                      separatorChar ,
                      serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                      skip.header.line.count 1
                      totalSize 1028381690
                      transient_lastDdlTime 1658039808
                    serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                    name: clickstream.clickstream_tbl
                  name: clickstream.clickstream_tbl
            Truncated Path -> Alias:
              /clickstream.db/clickstream_tbl [clickstream_tbl]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0)
                keys: KEY._col0 (type: int), KEY._col1 (type: string)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1713969 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col1 (type: string)
                  null sort order: a
                  sort order: +
                  Statistics: Num rows: 1713969 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                  tag: -1
                  TopN: 10
                  TopN Hash Memory Usage: 0.1
                  value expressions: _col0 (type: int), _col2 (type: double)
                  auto parallelism: false
        Reducer 3 
            Needs Tagging: false
            Reduce Operator Tree:
              Select Operator
                expressions: VALUE._col0 (type: int), KEY.reducesinkkey0 (type: string), VALUE._col1 (type: double)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1713969 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                Limit
                  Number of rows: 10
                  Statistics: Num rows: 10 Data size: 3000 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    GlobalTableId: 0
                    directory: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/6d06f1f1-d96b-4e15-a557-93756f1f3ebc/hive_2022-07-17_09-18-47_957_3460306734334734870-16/-mr-10001/.hive-staging_hive_2022-07-17_09-18-47_957_3460306734334734870-16/-ext-10002
                    NumFilesPerFileSink: 1
                    Statistics: Num rows: 10 Data size: 3000 Basic stats: COMPLETE Column stats: NONE
                    Stats Publishing Key Prefix: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/6d06f1f1-d96b-4e15-a557-93756f1f3ebc/hive_2022-07-17_09-18-47_957_3460306734334734870-16/-mr-10001/.hive-staging_hive_2022-07-17_09-18-47_957_3460306734334734870-16/-ext-10002/
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        properties:
                          columns _col0,_col1,_col2
                          columns.types int:string:double
                          escape.delim \
                          hive.serialization.extend.additional.nesting.levels true
                          serialization.escape.crlf true
                          serialization.format 1
                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    TotalFiles: 1
                    GatherStats: false
                    MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: 10
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717091847_b1e78de7-ee18-4c40-89d4-b989e1d5f04f); Time taken: 0.293 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717091847_b1e78de7-ee18-4c40-89d4-b989e1d5f04f): select * from monthly_brand_price order by brand limit 10
INFO  : Query ID = hive_20220717091847_b1e78de7-ee18-4c40-89d4-b989e1d5f04f
INFO  : Total jobs = 1
INFO  : Launching Job 1 out of 1
INFO  : Starting task [Stage-1:MAPRED] in serial mode
INFO  : Session is already open
INFO  : Dag name: select * from monthly_brand_price order...10(Stage-1)
INFO  : Tez session was closed. Reopening...
INFO  : Session re-established.
INFO  : Status: Running (Executing on YARN cluster with App id application_1658032091232_0013)

INFO  : Map 1: -/-Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 0(+1)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 1(+1)/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 2/2Reducer 2: 0/10Reducer 3: 0/1
INFO  : Map 1: 2/2Reducer 2: 0(+1)/1Reducer 3: 0/1
INFO  : Map 1: 2/2Reducer 2: 1/1Reducer 3: 0/1
INFO  : Map 1: 2/2Reducer 2: 1/1Reducer 3: 0(+1)/1
INFO  : Map 1: 2/2Reducer 2: 1/1Reducer 3: 1/1
INFO  : Completed executing command(queryId=hive_20220717091847_b1e78de7-ee18-4c40-89d4-b989e1d5f04f); Time taken: 80.449 seconds
INFO  : OK
+----------------------------+----------------------------+------------------------------------+
| monthly_brand_price.month  | monthly_brand_price.brand  | monthly_brand_price.monthly_price  |
+----------------------------+----------------------------+------------------------------------+
| 10                         |                            | 1.2475523980005352E7               |
| 11                         |                            | 1.371898461995436E7                |
| 10                         | airnails                   | 202151.00999996433                 |
| 11                         | airnails                   | 204049.01999997723                 |
| 11                         | almea                      | 29807.03999999971                  |
| 10                         | almea                      | 32792.11999999966                  |
| 10                         | andrea                     | 997.1999999999977                  |
| 11                         | andrea                     | 534.4900000000007                  |
| 11                         | ardell                     | 26911.29999999953                  |
| 10                         | ardell                     | 30837.820000000258                 |
+----------------------------+----------------------------+------------------------------------+
10 rows selected (80.77 seconds)
0: jdbc:hive2://localhost:10000/default> select brand,sum(case when Month = 11 then price else -price end) as Brand_P rice from clickstream_tbl group by brand;
Error: Error while compiling statement: FAILED: SemanticException [Error 10004]: Line 1:27 Invalid table alias or column reference 'Month': (possible column names are: event_time, event_type, product_id, category_id, category_code, brand, price, user_id, user_session) (state=42000,code=10004)
0: jdbc:hive2://localhost:10000/default> select brand,sum(case when Month = 11 then price else -price end) as Brand_P rice from monthly_brand_price group by brand;
Error: Error while compiling statement: FAILED: SemanticException [Error 10004]: Line 1:43 Invalid table alias or column reference 'price': (possible column names are: month, brand, monthly_price) (state=42000,code=10004)
0: jdbc:hive2://localhost:10000/default> select brand,sum(case when Month = 11 then Monthly_Price else -Monthly_Price  end) as Brand_Price from monthly_brand_price group by brand;
INFO  : Compiling command(queryId=hive_20220717092853_16d8d100-e2ae-4aeb-8aae-03b72cfe48e8): select brand,sum(case when Month = 11 then Monthly_Price else -Monthly_Price end) as Brand_Price from monthly_brand_price group by brand
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:brand, type:string, comment:null), FieldSchema(name:brand_price, type:double, comment:null)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717092853_16d8d100-e2ae-4aeb-8aae-03b72cfe48e8 : STAGE DEPENDENCIES:
  Stage-1 is a root stage [MAPRED]
  Stage-0 depends on stages: Stage-1 [FETCH]

STAGE PLANS:
  Stage: Stage-1
    Tez
      DagId: hive_20220717092853_16d8d100-e2ae-4aeb-8aae-03b72cfe48e8:30
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
        Reducer 4 <- Reducer 3 (SIMPLE_EDGE)
      DagName: 
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: clickstream_tbl
                  properties:
                    insideView TRUE
                  Statistics: Num rows: 3427938 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Select Operator
                    expressions: month(event_time) (type: int), brand (type: string), price (type: string)
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 3427938 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      aggregations: sum(_col2)
                      keys: _col0 (type: int), _col1 (type: string)
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 3427938 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: string)
                        null sort order: aa
                        sort order: ++
                        Map-reduce partition columns: _col0 (type: int), _col1 (type: string)
                        Statistics: Num rows: 3427938 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                        tag: -1
                        value expressions: _col2 (type: double)
                        auto parallelism: true
            Path -> Alias:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl [clickstream_tbl]
            Path -> Partition:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl 
                Partition
                  base file name: clickstream_tbl
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    column.name.delimiter ,
                    columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                    columns.comments 
                    columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                    escapeChar \
                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    insideView TRUE
                    location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                    name clickstream.clickstream_tbl
                    numFiles 2
                    numRows 0
                    quoteChar "
                    rawDataSize 0
                    separatorChar ,
                    serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                    skip.header.line.count 1
                    totalSize 1028381690
                    transient_lastDdlTime 1658039808
                  serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      column.name.delimiter ,
                      columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                      columns.comments 
                      columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                      escapeChar \
                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      insideView TRUE
                      location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                      name clickstream.clickstream_tbl
                      numFiles 2
                      numRows 0
                      quoteChar "
                      rawDataSize 0
                      separatorChar ,
                      serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                      skip.header.line.count 1
                      totalSize 1028381690
                      transient_lastDdlTime 1658039808
                    serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                    name: clickstream.clickstream_tbl
                  name: clickstream.clickstream_tbl
            Truncated Path -> Alias:
              /clickstream.db/clickstream_tbl [clickstream_tbl]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0)
                keys: KEY._col0 (type: int), KEY._col1 (type: string)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1713969 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: int), _col1 (type: string)
                  null sort order: aa
                  sort order: ++
                  Statistics: Num rows: 1713969 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                  tag: -1
                  value expressions: _col2 (type: double)
                  auto parallelism: false
        Reducer 3 
            Needs Tagging: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey1 (type: string), CASE WHEN ((KEY.reducesinkkey0 = 11)) THEN (VALUE._col0) ELSE ((- VALUE._col0)) END (type: double)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1713969 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                Group By Operator
                  aggregations: sum(_col1)
                  keys: _col0 (type: string)
                  mode: hash
                  outputColumnNames: _col0, _col1
                  Statistics: Num rows: 1713969 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: _col0 (type: string)
                    null sort order: a
                    sort order: +
                    Map-reduce partition columns: _col0 (type: string)
                    Statistics: Num rows: 1713969 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                    tag: -1
                    value expressions: _col1 (type: double)
                    auto parallelism: true
        Reducer 4 
            Needs Tagging: false
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0)
                keys: KEY._col0 (type: string)
                mode: mergepartial
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 856984 Data size: 257095273 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
                  directory: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/6d06f1f1-d96b-4e15-a557-93756f1f3ebc/hive_2022-07-17_09-28-53_222_4687061373815225022-16/-mr-10001/.hive-staging_hive_2022-07-17_09-28-53_222_4687061373815225022-16/-ext-10002
                  NumFilesPerFileSink: 1
                  Statistics: Num rows: 856984 Data size: 257095273 Basic stats: COMPLETE Column stats: NONE
                  Stats Publishing Key Prefix: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/6d06f1f1-d96b-4e15-a557-93756f1f3ebc/hive_2022-07-17_09-28-53_222_4687061373815225022-16/-mr-10001/.hive-staging_hive_2022-07-17_09-28-53_222_4687061373815225022-16/-ext-10002/
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      properties:
                        columns _col0,_col1
                        columns.types string:double
                        escape.delim \
                        hive.serialization.extend.additional.nesting.levels true
                        serialization.escape.crlf true
                        serialization.format 1
                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  TotalFiles: 1
                  GatherStats: false
                  MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717092853_16d8d100-e2ae-4aeb-8aae-03b72cfe48e8); Time taken: 0.167 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717092853_16d8d100-e2ae-4aeb-8aae-03b72cfe48e8): select brand,sum(case when Month = 11 then Monthly_Price else -Monthly_Price end) as Brand_Price from monthly_brand_price group by brand
INFO  : Query ID = hive_20220717092853_16d8d100-e2ae-4aeb-8aae-03b72cfe48e8
INFO  : Total jobs = 1
INFO  : Launching Job 1 out of 1
INFO  : Starting task [Stage-1:MAPRED] in serial mode
INFO  : Session is already open
INFO  : Dag name: select brand,sum(case when Month = 1...brand(Stage-1)
INFO  : Tez session was closed. Reopening...
INFO  : Session re-established.
INFO  : Status: Running (Executing on YARN cluster with App id application_1658032091232_0014)

INFO  : Map 1: 0/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+1)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 1(+1)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 1(+1)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 2/2Reducer 2: 0(+1)/1Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 2/2Reducer 2: 1/1Reducer 3: 0(+1)/1Reducer 4: 0/6
INFO  : Map 1: 2/2Reducer 2: 1/1Reducer 3: 1/1Reducer 4: 0(+2)/6
INFO  : Map 1: 2/2Reducer 2: 1/1Reducer 3: 1/1Reducer 4: 2(+2)/6
INFO  : Map 1: 2/2Reducer 2: 1/1Reducer 3: 1/1Reducer 4: 4(+1)/6
INFO  : Map 1: 2/2Reducer 2: 1/1Reducer 3: 1/1Reducer 4: 4(+2)/6
INFO  : Map 1: 2/2Reducer 2: 1/1Reducer 3: 1/1Reducer 4: 6/6
INFO  : Completed executing command(queryId=hive_20220717092853_16d8d100-e2ae-4aeb-8aae-03b72cfe48e8); Time taken: 81.682 seconds
INFO  : OK
+----------------+----------------------+
|     brand      |     brand_price      |
+----------------+----------------------+
| almea          | -2985.079999999951   |
| artex          | 16309.34000000207    |
| bioaqua        | -3786.9199999996345  |
| blixz          | -289.52999999998553  |
| carmex         | 896.2199999999734    |
| concept        | 8911.900000009628    |
| consly         | 203.53999999998132   |
| deoproce       | -4247.089999999953   |
| egomania       | -2809.270000000013   |
| ellips         | 1024.1400000000285   |
| embryolisse    | -207.4500000000001   |
| emil           | 20090.870000001305   |
| freshbubble    | -1652.0200000000577  |
| gena           | -17.78               |
| haruyama       | 22547.789999984263   |
| helloganic     | -471.84000000000157  |
| ibd            | 7.76                 |
| insight        | -5825.180000000226   |
| jaguar         | 559.8299999987212    |
| joico          | -7329.450000000499   |
| juno           | -72.70000000000016   |
| konad          | -3951.1000000005733  |
| lakme          | -3158.6499999999032  |
| lamixx         | -4884.399999999703   |
| limoni         | 4764.480000000083    |
| macadamia      | -400.81              |
| mane           | 504.2200000000139    |
| markell        | 4835.99000000034     |
| masura         | -31588.09999942372   |
| meisterwerk    | -351.8999999999778   |
| miskin         | -644.0399999999427   |
| nitrile        | 1821.8699999998662   |
| osmo           | -14958.589999999589  |
| plazan         | 445.5799999999931    |
| protokeratin   | -7996.41000000006    |
| rocknailstar   | -17.709999999999965  |
| runail         | 23185.250002758345   |
| shik           | 67108.7199999913     |
| sophin         | 5126.779999998937    |
| strong         | 163467.68000014964   |
| thuya          | -105957.2299999921   |
| tosowoong      | -106.30000000000246  |
| uskusi         | -962.1500000050291   |
| yoko           | 25271.18000000692    |
| zab            | -618.1799999999996   |
| andrea         | -462.70999999999697  |
| aura           | 313.6999999999978    |
| balbcare       | 1736.4100000000776   |
| beauugreen     | 2667.4999999999345   |
| bergamo        | -2734.1200000000335  |
| biofollica     | 1891.1100000000215   |
| bodyton        | -2456.4599999995335  |
| cnd            | 70391.4699999661     |
| coxir          | -3772.339999999991   |
| de.lux         | 5762.349999995451    |
| farmona        | -3578.6400000003778  |
| freedecor      | 46616.33999996718    |
| grace          | -1109.6400000000006  |
| igrobeauty     | 274.81999999995605   |
| ingarden       | 65672.43999985087    |
| inoface        | -351.28999999995585  |
| jessnail       | 217235.78999954648   |
| kims           | -10724.029999999952  |
| kiss           | 426.72000000040134   |
| koreatida      | 1727.9400000000019   |
| labay          | -2552.289999999994   |
| lador          | 1873.9800000001997   |
| ladykin        | -766.0899999999974   |
| latinoil       | -3117.8399999999765  |
| lebelage       | -3086.210000000023   |
| litaline       | -10392.589999999956  |
| lsanic         | -1808.7800000002135  |
| matrix         | -264.28999999922235  |
| metzger        | 7437.950000007215    |
| oniq           | -1761.1700000333076  |
| parachute      | -1466.1499999998632  |
| pnb            | -9679.510000016628   |
| riche          | -8081.829999999978   |
| rosi           | -258.63999999756925  |
| roubloff       | 6586.1799999949      |
| sawa           | -495.9000000000133   |
| severina       | 6440.589999998614    |
| staleks        | 33791.60999998104    |
| sun            | -520.7299999999905   |
| sunuv          | -49640.670000018785  |
| supertan       | -48.490000000003874  |
| tannymaxx      | -1068.1299999999828  |
| vilenta        | 137.04000000001952   |
| vl-gel         | -7.5600000000000005  |
| ardell         | -3926.520000000728   |
| art-visage     | 6124.179999996042    |
| australis      | 557.9799999999999    |
| barbie         | 68.18999999999993    |
| beautyblender  | -1149.5000000000036  |
| coocla         | -2874.6700000000783  |
| cutrin         | -874.8400000000802   |
| domix          | -3640.820000002859   |
| dr.gloderm     | -9586.950000000012   |
| ecocraft       | 7659.639999999954    |
| elskin         | 319.6800000000271    |
+----------------+----------------------+
|     brand      |     brand_price      |
+----------------+----------------------+
| entity         | 1630.589999998716    |
| eos            | 762.2699999999943    |
| fancy          | -1036.710000000019   |
| farmavita      | -7990.919999998812   |
| fedua          | 1573.2399999999952   |
| frozen         | 91.14000000000033    |
| glysolid       | 498.3599999999924    |
| ikoo           | 113.33               |
| inm            | 32.42999999996209    |
| kamill         | 81.74000000000058    |
| kares          | -3176.170000000002   |
| kaypro         | -31802.169999998703  |
| keen           | -6855.999999999656   |
| lianail        | 144334.34999995455   |
| mavala         | -9855.540000000286   |
| missha         | 24733.69999999882    |
| moyou          | -230.75999999999794  |
| nagaraku       | 7820.140000001724    |
| nitrimax       | -9212.170000000253   |
| philips        | 38.72999999999985    |
| pole           | -146386.95999976053  |
| siberina       | -15799.869999999879  |
| smart          | 1980.0499999975727   |
| trind          | -14593.780000000352  |
| uno            | 113158.08999999863   |
| uralsoap       | -10.500000000000007  |
| voesh          | -8.940000000000001   |
| vosev          | 11891.32000000067    |
| zinger         | -44067.370000000956  |
| airnails       | 1898.0100000129023   |
| bespecial      | -13.009999999968386  |
| binacil        | -0.4600000000000364  |
| bluesky        | -20938.6399999634    |
| bodipure       | -2.7500000000000018  |
| bpw.style      | 11059.280000112252   |
| chi            | -3157.040000000099   |
| cosima         | -61.02999999999997   |
| cosmoprofi     | 42547.34000005247    |
| cuccio         | -8.730000000000004   |
| depilflax      | -6296.329999998205   |
| dermacol       | -118.29999999999994  |
| dewal          | 2028.9099999999976   |
| dizao          | 1471.8400000007641   |
| elizavecca     | -1134.7199999999211  |
| essie          | -130.84000000000003  |
| finish         | 1082.4899999999966   |
| footlogix      | -19.050000000000004  |
| grattol        | 353045.5699990003    |
| italwax        | 10355.33999998431    |
| jas            | 80599.36999999758    |
| kapous         | 4732.6300000145275   |
| kerasys        | -1363.9599999999518  |
| kocostar       | -1366.4299999999475  |
| koelf          | 1590.220000000094    |
| kosmekka       | 970.7599999589147    |
| laiseven       | 58.239999999999995   |
| levrana        | 400.8900000022695    |
| marutaka-foot  | -188.89000000000442  |
| naturmed       | -500.10999999999535  |
| neoleor        | -1355.8299999999995  |
| opi            | 397.9199999999728    |
| polarus        | 121377.82000001462   |
| radius         | -369.53999999999905  |
| s.care         | 27526.710000000792   |
| sanoto         | 19173.29000000011    |
| shary          | 1212.9899999998797   |
| shifei         | 14.049999999999997   |
| tazol          | 5.389999999999986    |
| tertio         | 1279.86999999999     |
| treaclemoon    | -1744.5999999999844  |
| veraclara      | -249.08999999999787  |
| ypsed          | -1239.340000000011   |
| zeitun         | 4582.520000000168    |
| batiste        | 1595.1000000000477   |
| beautix        | 9187.080000057002    |
| biore          | -1065.3399999999992  |
| blise          | -119.69000000000017  |
| browxenna      | 9124.02000000485     |
| busch          | 82.52000000000007    |
| dessata        | -19.52               |
| ecolab         | 14169.750000000557   |
| enas           | 58.110000000006266   |
| enigma         | -3095.5199999999204  |
| esquire        | -309.6199999999999   |
| f.o.x          | 7644.809999996825    |
| fly            | 172.6700000000011    |
| gehwol         | 3489.1000000000495   |
| greymy         | 934.1199999999963    |
| happyfons      | 1046.6299999995026   |
| i-laq          | -11101.109999999957  |
| kaaral         | -4929.5000000019645  |
| keune          | -5161.039999999892   |
| laboratorium   | -213.71000000005006  |
| levissime      | 5358.219999998259    |
| likato         | -7725.779999999921   |
| lovely         | 26082.139999998704   |
| lunaris        | -562.93              |
| marathon       | 124160.59999998717   |
| max            | 49760.50000000722    |
| mielle         | -1687.7600000000107  |
+----------------+----------------------+
|     brand      |     brand_price      |
+----------------+----------------------+
| milv           | 10711.569999991523   |
| naomi          | 21459.030000000133   |
| nefertiti      | -116.12000000015087  |
| nirvel         | -343.23000000000593  |
| nova           | -71.96000000000001   |
| orly           | -4440.410000000411   |
| ovale          | -203.7999999999998   |
| profhenna      | -1912.680000000144   |
| provoc         | -1001.7199999996556  |
| pueen          | -6.98                |
| skinlite       | 67.84000000000742    |
| skipofit       | -494.1899999999989   |
| soleo          | -391.5799999999995   |
|                | 1243460.6399490088   |
| beauty-free    | 12569.42999999963    |
| benovy         | 23382.809999999998   |
| bosnic         | -688.7900000000009   |
| candy          | 4725.729999999752    |
| coifin         | 21890.03999999965    |
| cristalinas    | 1498.8999999999924   |
| cruset         | -3666.520000000034   |
| dermal         | -1241.7400000000612  |
| dorena         | -9392.320000000094   |
| enjoy          | -819.2200000000073   |
| estel          | -27760.74000005721   |
| estelare       | -644.8700000001454   |
| eunyul         | -2511.7200000001226  |
| farmstay       | -23414.330000000737  |
| foamie         | -43.63000000000193   |
| godefroy       | -37.26999999998043   |
| invisibobble   | 9.200000000000003    |
| irisk          | -26942.039998786524  |
| kinetics       | -5486.110000002474   |
| koelcia        | -498.87000000000353  |
| lowence        | 2022.1000000000658   |
| matreshka      | 10283.630000000114   |
| petitfee       | -962.1099999999751   |
| profepil       | -1633.1299999999835  |
| rasyan         | -883.9600000000207   |
| refectocil     | 3748.2300000005343   |
| skinity        | -53.19999999999993   |
| solomeya       | -8031.36999999758    |
| swarovski      | 7882.670000001206    |
| weaver         | -99.7199999999998    |
| yu-r           | 6686.3999999999305   |
+----------------+----------------------+
245 rows selected (81.964 seconds)
0: jdbc:hive2://localhost:10000/default> select brand,Increased_Sales from (select brand,sum(case when Month = 11 the n Monthly_Price else -Monthly_Price end) as Increased_Sales from monthly_brand_price group by brand) where Brand_Pric e>0;
Error: Error while compiling statement: FAILED: ParseException line 1:177 cannot recognize input near 'where' 'Brand_Price' '>' in subquery source (state=42000,code=40000)
0: jdbc:hive2://localhost:10000/default> select brand,Increased_Sales from (select brand,sum(case when Month = 11 the n Monthly_Price else -Monthly_Price end) as Increased_Sales from monthly_brand_price group by brand) where Increased_ Sales>0;
Error: Error while compiling statement: FAILED: ParseException line 1:177 cannot recognize input near 'where' 'Increased_Sales' '>' in subquery source (state=42000,code=40000)
0: jdbc:hive2://localhost:10000/default> select brand,Increased_Sales from (select brand,sum(case when Month = 11 the n Monthly_Price else -Monthly_Price end) as Increased_Sales from monthly_brand_price group by brand) having Increased _Sales>0;
Error: Error while compiling statement: FAILED: ParseException line 1:177 cannot recognize input near 'having' 'Increased_Sales' '>' in subquery source (state=42000,code=40000)
0: jdbc:hive2://localhost:10000/default> select brand,Increased_Sales from (select brand,sum(case when Month = 11 the n Monthly_Price else -Monthly_Price end) as Increased_Sales from monthly_brand_price group by brand hacing Increased_ Sales>0)s;
Error: Error while compiling statement: FAILED: ParseException line 1:176 missing ) at 'hacing' near 'hacing'
line 1:183 missing EOF at 'Increased_Sales' near 'hacing' (state=42000,code=40000)
0: jdbc:hive2://localhost:10000/default> select brand,Increased_Sales from (select brand,sum(case when Month = 11 the n Monthly_Price else -Monthly_Price end) as Increased_Sales from monthly_brand_price group by brand having Increased_ Sales>0)s;
INFO  : Compiling command(queryId=hive_20220717093534_687c7a77-8c5e-402a-ae2d-8a86e8e21605): select brand,Increased_Sales from (select brand,sum(case when Month = 11 then Monthly_Price else -Monthly_Price end) as Increased_Sales from monthly_brand_price group by brand having Increased_Sales>0)s
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:brand, type:string, comment:null), FieldSchema(name:increased_sales, type:double, comment:null)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717093534_687c7a77-8c5e-402a-ae2d-8a86e8e21605 : STAGE DEPENDENCIES:
  Stage-1 is a root stage [MAPRED]
  Stage-0 depends on stages: Stage-1 [FETCH]

STAGE PLANS:
  Stage: Stage-1
    Tez
      DagId: hive_20220717093534_687c7a77-8c5e-402a-ae2d-8a86e8e21605:31
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
        Reducer 4 <- Reducer 3 (SIMPLE_EDGE)
      DagName: 
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: clickstream_tbl
                  Statistics: Num rows: 3427938 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Select Operator
                    expressions: event_time (type: string), brand (type: string), price (type: string)
                    outputColumnNames: event_time, brand, price
                    Statistics: Num rows: 3427938 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      aggregations: sum(price)
                      keys: month(event_time) (type: int), brand (type: string)
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 3427938 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: string)
                        null sort order: aa
                        sort order: ++
                        Map-reduce partition columns: _col0 (type: int), _col1 (type: string)
                        Statistics: Num rows: 3427938 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                        tag: -1
                        value expressions: _col2 (type: double)
                        auto parallelism: true
            Path -> Alias:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl [clickstream_tbl]
            Path -> Partition:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl 
                Partition
                  base file name: clickstream_tbl
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    column.name.delimiter ,
                    columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                    columns.comments 
                    columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                    escapeChar \
                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                    name clickstream.clickstream_tbl
                    numFiles 2
                    numRows 0
                    quoteChar "
                    rawDataSize 0
                    separatorChar ,
                    serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                    skip.header.line.count 1
                    totalSize 1028381690
                    transient_lastDdlTime 1658039808
                  serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      column.name.delimiter ,
                      columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                      columns.comments 
                      columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                      escapeChar \
                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                      name clickstream.clickstream_tbl
                      numFiles 2
                      numRows 0
                      quoteChar "
                      rawDataSize 0
                      separatorChar ,
                      serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                      skip.header.line.count 1
                      totalSize 1028381690
                      transient_lastDdlTime 1658039808
                    serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                    name: clickstream.clickstream_tbl
                  name: clickstream.clickstream_tbl
            Truncated Path -> Alias:
              /clickstream.db/clickstream_tbl [clickstream_tbl]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0)
                keys: KEY._col0 (type: int), KEY._col1 (type: string)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1713969 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: int), _col1 (type: string)
                  null sort order: aa
                  sort order: ++
                  Statistics: Num rows: 1713969 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                  tag: -1
                  value expressions: _col2 (type: double)
                  auto parallelism: false
        Reducer 3 
            Needs Tagging: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string), VALUE._col0 (type: double)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1713969 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                Group By Operator
                  aggregations: sum(CASE WHEN ((_col0 = 11)) THEN (_col2) ELSE ((- _col2)) END)
                  keys: _col1 (type: string)
                  mode: hash
                  outputColumnNames: _col0, _col1
                  Statistics: Num rows: 1713969 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: _col0 (type: string)
                    null sort order: a
                    sort order: +
                    Map-reduce partition columns: _col0 (type: string)
                    Statistics: Num rows: 1713969 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                    tag: -1
                    value expressions: _col1 (type: double)
                    auto parallelism: true
        Reducer 4 
            Needs Tagging: false
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0)
                keys: KEY._col0 (type: string)
                mode: mergepartial
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 856984 Data size: 257095273 Basic stats: COMPLETE Column stats: NONE
                Filter Operator
                  isSamplingPred: false
                  predicate: (_col1 > 0.0) (type: boolean)
                  Statistics: Num rows: 285661 Data size: 85698324 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    GlobalTableId: 0
                    directory: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/6d06f1f1-d96b-4e15-a557-93756f1f3ebc/hive_2022-07-17_09-35-34_426_9165584370013461265-16/-mr-10001/.hive-staging_hive_2022-07-17_09-35-34_426_9165584370013461265-16/-ext-10002
                    NumFilesPerFileSink: 1
                    Statistics: Num rows: 285661 Data size: 85698324 Basic stats: COMPLETE Column stats: NONE
                    Stats Publishing Key Prefix: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/6d06f1f1-d96b-4e15-a557-93756f1f3ebc/hive_2022-07-17_09-35-34_426_9165584370013461265-16/-mr-10001/.hive-staging_hive_2022-07-17_09-35-34_426_9165584370013461265-16/-ext-10002/
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        properties:
                          columns _col0,_col1
                          columns.types string:double
                          escape.delim \
                          hive.serialization.extend.additional.nesting.levels true
                          serialization.escape.crlf true
                          serialization.format 1
                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    TotalFiles: 1
                    GatherStats: false
                    MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717093534_687c7a77-8c5e-402a-ae2d-8a86e8e21605); Time taken: 0.194 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717093534_687c7a77-8c5e-402a-ae2d-8a86e8e21605): select brand,Increased_Sales from (select brand,sum(case when Month = 11 then Monthly_Price else -Monthly_Price end) as Increased_Sales from monthly_brand_price group by brand having Increased_Sales>0)s
INFO  : Query ID = hive_20220717093534_687c7a77-8c5e-402a-ae2d-8a86e8e21605
INFO  : Total jobs = 1
INFO  : Launching Job 1 out of 1
INFO  : Starting task [Stage-1:MAPRED] in serial mode
INFO  : Session is already open
INFO  : Dag name: select brand,Increased...Increased_Sales>0)s(Stage-1)
INFO  : Tez session was closed. Reopening...
INFO  : Session re-established.
INFO  : Status: Running (Executing on YARN cluster with App id application_1658032091232_0015)

INFO  : Map 1: -/-Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+1)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 1(+1)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 2/2Reducer 2: 0(+1)/1Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 2/2Reducer 2: 1/1Reducer 3: 0(+1)/1Reducer 4: 0/6
INFO  : Map 1: 2/2Reducer 2: 1/1Reducer 3: 1/1Reducer 4: 0(+2)/6
INFO  : Map 1: 2/2Reducer 2: 1/1Reducer 3: 1/1Reducer 4: 1(+1)/6
INFO  : Map 1: 2/2Reducer 2: 1/1Reducer 3: 1/1Reducer 4: 2(+2)/6
INFO  : Map 1: 2/2Reducer 2: 1/1Reducer 3: 1/1Reducer 4: 3(+2)/6
INFO  : Map 1: 2/2Reducer 2: 1/1Reducer 3: 1/1Reducer 4: 5(+1)/6
INFO  : Map 1: 2/2Reducer 2: 1/1Reducer 3: 1/1Reducer 4: 6/6
INFO  : Completed executing command(queryId=hive_20220717093534_687c7a77-8c5e-402a-ae2d-8a86e8e21605); Time taken: 82.578 seconds
INFO  : OK
+---------------+---------------------+
|     brand     |   increased_sales   |
+---------------+---------------------+
| artex         | 16309.34000000207   |
| carmex        | 896.2199999999734   |
| concept       | 8911.900000009628   |
| consly        | 203.53999999998132  |
| ellips        | 1024.1400000000285  |
| emil          | 20090.870000001305  |
| haruyama      | 22547.789999984263  |
| ibd           | 7.76                |
| jaguar        | 559.8299999987212   |
| limoni        | 4764.480000000083   |
| mane          | 504.2200000000139   |
| markell       | 4835.99000000034    |
| nitrile       | 1821.8699999998662  |
| plazan        | 445.5799999999931   |
| runail        | 23185.250002758345  |
| shik          | 67108.7199999913    |
| sophin        | 5126.779999998937   |
| strong        | 163467.68000014964  |
| yoko          | 25271.18000000692   |
| aura          | 313.6999999999978   |
| balbcare      | 1736.4100000000776  |
| beauugreen    | 2667.4999999999345  |
| biofollica    | 1891.1100000000215  |
| cnd           | 70391.4699999661    |
| de.lux        | 5762.349999995451   |
| freedecor     | 46616.33999996718   |
| igrobeauty    | 274.81999999995605  |
| ingarden      | 65672.43999985087   |
| jessnail      | 217235.78999954648  |
| kiss          | 426.72000000040134  |
| koreatida     | 1727.9400000000019  |
| lador         | 1873.9800000001997  |
| metzger       | 7437.950000007215   |
| roubloff      | 6586.1799999949     |
| severina      | 6440.589999998614   |
| staleks       | 33791.60999998104   |
| vilenta       | 137.04000000001952  |
| art-visage    | 6124.179999996042   |
| australis     | 557.9799999999999   |
| barbie        | 68.18999999999993   |
| ecocraft      | 7659.639999999954   |
| elskin        | 319.6800000000271   |
| entity        | 1630.589999998716   |
| eos           | 762.2699999999943   |
| fedua         | 1573.2399999999952  |
| frozen        | 91.14000000000033   |
| glysolid      | 498.3599999999924   |
| ikoo          | 113.33              |
| inm           | 32.42999999996209   |
| kamill        | 81.74000000000058   |
| lianail       | 144334.34999995455  |
| missha        | 24733.69999999882   |
| nagaraku      | 7820.140000001724   |
| philips       | 38.72999999999985   |
| smart         | 1980.0499999975727  |
| uno           | 113158.08999999863  |
| vosev         | 11891.32000000067   |
| airnails      | 1898.0100000129023  |
| bpw.style     | 11059.280000112252  |
| cosmoprofi    | 42547.34000005247   |
| dewal         | 2028.9099999999976  |
| dizao         | 1471.8400000007641  |
| finish        | 1082.4899999999966  |
| grattol       | 353045.5699990003   |
| italwax       | 10355.33999998431   |
| jas           | 80599.36999999758   |
| kapous        | 4732.6300000145275  |
| koelf         | 1590.220000000094   |
| kosmekka      | 970.7599999589147   |
| laiseven      | 58.239999999999995  |
| levrana       | 400.8900000022695   |
| opi           | 397.9199999999728   |
| polarus       | 121377.82000001462  |
| s.care        | 27526.710000000792  |
| sanoto        | 19173.29000000011   |
| shary         | 1212.9899999998797  |
| shifei        | 14.049999999999997  |
| tazol         | 5.389999999999986   |
| tertio        | 1279.86999999999    |
| zeitun        | 4582.520000000168   |
| batiste       | 1595.1000000000477  |
| beautix       | 9187.080000057002   |
| browxenna     | 9124.02000000485    |
| busch         | 82.52000000000007   |
| ecolab        | 14169.750000000557  |
| enas          | 58.110000000006266  |
| f.o.x         | 7644.809999996825   |
| fly           | 172.6700000000011   |
| gehwol        | 3489.1000000000495  |
| greymy        | 934.1199999999963   |
| happyfons     | 1046.6299999995026  |
| levissime     | 5358.219999998259   |
| lovely        | 26082.139999998704  |
| marathon      | 124160.59999998717  |
| max           | 49760.50000000722   |
| milv          | 10711.569999991523  |
| naomi         | 21459.030000000133  |
| skinlite      | 67.84000000000742   |
|               | 1243460.6399490088  |
| beauty-free   | 12569.42999999963   |
+---------------+---------------------+
|     brand     |   increased_sales   |
+---------------+---------------------+
| benovy        | 23382.809999999998  |
| candy         | 4725.729999999752   |
| coifin        | 21890.03999999965   |
| cristalinas   | 1498.8999999999924  |
| invisibobble  | 9.200000000000003   |
| lowence       | 2022.1000000000658  |
| matreshka     | 10283.630000000114  |
| refectocil    | 3748.2300000005343  |
| swarovski     | 7882.670000001206   |
| yu-r          | 6686.3999999999305  |
+---------------+---------------------+
110 rows selected (82.839 seconds)
0: jdbc:hive2://localhost:10000/default> select brand,Increased_Sales from (select brand,sum(case when Month = 11 the n Monthly_Price else -Monthly_Price end) as Increased_Sales from monthly_brand_price group by brand having Increased_ Sales>0);
Error: Error while compiling statement: FAILED: ParseException line 1:201 cannot recognize input near '<EOF>' '<EOF>' '<EOF>' in subquery source (state=42000,code=40000)
0: jdbc:hive2://localhost:10000/default> select brand,Increased_Sales from (select brand,sum(case when Month = 11 then Monthly_Price else -Monthly_Price end) as Increased_Sales from monthly_brand_price group by brand having Increased_Sales>0);s;
INFO  : Compiling command(queryId=hive_20220717094409_7e8a1548-4f9e-480a-8cb6-58eceba6982c): select brand,Increased_Sales from (select brand,sum(case when Month = 11 then Monthly_Price else -Monthly_Price end) as Increased_Sales from monthly_brand_price group by brand having Increased_Sales>0)s
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:brand, type:string, comment:null), FieldSchema(name:increased_sales, type:double, comment:null)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717094409_7e8a1548-4f9e-480a-8cb6-58eceba6982c : STAGE DEPENDENCIES:
  Stage-1 is a root stage [MAPRED]
  Stage-0 depends on stages: Stage-1 [FETCH]

STAGE PLANS:
  Stage: Stage-1
    Tez
      DagId: hive_20220717094409_7e8a1548-4f9e-480a-8cb6-58eceba6982c:32
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
        Reducer 4 <- Reducer 3 (SIMPLE_EDGE)
      DagName: 
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: clickstream_tbl
                  Statistics: Num rows: 3427938 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Select Operator
                    expressions: event_time (type: string), brand (type: string), price (type: string)
                    outputColumnNames: event_time, brand, price
                    Statistics: Num rows: 3427938 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      aggregations: sum(price)
                      keys: month(event_time) (type: int), brand (type: string)
                      mode: hash
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 3427938 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int), _col1 (type: string)
                        null sort order: aa
                        sort order: ++
                        Map-reduce partition columns: _col0 (type: int), _col1 (type: string)
                        Statistics: Num rows: 3427938 Data size: 1028381696 Basic stats: COMPLETE Column stats: NONE
                        tag: -1
                        value expressions: _col2 (type: double)
                        auto parallelism: true
            Path -> Alias:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl [clickstream_tbl]
            Path -> Partition:
              hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl 
                Partition
                  base file name: clickstream_tbl
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    column.name.delimiter ,
                    columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                    columns.comments 
                    columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                    escapeChar \
                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                    name clickstream.clickstream_tbl
                    numFiles 2
                    numRows 0
                    quoteChar "
                    rawDataSize 0
                    separatorChar ,
                    serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                    skip.header.line.count 1
                    totalSize 1028381690
                    transient_lastDdlTime 1658039808
                  serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      bucket_count -1
                      column.name.delimiter ,
                      columns event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
                      columns.comments 
                      columns.types timestamp:string:string:string:string:string:decimal(10,3):bigint:string
                      escapeChar \
                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      location hdfs://ip-172-31-42-254.ec2.internal:8020/user/hive/warehouse/clickstream.db/clickstream_tbl
                      name clickstream.clickstream_tbl
                      numFiles 2
                      numRows 0
                      quoteChar "
                      rawDataSize 0
                      separatorChar ,
                      serialization.ddl struct clickstream_tbl { timestamp event_time, string event_type, string product_id, string category_id, string category_code, string brand, decimal(10,3) price, i64 user_id, string user_session}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.OpenCSVSerde
                      skip.header.line.count 1
                      totalSize 1028381690
                      transient_lastDdlTime 1658039808
                    serde: org.apache.hadoop.hive.serde2.OpenCSVSerde
                    name: clickstream.clickstream_tbl
                  name: clickstream.clickstream_tbl
            Truncated Path -> Alias:
              /clickstream.db/clickstream_tbl [clickstream_tbl]
        Reducer 2 
            Needs Tagging: false
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0)
                keys: KEY._col0 (type: int), KEY._col1 (type: string)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1713969 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: int), _col1 (type: string)
                  null sort order: aa
                  sort order: ++
                  Statistics: Num rows: 1713969 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                  tag: -1
                  value expressions: _col2 (type: double)
                  auto parallelism: false
        Reducer 3 
            Needs Tagging: false
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string), VALUE._col0 (type: double)
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1713969 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                Group By Operator
                  aggregations: sum(CASE WHEN ((_col0 = 11)) THEN (_col2) ELSE ((- _col2)) END)
                  keys: _col1 (type: string)
                  mode: hash
                  outputColumnNames: _col0, _col1
                  Statistics: Num rows: 1713969 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: _col0 (type: string)
                    null sort order: a
                    sort order: +
                    Map-reduce partition columns: _col0 (type: string)
                    Statistics: Num rows: 1713969 Data size: 514190848 Basic stats: COMPLETE Column stats: NONE
                    tag: -1
                    value expressions: _col1 (type: double)
                    auto parallelism: true
        Reducer 4 
            Needs Tagging: false
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0)
                keys: KEY._col0 (type: string)
                mode: mergepartial
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 856984 Data size: 257095273 Basic stats: COMPLETE Column stats: NONE
                Filter Operator
                  isSamplingPred: false
                  predicate: (_col1 > 0.0) (type: boolean)
                  Statistics: Num rows: 285661 Data size: 85698324 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    GlobalTableId: 0
                    directory: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/6d06f1f1-d96b-4e15-a557-93756f1f3ebc/hive_2022-07-17_09-44-09_132_2313325014176445934-16/-mr-10001/.hive-staging_hive_2022-07-17_09-44-09_132_2313325014176445934-16/-ext-10002
                    NumFilesPerFileSink: 1
                    Statistics: Num rows: 285661 Data size: 85698324 Basic stats: COMPLETE Column stats: NONE
                    Stats Publishing Key Prefix: hdfs://ip-172-31-42-254.ec2.internal:8020/tmp/hive/hadoop/6d06f1f1-d96b-4e15-a557-93756f1f3ebc/hive_2022-07-17_09-44-09_132_2313325014176445934-16/-mr-10001/.hive-staging_hive_2022-07-17_09-44-09_132_2313325014176445934-16/-ext-10002/
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        properties:
                          columns _col0,_col1
                          columns.types string:double
                          escape.delim \
                          hive.serialization.extend.additional.nesting.levels true
                          serialization.escape.crlf true
                          serialization.format 1
                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    TotalFiles: 1
                    GatherStats: false
                    MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717094409_7e8a1548-4f9e-480a-8cb6-58eceba6982c); Time taken: 0.144 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717094409_7e8a1548-4f9e-480a-8cb6-58eceba6982c): select brand,Increased_Sales from (select brand,sum(case when Month = 11 then Monthly_Price else -Monthly_Price end) as Increased_Sales from monthly_brand_price group by brand having Increased_Sales>0)s
INFO  : Query ID = hive_20220717094409_7e8a1548-4f9e-480a-8cb6-58eceba6982c
INFO  : Total jobs = 1
INFO  : Launching Job 1 out of 1
INFO  : Starting task [Stage-1:MAPRED] in serial mode
INFO  : Session is already open
INFO  : Dag name: select brand,Increased...Increased_Sales>0)s(Stage-1)
INFO  : Tez session was closed. Reopening...
INFO  : Session re-established.
INFO  : Status: Running (Executing on YARN cluster with App id application_1658032091232_0016)

INFO  : Map 1: -/-Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+1)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 0(+2)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 1(+1)/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 2/2Reducer 2: 0/10Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 2/2Reducer 2: 0(+1)/1Reducer 3: 0/1Reducer 4: 0/6
INFO  : Map 1: 2/2Reducer 2: 1/1Reducer 3: 0(+1)/1Reducer 4: 0/6
INFO  : Map 1: 2/2Reducer 2: 1/1Reducer 3: 1/1Reducer 4: 0/6
INFO  : Map 1: 2/2Reducer 2: 1/1Reducer 3: 1/1Reducer 4: 0(+2)/6
INFO  : Map 1: 2/2Reducer 2: 1/1Reducer 3: 1/1Reducer 4: 1(+2)/6
INFO  : Map 1: 2/2Reducer 2: 1/1Reducer 3: 1/1Reducer 4: 2(+2)/6
INFO  : Map 1: 2/2Reducer 2: 1/1Reducer 3: 1/1Reducer 4: 3(+2)/6
INFO  : Map 1: 2/2Reducer 2: 1/1Reducer 3: 1/1Reducer 4: 5(+1)/6
INFO  : Map 1: 2/2Reducer 2: 1/1Reducer 3: 1/1Reducer 4: 6/6
INFO  : Completed executing command(queryId=hive_20220717094409_7e8a1548-4f9e-480a-8cb6-58eceba6982c); Time taken: 81.125 seconds
INFO  : OK
+---------------+---------------------+
|     brand     |   increased_sales   |
+---------------+---------------------+
| artex         | 16309.34000000207   |
| carmex        | 896.2199999999734   |
| concept       | 8911.900000009628   |
| consly        | 203.53999999998132  |
| ellips        | 1024.1400000000285  |
| emil          | 20090.870000001305  |
| haruyama      | 22547.789999984263  |
| ibd           | 7.76                |
| jaguar        | 559.8299999987212   |
| limoni        | 4764.480000000083   |
| mane          | 504.2200000000139   |
| markell       | 4835.99000000034    |
| nitrile       | 1821.8699999998662  |
| plazan        | 445.5799999999931   |
| runail        | 23185.250002758345  |
| shik          | 67108.7199999913    |
| sophin        | 5126.779999998937   |
| strong        | 163467.68000014964  |
| yoko          | 25271.18000000692   |
| aura          | 313.6999999999978   |
| balbcare      | 1736.4100000000776  |
| beauugreen    | 2667.4999999999345  |
| biofollica    | 1891.1100000000215  |
| cnd           | 70391.4699999661    |
| de.lux        | 5762.349999995451   |
| freedecor     | 46616.33999996718   |
| igrobeauty    | 274.81999999995605  |
| ingarden      | 65672.43999985087   |
| jessnail      | 217235.78999954648  |
| kiss          | 426.72000000040134  |
| koreatida     | 1727.9400000000019  |
| lador         | 1873.9800000001997  |
| metzger       | 7437.950000007215   |
| roubloff      | 6586.1799999949     |
| severina      | 6440.589999998614   |
| staleks       | 33791.60999998104   |
| vilenta       | 137.04000000001952  |
| art-visage    | 6124.179999996042   |
| australis     | 557.9799999999999   |
| barbie        | 68.18999999999993   |
| ecocraft      | 7659.639999999954   |
| elskin        | 319.6800000000271   |
| entity        | 1630.589999998716   |
| eos           | 762.2699999999943   |
| fedua         | 1573.2399999999952  |
| frozen        | 91.14000000000033   |
| glysolid      | 498.3599999999924   |
| ikoo          | 113.33              |
| inm           | 32.42999999996209   |
| kamill        | 81.74000000000058   |
| lianail       | 144334.34999995455  |
| missha        | 24733.69999999882   |
| nagaraku      | 7820.140000001724   |
| philips       | 38.72999999999985   |
| smart         | 1980.0499999975727  |
| uno           | 113158.08999999863  |
| vosev         | 11891.32000000067   |
| airnails      | 1898.0100000129023  |
| bpw.style     | 11059.280000112252  |
| cosmoprofi    | 42547.34000005247   |
| dewal         | 2028.9099999999976  |
| dizao         | 1471.8400000007641  |
| finish        | 1082.4899999999966  |
| grattol       | 353045.5699990003   |
| italwax       | 10355.33999998431   |
| jas           | 80599.36999999758   |
| kapous        | 4732.6300000145275  |
| koelf         | 1590.220000000094   |
| kosmekka      | 970.7599999589147   |
| laiseven      | 58.239999999999995  |
| levrana       | 400.8900000022695   |
| opi           | 397.9199999999728   |
| polarus       | 121377.82000001462  |
| s.care        | 27526.710000000792  |
| sanoto        | 19173.29000000011   |
| shary         | 1212.9899999998797  |
| shifei        | 14.049999999999997  |
| tazol         | 5.389999999999986   |
| tertio        | 1279.86999999999    |
| zeitun        | 4582.520000000168   |
| batiste       | 1595.1000000000477  |
| beautix       | 9187.080000057002   |
| browxenna     | 9124.02000000485    |
| busch         | 82.52000000000007   |
| ecolab        | 14169.750000000557  |
| enas          | 58.110000000006266  |
| f.o.x         | 7644.809999996825   |
| fly           | 172.6700000000011   |
| gehwol        | 3489.1000000000495  |
| greymy        | 934.1199999999963   |
| happyfons     | 1046.6299999995026  |
| levissime     | 5358.219999998259   |
| lovely        | 26082.139999998704  |
| marathon      | 124160.59999998717  |
| max           | 49760.50000000722   |
| milv          | 10711.569999991523  |
| naomi         | 21459.030000000133  |
| skinlite      | 67.84000000000742   |
|               | 1243460.6399490088  |
| beauty-free   | 12569.42999999963   |
+---------------+---------------------+
|     brand     |   increased_sales   |
+---------------+---------------------+
| benovy        | 23382.809999999998  |
| candy         | 4725.729999999752   |
| coifin        | 21890.03999999965   |
| cristalinas   | 1498.8999999999924  |
| invisibobble  | 9.200000000000003   |
| lowence       | 2022.1000000000658  |
| matreshka     | 10283.630000000114  |
| refectocil    | 3748.2300000005343  |
| swarovski     | 7882.670000001206   |
| yu-r          | 6686.3999999999305  |
+---------------+---------------------+
110 rows selected (81.327 seconds)
0: jdbc:hive2://localhost:10000/default> select brand,Increased_Sales from (select brand,sum(case when Month = 11 then Monthly_Price else -Monthly_Price end) as Increased_Sales from monthly_brand_price group by brand having Increased_Sales>0)s;;s;cing Increased_Sales>0)s;) having Increased_Sales>0;where Increased_Sales>0;Brand_Price>0;sum(case when Month = 11 then Monthly_Price else -Monthly_Price end) as Brand_Price from monthly_brand_price group by brand;price else -price end) as Brand_Price from monthly_brand_price group by brand;clickstream_tbl group by brand;* from monthly_brand_price order by brand limit 10;group by brand order by brand limit 10;limit 10;create view monthly_brand_price as (select month(event_time) as Month, brand, sum(price) as Monthly_Price from clickstream_tbl group by month(event_time),brand order by Month,brand);show tables;drop view monthly_brand_price;show tables;create view monthly_brand_price as (select month(event_time) as Month, brand, sum(price) as Monthly_Price from clickstream_tbl group by month(event_time),brand order by Month,brand);show tables;drop view monthly_brand_price;table monthly_brand_price;;drop table monthly_brand_priceshow tables;create view monthly_brand_price as (select month(event_time) as Month, brand, sum(price) as Monthly_Price from clickstream_tbl group by month(event_time),brand order by Month,brand);month(event_time),brand);select * from monthly_brand_price limit 5;create view monthly_brand_price as (select month(event_time) as Month, brand, sum(price) as Monthly_Price from clickstream_tbl group by month(event_time),brand);Month,brand);;select user_id,sum(price) as Purchase_Amt from clickstream_tbl where event_type = 'purchase' group by user_id order by Purchase_Amt desc limit 10;chase' group by user_id order by Purchase_Amt desc limit 10;brand,sum(price) as Brand_Price from clickstream_tbl group by brand order by Brand_Price desc limit 5;count(product_id) as Product_Count, category_code from clickstream_tbl group by category_code; order by 1;describe clickstream_tbl;select count(product_id) as Product_Count, category_code from clickstream_tbl group by category_code order by 1;use clickstream;select count(product_id) as Product_Count, category_code from clickstream_tbl group by category_code order by 1;group by category_code order by 1;select count(product_id) as Product_Count, category_code from clickstream_tbl distinct(category_code) from part_mnth_buck_type_tbl where category_code!="" and category_code is not null;use clickstream;select distinct(category_code) from clickstream_tbl where category_code!="" and category_code is not null;how tables;use clickstream;select distinct(category_code) from clickstream_tbl where category_code!="" and category_code is not null; ;how tables;elect distinct(category_code) from clickstream_tbl where category_code is not Null or category_code != ""; category_code != "";and category_code != "";use clickstream;select distinct(category_code) from clickstream_tbl where category_code is not Null and category_code != "";October_price, November_price, November_price - October_price as Difference from(select sum(case when month(event_time)=10 then price else 0 end) as October_price, sum(case when month(event_time)=11 then price else 0 end) as November_price from part_mnth_buck_type_tbl WHERE month(event_time)in (10,11) and event_type='purchase')s;all;use clickstream;select October_price, November_price, November_price - October_price as Difference from(select sum(case when month(event_time)=10 then price else 0 end) as October_price, sum(case when month(event_time)=11 then price else 0 end) as November_price from part_mnth_buck_type_tbl WHERE month(event_time)in (10,11) and event_type='purchase')s;a;ll;SELECT sum(case when month(event_time)=10 then price else 0 end) as October_price, sum(case when month(event_time)=11 then price else 0 end) as November_price from part_mnth_buck_type_tbl WHERE month(event_time)in (10,11) and event_type='purchase')all;select October_price, November_price, November_price - October_price as Difference from( SELECT sum(case when month(event_time)=10 then price else 0 end) as October_price, sum(case when month(event_time)=11 then price else 0 end) as November_price from part_mnth_buck_type_tbl WHERE month(event_time)in (10,11) and event_type='purchase')all;clickstream_tbl WHERE month(event_time)in (10,11) and event_type='purchase')s;select October_price, November_price, November_price - October_price as Difference from( SELECT sum(case when month(event_time)=10 then price else 0 end) as October_price, sum(case when month(event_time)=11 then price else 0 end) as November_price from clickstream_tbl WHERE month(event_time)in (10,11) and event_type='purchase')s;select October, November, November - October as Difference from( sum(price) as november_sum from clickstream_tbl where month(event_time) = 11 and event_type = 'purchase' );UNION ALLselect sum(price) as october_sum from clickstream_tbl where month(event_time) = 10 and event_type = 'purchase'october_sum,november_sum from( sum(price) as november_sum from clickstream_tbl where month(event_time) = 11 and event_type = 'purchase' ) all;UNION ALLselect sum(price) as october_sum from clickstream_tbl where month(event_time) = 10 and event_type = 'purchase'all.october_sum,all.november_sum from ( sum(price) as october_sum from clickstream_tbl where month(event_time) = 10 and event_type = 'purchase'; where month(event_time) = 10 and event_type = 'purchase' from clickstream_tbl; ,sum(price) as november_sum where month(event_time) = 11 and event_type = 'purchase'  from clickstream_tbl;use clickstream;select sum(price) where month(event_time) = 10 and event_type = 'purchase' as october_sum,sum(price) where month(event_time) = 11 and event_type = 'purchase' as november_sum from clickstream_tbl;october_sum,november_sum,november_sum - october_sum as Difference from (select sum(price) where month(event_time) = 10 and event_type = 'purchase' as october_sum,sum(price) where month(event_time) = 11 and event_type = 'purchase') as november_sum from clickstream_tbl););* from (select sum(price) where month(event_time) = 10 and event_type = 'purchase') as october_sum,(select sum(price) where month(event_time) = 11 and event_type = 'purchase') as november_sum);as Price where month(event_time) = 10 and event_type = 'purchase'),(select sum(price) as Nov_Price where month(event_time) = 11 and event_type = 'purchase'));sum(price) as Price where month(event_time) = 10 and event_type = 'purchase', select sum(price) as Nov_Price where month(event_time) = 11 and event_type = 'purchase');month(event_time) as Month, sum(price) as Price from part_mnth_buck_type_tbl where event_type = 'purchase' group by month(event_time);how tables;use clickstream;show tables;elect month(event_time) as Month, sum(price) as Price from part_mnth_buck_type_tbl where event_type = 'purchase' group by month(event_time);clickstream_tbl where event_type = 'purchase' group by month(event_time);chase' group by month(event_time);round(sum(price),2) as Oct_Revenue from part_mnth_buck_type_tbl where month(event_time) = 10 and event_type = 'purchase';clickstream_tbl where month(event_time) = 10 and event_type = 'purchase';create table if not exists part_type_tbl(event_time string,event_type string,product_id string,category_id string,category_code string,brand string,price decimal(10,3),user_id bigint,user_session string) partitioned by (event_type) row format SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' stored as textfile; string) row format SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' stored as textfile;select * from part_mnth_buck_type_tbl limit 5;insert into table part_mnth_buck_type_tbl partition(mnth) select *,month(event_time) as mnth from clickstream_stats where month(event_time) in (10,11);create table if not exists part_mnth_buck_type_tbl(event_time string,event_type string,product_id string,category_id string,category_code string,brand string,price decimal(10,3),user_id bigint,user_session string) partitioned by (mnth int) clustered by (event_type) into 4 buckets row format SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' stored as textfile;show tables;drop table part_mnth_buck_type_tbl;show tables;create table if not exists part_mnth_buck_type_tbl(event_time string,event_type string,product_id string,category_id string,category_code string,brand string,price string,user_id string,user_session string) partitioned by (mnth int) clustered by (event_type) into 4 buckets row format SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' stored as textfile;external table if not exists part_type_bucket_mnth_tbl(event_time string,event_type string,product_id string,category_id string,category_code string,brand string,price decimal(10,3),user_id bigint,user_session string) partitioned by (event_type string) clustered by (mnth int) into 2 buckets row format SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' stored as textfile;) into 2 buckets row format SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' stored as textfile;) clustered by (mnth int) into 2 buckets row format SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' stored as textfile;set hive.enforce.bucketing = true;xec.dynamic.partition.mode = nonstrict; = true;lect distinct event_type from clickstream_tbl;* from clickstream_tbl order by event_time desc limit 20;asc limit 20;load data local inpath '/home/hadoop/hive_cs/2019-Nov.csv' into table clickstream_tbl;Oct.csv' into table clickstream_tbl;create table if not exists clickstream_tbl(event_time timestamp,event_type string, product_id string, category_id string, category_code string, brand string, price decimal(10,3),user_id bigint, user_session string) row format serde 'org.apache.hadoop.hive.serde2.OpenCSVSerde' WITH SERDEPROPERTIES ( "separatorChar" = ",", "quoteChar" = "\"", "escapeChar" = "\\") stored as textfile TBLPROPERTIES ("skip.header.line.count"="1");TBLPROPERTIES ("skip.header.line.count"="1"));WITH SERDEPROPERTIES ( "separatorChar" = ",", "quoteChar" = "\"", "escapeChar" = "\\") stored as textfile create table if not exists clickstream_tbl(event_time timestamp,event_type string, product_id string, category_id string, category_code string, brand string, price decimal(10,3),user_id bigint, user_session string) row format serde 'org.apache.hadoop.hive.serde2.OpenCSVSerde' show tables;elect * from clickstream_stats order by event_time asc limit 20;desc limit 20;asc limit 20;desc limit 20;10;asc limit 10;load data local inpath '/home/hadoop/hive_cs/2019-Nov.csv' into table clickstream_stats;Oct.csv' into table clickstream_stats;create table clickstream_stats(event_time string,event_type string,product_id string,category_id string,category_code string,brand string,price string,user_id string,user_session string) row format delimited fields terminated by ',' lines terminated by '\n' stored as textfile;use clickstream;show databases;create database if not exists clickstream;show databases;create database if not exists clickstream;show databases;use clickstream;create table clickstream_stats(event_time string,event_type string,product_id string,category_id string,category_code string,brand string,price string,user_id string,user_session string) row format delimited fields terminated by ',' lines terminated by '\n' stored as textfile;load data local inpath '/home/hadoop/hive_cs/2019-Oct.csv' into table clickstream_stats;Nov.csv' into table clickstream_stats;Oct.csv' into table clickstream_stats;Nov.csv' into table clickstream_stats;Oct.csv' into table clickstream_stats;Nov.csv' into table clickstream_stats;select * from clickstream_stats order by event_time asc limit 10;desc limit 10;20;asc limit 20;how tables;create table if not exists clickstream_tbl(event_time timestamp,event_type string, product_id string, category_id string, category_code string, brand string, price decimal(10,3),user_id bigint, user_session string) row format serde 'org.apache.hadoop.hive.serde2.OpenCSVSerde' WITH SERDEPROPERTIES ( "separatorChar" = ",", "quoteChar" = "\"", "escapeChar" = "\\") stored as textfile TBLPROPERTIES ("skip.header.line.count"="1"));create table if not exists clickstream_tbl(event_time timestamp,event_type string, product_id string, category_id string, category_code string, brand string, price decimal(10,3),user_id bigint, user_session string) row format serde 'org.apache.hadoop.hive.serde2.OpenCSVSerde' WITH SERDEPROPERTIES ( "separatorChar" = ",", "quoteChar" = "\"", "escapeChar" = "\\") stored as textfile TBLPROPERTIES ("skip.header.line.count"="1");load data local inpath '/home/hadoop/hive_cs/2019-Oct.csv' into table clickstream_tbl;Nov.csv' into table clickstream_tbl;select * from clickstream_tbl order by event_time asc limit 20;desc limit 20;asc limit 20;desc limit 20;distinct event_type from clickstream_tbl;t hive.exec.dynamic.partition = true;.mode = nonstrict;nforce.bucketing = true;create external table if not exists part_type_bucket_mnth_tbl(event_time string,event_type string,product_id string,category_id string,category_code string,brand string,price decimal(10,3),user_id bigint,user_session string) partitioned by (event_type) clustered by (mnth int) into 2 buckets row format SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' stored as textfile;set hive.enforce.bucketing = true;xec.dynamic.partition.mode = nonstrict;nforce.bucketing = true;create external table if not exists part_type_bucket_mnth_tbl(event_time string,event_type string,product_id string,category_id string,category_code string,brand string,price decimal(10,3),user_id bigint,user_session string) partitioned by (event_type) clustered by (mnth int) into 2 buckets row format SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' stored as textfile; string) clustered by (mnth) into 2 buckets row format SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' stored as textfile; int) into 2 buckets row format SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' stored as textfile;table if not exists part_mnth_buck_type_tbl(event_time string,event_type string,product_id string,category_id string,category_code string,brand string,price string,user_id string,user_session string) partitioned by (mnth int) clustered by (event_type) into 4 buckets row format SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' stored as textfile;show tables;drop table part_mnth_buck_type_tbl;show tables;create table if not exists part_mnth_buck_type_tbl(event_time string,event_type string,product_id string,category_id string,category_code string,brand string,price decimal(10,3),user_id bigint,user_session string) partitioned by (mnth int) clustered by (event_type) into 4 buckets row format SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' stored as textfile;insert into table part_mnth_buck_type_tbl partition(mnth) select *,month(event_time) as mnth from clickstream_stats where month(event_time) in (10,11);select * from part_mnth_buck_type_tbl limit 5;create table if not exists part_type_tbl(event_time string,event_type string,product_id string,category_id string,category_code string,brand string,price decimal(10,3),user_id bigint,user_session string) partitioned by (event_type string) row format SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' stored as textfile;) row format SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' stored as textfile; string) row format SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' stored as textfile;select * from part_mnth_buck_type_tbl limit 5;show tables;
INFO  : Compiling command(queryId=hive_20220717124728_2d7afcec-f06a-4266-ae69-6c04b22bd181): show tables
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:tab_name, type:string, comment:from deserializer)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717124728_2d7afcec-f06a-4266-ae69-6c04b22bd181 : STAGE DEPENDENCIES:
  Stage-0 is a root stage [DDL]
  Stage-1 depends on stages: Stage-0 [FETCH]

STAGE PLANS:
  Stage: Stage-0
      Show Table Operator:
        Show Tables
          database name: clickstream
          result file: file:/mnt/tmp/hive/6d06f1f1-d96b-4e15-a557-93756f1f3ebc/hive_2022-07-17_12-47-28_636_5837884531098777502-16/-local-10000

  Stage: Stage-1
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717124728_2d7afcec-f06a-4266-ae69-6c04b22bd181); Time taken: 0.02 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717124728_2d7afcec-f06a-4266-ae69-6c04b22bd181): show tables
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20220717124728_2d7afcec-f06a-4266-ae69-6c04b22bd181); Time taken: 0.011 seconds
INFO  : OK
+--------------------------+
|         tab_name         |
+--------------------------+
| clickstream_stats        |
| clickstream_tbl          |
| monthly_brand_price      |
| part_mnth_buck_type_tbl  |
+--------------------------+
4 rows selected (0.042 seconds)
0: jdbc:hive2://localhost:10000/default> show tables;elect brand,Increased_Sales from (select brand,sum(case when Month = 11 then Monthly_Price else -Monthly_Price end) as Increased_Sales from monthly_brand_price group by brand having Increased_Sales>0)s;;s;how tables;show tables;show partitions;
Error: Error while compiling statement: FAILED: ParseException line 1:15 cannot recognize input near '<EOF>' '<EOF>' '<EOF>' in table name (state=42000,code=40000)
0: jdbc:hive2://localhost:10000/default> show partitions;;
Error: Error while compiling statement: FAILED: ParseException line 1:5 cannot recognize input near 'show' 'partition' '<EOF>' in ddl statement (state=42000,code=40000)
0: jdbc:hive2://localhost:10000/default> show partition;show tables;
INFO  : Compiling command(queryId=hive_20220717130257_39c5c850-de2c-467b-907f-af8e6ba8b168): show tables
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:tab_name, type:string, comment:from deserializer)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717130257_39c5c850-de2c-467b-907f-af8e6ba8b168 : STAGE DEPENDENCIES:
  Stage-0 is a root stage [DDL]
  Stage-1 depends on stages: Stage-0 [FETCH]

STAGE PLANS:
  Stage: Stage-0
      Show Table Operator:
        Show Tables
          database name: clickstream
          result file: file:/mnt/tmp/hive/6d06f1f1-d96b-4e15-a557-93756f1f3ebc/hive_2022-07-17_13-02-57_327_1366162490606691343-16/-local-10000

  Stage: Stage-1
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717130257_39c5c850-de2c-467b-907f-af8e6ba8b168); Time taken: 0.018 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717130257_39c5c850-de2c-467b-907f-af8e6ba8b168): show tables
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20220717130257_39c5c850-de2c-467b-907f-af8e6ba8b168); Time taken: 0.011 seconds
INFO  : OK
+--------------------------+
|         tab_name         |
+--------------------------+
| clickstream_stats        |
| clickstream_tbl          |
| monthly_brand_price      |
| part_mnth_buck_type_tbl  |
+--------------------------+
4 rows selected (0.044 seconds)
0: jdbc:hive2://localhost:10000/default> show tables;partition;s;
Error: Error while compiling statement: FAILED: ParseException line 1:15 cannot recognize input near '<EOF>' '<EOF>' '<EOF>' in table name (state=42000,code=40000)
0: jdbc:hive2://localhost:10000/default> show databases;
INFO  : Compiling command(queryId=hive_20220717130348_bbed999e-ac92-421f-9d42-ce4c3f46c2ac): show databases
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:database_name, type:string, comment:from deserializer)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717130348_bbed999e-ac92-421f-9d42-ce4c3f46c2ac : STAGE DEPENDENCIES:
  Stage-0 is a root stage [DDL]
  Stage-1 depends on stages: Stage-0 [FETCH]

STAGE PLANS:
  Stage: Stage-0
      Show Databases Operator:
        Show Databases
          result file: file:/mnt/tmp/hive/6d06f1f1-d96b-4e15-a557-93756f1f3ebc/hive_2022-07-17_13-03-48_911_6441665260525529721-16/-local-10000

  Stage: Stage-1
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717130348_bbed999e-ac92-421f-9d42-ce4c3f46c2ac); Time taken: 0.028 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717130348_bbed999e-ac92-421f-9d42-ce4c3f46c2ac): show databases
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20220717130348_bbed999e-ac92-421f-9d42-ce4c3f46c2ac); Time taken: 0.01 seconds
INFO  : OK
+----------------+
| database_name  |
+----------------+
| clickstream    |
| default        |
+----------------+
2 rows selected (0.058 seconds)
0: jdbc:hive2://localhost:10000/default> use clickstream;
INFO  : Compiling command(queryId=hive_20220717130356_5db36a78-6458-468f-8298-314cd715f3b1): use clickstream
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : EXPLAIN output for queryid hive_20220717130356_5db36a78-6458-468f-8298-314cd715f3b1 : STAGE DEPENDENCIES:
  Stage-0 is a root stage [DDL]

STAGE PLANS:
  Stage: Stage-0


INFO  : Completed compiling command(queryId=hive_20220717130356_5db36a78-6458-468f-8298-314cd715f3b1); Time taken: 0.019 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717130356_5db36a78-6458-468f-8298-314cd715f3b1): use clickstream
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20220717130356_5db36a78-6458-468f-8298-314cd715f3b1); Time taken: 0.009 seconds
INFO  : OK
No rows affected (0.035 seconds)
0: jdbc:hive2://localhost:10000/default> use clickstream;show databases;partitions;
Error: Error while compiling statement: FAILED: ParseException line 1:15 cannot recognize input near '<EOF>' '<EOF>' '<EOF>' in table name (state=42000,code=40000)
0: jdbc:hive2://localhost:10000/default> show partitions clickstream_tbl;
INFO  : Compiling command(queryId=hive_20220717163226_071d41e9-1e93-4785-b02a-c9e3210de136): show partitions clickstream_tbl
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:partition, type:string, comment:from deserializer)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717163226_071d41e9-1e93-4785-b02a-c9e3210de136 : STAGE DEPENDENCIES:
  Stage-0 is a root stage [DDL]
  Stage-1 depends on stages: Stage-0 [FETCH]

STAGE PLANS:
  Stage: Stage-0
      Show Partitions Operator:
        Show Partitions
          result file: file:/mnt/tmp/hive/6d06f1f1-d96b-4e15-a557-93756f1f3ebc/hive_2022-07-17_16-32-26_164_750705385395570619-16/-local-10000
          table: clickstream_tbl

  Stage: Stage-1
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717163226_071d41e9-1e93-4785-b02a-c9e3210de136); Time taken: 0.047 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717163226_071d41e9-1e93-4785-b02a-c9e3210de136): show partitions clickstream_tbl
INFO  : Starting task [Stage-0:DDL] in serial mode
ERROR : FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. Table clickstream_tbl is not a partitioned table
INFO  : Completed executing command(queryId=hive_20220717163226_071d41e9-1e93-4785-b02a-c9e3210de136); Time taken: 0.011 seconds
Error: org.apache.hive.service.cli.HiveSQLException: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. Table clickstream_tbl is not a partitioned table
at org.apache.hive.service.cli.operation.Operation.toSQLException(Operation.java:380)
at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:254)
at org.apache.hive.service.cli.operation.SQLOperation.access$800(SQLOperation.java:88)
at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:345)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:422)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1926)
at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:360)
at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
at java.util.concurrent.FutureTask.run(FutureTask.java:266)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Table clickstream_tbl is not a partitioned table
at org.apache.hadoop.hive.ql.exec.DDLTask.showPartitions(DDLTask.java:2122)
at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:499)
at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:203)
at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:100)
at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:2183)
at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1839)
at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1526)
at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1237)
at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1232)
at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:252)
... 11 more (state=08S01,code=1)
0: jdbc:hive2://localhost:10000/default> show partitions clickstream_tbl;;;;;;;;;;;;;;;;; ;p;a;r;t;_;m;n;t;h;_;b;u;c;k;_;t;y;p;e;_;t;b;l;
INFO  : Compiling command(queryId=hive_20220717163256_fd3414e0-1cc5-4b9b-8149-a519dbd5aa75): show partitions part_mnth_buck_type_tbl
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:partition, type:string, comment:from deserializer)], properties:null)
INFO  : EXPLAIN output for queryid hive_20220717163256_fd3414e0-1cc5-4b9b-8149-a519dbd5aa75 : STAGE DEPENDENCIES:
  Stage-0 is a root stage [DDL]
  Stage-1 depends on stages: Stage-0 [FETCH]

STAGE PLANS:
  Stage: Stage-0
      Show Partitions Operator:
        Show Partitions
          result file: file:/mnt/tmp/hive/6d06f1f1-d96b-4e15-a557-93756f1f3ebc/hive_2022-07-17_16-32-56_452_712136413452855922-16/-local-10000
          table: part_mnth_buck_type_tbl

  Stage: Stage-1
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink


INFO  : Completed compiling command(queryId=hive_20220717163256_fd3414e0-1cc5-4b9b-8149-a519dbd5aa75); Time taken: 0.044 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20220717163256_fd3414e0-1cc5-4b9b-8149-a519dbd5aa75): show partitions part_mnth_buck_type_tbl
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20220717163256_fd3414e0-1cc5-4b9b-8149-a519dbd5aa75); Time taken: 0.039 seconds
INFO  : OK
+------------+
| partition  |
+------------+
| mnth=10    |
| mnth=11    |
+------------+
2 rows selected (0.095 seconds)
0: jdbc:hive2://localhost:10000/default> 